[
  {
    "objectID": "10_dataloaders/tabular_dataloaders.html",
    "href": "10_dataloaders/tabular_dataloaders.html",
    "title": "Tabular dataloaders",
    "section": "",
    "text": "source",
    "crumbs": [
      "Dataloaders",
      "Tabular dataloaders"
    ]
  },
  {
    "objectID": "10_dataloaders/tabular_dataloaders.html#xydataloader",
    "href": "10_dataloaders/tabular_dataloaders.html#xydataloader",
    "title": "Tabular dataloaders",
    "section": "XYDataLoader",
    "text": "XYDataLoader\n\n XYDataLoader (X:numpy.ndarray, Y:numpy.ndarray,\n               val_index_start:Optional[int]=None,\n               test_index_start:Optional[int]=None,\n               lag_window_params:dict=None, normalize_features:dict=None)\n\nA class for datasets with the typicall X, Y structure. Both X and Y are numpy arrays. X may be of shape (datapoints, features) or (datapoints, sequence_length, features) if lag features are used. The prep_lag_features can be used to create those lag features. Y is of shape (datapoints, units).\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nX\nndarray\n\n\n\n\nY\nndarray\n\n\n\n\nval_index_start\nOptional\nNone\n\n\n\ntest_index_start\nOptional\nNone\n\n\n\nlag_window_params\ndict\nNone\ndefault: {‘lag_window’: 0, ‘include_y’: False, ‘pre_calc’: False}\n\n\nnormalize_features\ndict\nNone\ndefault: {‘normalize’: True, ‘ignore_one_hot’: True}\n\n\n\n\nsource\n\nXYDataLoader.prep_lag_features\n\n XYDataLoader.prep_lag_features (lag_window:int=0, include_y:bool=False,\n                                 pre_calc:bool=False)\n\nCreate lag feature for the dataset. If “inlcude_y” is true, then a lag-1 of of the target variable is added as a feature. If lag-window is &gt; 0, the lag features are added as middle dimension to X. Note that this, e.g., means that with a lag window of 1, the data will include 2 time steps, the current features including lag-1 demand and the lag-1 features including lag-2 demand. If pre-calc is true, all these calculations are performed on the entire dataset reduce computation time later on at the expense of increases memory usage.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nlag_window\nint\n0\nlength of the lage window\n\n\ninclude_y\nbool\nFalse\nif lag demand shall be included as feature\n\n\npre_calc\nbool\nFalse\nif all lags are pre-calculated for the entire dataset\n\n\n\n\nsource\n\n\nXYDataLoader.__getitem__\n\n XYDataLoader.__getitem__ (idx)\n\nget item by index, depending on the dataset type (train, val, test)\n\nsource\n\n\nXYDataLoader.get_all_X\n\n XYDataLoader.get_all_X (dataset_type:str='train')\n\nReturns the entire features dataset. Return either the train, val, test, or all data.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndataset_type\nstr\ntrain\ncan be ‘train’, ‘val’, ‘test’, ‘all’\n\n\n\n\nsource\n\n\nXYDataLoader.get_all_Y\n\n XYDataLoader.get_all_Y (dataset_type:str='train')\n\nReturns the entire target dataset. Return either the train, val, test, or all data.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndataset_type\nstr\ntrain\ncan be ‘train’, ‘val’, ‘test’, ‘all’\n\n\n\nExample usage of [`XYDataLoader`](https://opimwue.github.io/ddopai/10_dataloaders/tabular_dataloaders.html#xydataloader) for simple dataset:\n\nX = np.random.standard_normal((100, 2))\nY = np.random.standard_normal((100, 1))\nY += 2*X[:,0].reshape(-1, 1) + 3*X[:,1].reshape(-1, 1)\n\ndataloader = XYDataLoader(X = X, Y = Y)\n\nsample_X, sample_Y = dataloader[0]\nprint(\"sample:\", sample_X, sample_Y)\nprint(\"sample shape Y:\", sample_Y.shape)\n\nprint(\"length:\", len(dataloader))\n\nsample: [0.19586287 1.09162108] [1.040336]\nsample shape Y: (1,)\nlength: 100\n\n\nExample usage of [`XYDataLoader`](https://opimwue.github.io/ddopai/10_dataloaders/tabular_dataloaders.html#xydataloader) on how to handle train, val, and test set:\n\nX = np.random.standard_normal((10, 2))\nY = np.random.standard_normal((10, 1))\nY += 2*X[:,0].reshape(-1, 1) + 3*X[:,1].reshape(-1, 1)\n\ndataloader = XYDataLoader(X = X, Y = Y, val_index_start=6, test_index_start=8)\n\nsample_X, sample_Y = dataloader[0]\n\nprint(\"length train:\", dataloader.len_train, \"length val:\", dataloader.len_val, \"length test:\", dataloader.len_test)\n\nprint(\"\")\nprint(\"### Data from train set ###\")\nfor i in range(dataloader.len_train):\n    sample_X, sample_Y = dataloader[i]\n    print(\"idx:\", i, \"data:\", sample_X, sample_Y)\n\ndataloader.val()\n\nprint(\"\")\nprint(\"### Data from val set ###\")\nfor i in range(dataloader.len_val):\n    sample_X, sample_Y = dataloader[i]\n    print(\"idx:\", i, \"data:\", sample_X, sample_Y)\n\ndataloader.test()\n\nprint(\"\")\nprint(\"### Data from test set ###\")\nfor i in range(dataloader.len_test):\n    sample_X, sample_Y = dataloader[i]\n    print(\"idx:\", i, \"data:\", sample_X, sample_Y)\n\ndataloader.train()\n\nprint(\"\")\nprint(\"### Data from train set again ###\")\nfor i in range(dataloader.len_train):\n    sample_X, sample_Y = dataloader[i]\n    print(\"idx:\", i, \"data:\", sample_X, sample_Y)\n\nlength train: 6 length val: 2 length test: 2\n\n### Data from train set ###\nidx: 0 data: [ 0.08854902 -1.7602724 ] [-5.34363735]\nidx: 1 data: [ 0.99129486 -1.78646157] [-0.9519102]\nidx: 2 data: [0.66334628 0.01231061] [0.95274982]\nidx: 3 data: [ 0.61796118 -0.54523986] [0.35028762]\nidx: 4 data: [1.04676734 1.75569924] [5.92952598]\nidx: 5 data: [ 0.21987025 -0.53602459] [0.66207364]\n\n### Data from val set ###\nidx: 0 data: [-1.54514703 -0.67784998] [-5.27601525]\nidx: 1 data: [ 0.935785   -1.30048604] [-2.66055254]\n\n### Data from test set ###\nidx: 0 data: [1.86740017 0.79714291] [4.61669816]\nidx: 1 data: [ 0.30325407 -0.62230244] [-2.03026803]\n\n### Data from train set again ###\nidx: 0 data: [ 0.08854902 -1.7602724 ] [-5.34363735]\nidx: 1 data: [ 0.99129486 -1.78646157] [-0.9519102]\nidx: 2 data: [0.66334628 0.01231061] [0.95274982]\nidx: 3 data: [ 0.61796118 -0.54523986] [0.35028762]\nidx: 4 data: [1.04676734 1.75569924] [5.92952598]\nidx: 5 data: [ 0.21987025 -0.53602459] [0.66207364]\n\n\nExample usage of [`XYDataLoader`](https://opimwue.github.io/ddopai/10_dataloaders/tabular_dataloaders.html#xydataloader) on how to include lag features:\n\nX = np.random.standard_normal((10, 2))\nY = np.random.standard_normal((10, 1))\nY += 2*X[:,0].reshape(-1, 1) + 3*X[:,1].reshape(-1, 1)\n\nlag_window_params = {'lag_window': 1, 'include_y': True, 'pre_calc': True}\n\ndataloader = XYDataLoader(X = X, Y = Y, val_index_start=6, test_index_start=8, lag_window_params=lag_window_params)\n\nsample_X, sample_Y = dataloader[0]\n\nprint(\"length train:\", dataloader.len_train, \"length val:\", dataloader.len_val, \"length test:\", dataloader.len_test)\n\nprint(\"\")\nprint(\"### Data from train set ###\")\nfor i in range(dataloader.len_train):\n    sample_X, sample_Y = dataloader[i]\n    print(\"idx:\", i, \"data:\", sample_X, sample_Y)\n\ndataloader.val()\n\nprint(\"\")\nprint(\"### Data from val set ###\")\nfor i in range(dataloader.len_val):\n    sample_X, sample_Y = dataloader[i]\n    print(\"idx:\", i, \"data:\", sample_X, sample_Y)\n\ndataloader.test()\n\nprint(\"\")\nprint(\"### Data from test set ###\")\nfor i in range(dataloader.len_test):\n    sample_X, sample_Y = dataloader[i]\n    print(\"idx:\", i, \"data:\", sample_X, sample_Y)\n\ndataloader.train()\n\nprint(\"\")\nprint(\"### Data from train set again ###\")\nfor i in range(dataloader.len_train):\n    sample_X, sample_Y = dataloader[i]\n    print(\"idx:\", i, \"data:\", sample_X, sample_Y)\n\nlength train: 4 length val: 2 length test: 2\n\n### Data from train set ###\nidx: 0 data: [[ 0.73863651  0.6084497  -0.1193545 ]\n [ 0.35830697 -1.87500947  2.48387723]] [-4.9460667]\nidx: 1 data: [[ 0.35830697 -1.87500947  2.48387723]\n [-1.11068046 -0.5626968  -4.9460667 ]] [-1.24390416]\nidx: 2 data: [[-1.11068046 -0.5626968  -4.9460667 ]\n [ 0.89828028 -2.19265635 -1.24390416]] [-5.78471176]\nidx: 3 data: [[ 0.89828028 -2.19265635 -1.24390416]\n [-0.09191616  0.32758207 -5.78471176]] [0.35156491]\n\n### Data from val set ###\nidx: 0 data: [[-0.09191616  0.32758207 -5.78471176]\n [ 1.51172992 -0.25329154  0.35156491]] [2.47560231]\nidx: 1 data: [[ 1.51172992 -0.25329154  0.35156491]\n [ 0.17512356  0.93368771  2.47560231]] [1.80751149]\n\n### Data from test set ###\nidx: 0 data: [[ 0.17512356  0.93368771  2.47560231]\n [-0.65111828 -0.13138032  1.80751149]] [-1.55867887]\nidx: 1 data: [[-0.65111828 -0.13138032  1.80751149]\n [ 0.41587237 -1.40709561 -1.55867887]] [-3.46579185]\n\n### Data from train set again ###\nidx: 0 data: [[ 0.73863651  0.6084497  -0.1193545 ]\n [ 0.35830697 -1.87500947  2.48387723]] [-4.9460667]\nidx: 1 data: [[ 0.35830697 -1.87500947  2.48387723]\n [-1.11068046 -0.5626968  -4.9460667 ]] [-1.24390416]\nidx: 2 data: [[-1.11068046 -0.5626968  -4.9460667 ]\n [ 0.89828028 -2.19265635 -1.24390416]] [-5.78471176]\nidx: 3 data: [[ 0.89828028 -2.19265635 -1.24390416]\n [-0.09191616  0.32758207 -5.78471176]] [0.35156491]\n\n\n\nsource\n\n\nMultiShapeLoader\n\n MultiShapeLoader (demand:pandas.core.frame.DataFrame,\n                   time_features:pandas.core.frame.DataFrame,\n                   time_SKU_features:pandas.core.frame.DataFrame,\n                   mask:pandas.core.frame.DataFrame=None,\n                   SKU_features:pandas.core.frame.DataFrame=None,\n                   val_index_start:Optional[int]=None,\n                   test_index_start:Optional[int]=None,\n                   in_sample_val_test_SKUs:List=None,\n                   out_of_sample_val_SKUs:List=None,\n                   out_of_sample_test_SKUs:List=None,\n                   lag_window_params:dict|None=None,\n                   normalize_features:dict|None=None,\n                   engineered_SKU_features:dict=None,\n                   use_engineered_SKU_features:bool=False,\n                   include_non_available:bool=False,\n                   train_subset:int=None, train_subset_SKUs:List=None,\n                   meta_learn_units:bool=False, lag_demand_normalization:O\n                   ptional[Literal['minmax','standard','no_normalization']\n                   ]='standard', demand_normalization:Literal['minmax','st\n                   andard','no_normalization']='no_normalization',\n                   demand_unit_size:float|None=None,\n                   provide_additional_target:bool=False,\n                   permutate_inputs:bool=False,\n                   max_feature_dim:int|None=None)\n\nA class designed for comlex datasets with mutlipe feature types. The class is more memory-efficient than the XYDataLoader, as it separate the storeage of SKU-specific feature, time-specific features, and time-SKU-specific features. The class works generically as long as those feature classes are provided during pre-processing. The class is designed to handle classic learning, but able to work in a meta-learning pipeline where no SKU-dimension is present and the model needs to make prediction on SKU-time level without knowhing the specific SKU.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndemand\nDataFrame\n\nDemand data of shape time x SKU\n\n\ntime_features\nDataFrame\n\nFeatures constant over SKU of shape time x time_features\n\n\ntime_SKU_features\nDataFrame\n\nFeatures varying over time and SKU of shape time x (time_SKU_features*SKU) with double index\n\n\nmask\nDataFrame\nNone\nMask of shape time x SKU telling which SKUs are available at which time (can be used as mask during trainig or added to features)\n\n\nSKU_features\nDataFrame\nNone\nFeatures constant over time of shape SKU x SKU_features - only for algorithms learning across SKUs\n\n\nval_index_start\nOptional\nNone\nValidation index start on the time dimension\n\n\ntest_index_start\nOptional\nNone\nTest index start on the time dimension\n\n\nin_sample_val_test_SKUs\nList\nNone\nSKUs in the training set to be used for validation and testing, out-of-sample w.r.t. time dimension\n\n\nout_of_sample_val_SKUs\nList\nNone\nSKUs to be hold-out for validation (can be same as test if no validation on out-of-sample SKUs required)\n\n\nout_of_sample_test_SKUs\nList\nNone\nSKUs to be hold-out for testing\n\n\nlag_window_params\ndict | None\nNone\ndefault: {‘lag_window’: 0, ‘include_y’: False, ‘pre_calc’: True}\n\n\nnormalize_features\ndict | None\nNone\ndefault: {‘normalize’: True, ‘ignore_one_hot’: True}\n\n\nengineered_SKU_features\ndict\nNone\ndefault: [“mean_demand”, “std_demand”, “kurtosis_demand”, “skewness_demand”, “percentile_10_demand”, “percentile_30_demand”, “median_demand”, “percentile_70_demand”, “percentile_90_demand”, “inter_quartile_range”]\n\n\nuse_engineered_SKU_features\nbool\nFalse\nif engineered features shall be used\n\n\ninclude_non_available\nbool\nFalse\nif timestep/SKU combination where the SKU was not available for sale shall be included. If included, it will be used as feature, otherwise as mask.\n\n\ntrain_subset\nint\nNone\nif only a subset of SKUs is used for training. Will always contain in_sample_val_test_SKUs and then fills the rest with random SKUs\n\n\ntrain_subset_SKUs\nList\nNone\nif train_subset is set, specific SKUs can be provided\n\n\nmeta_learn_units\nbool\nFalse\nif units (SKUs) are trained in the batch dimension to meta-learn across SKUs\n\n\nlag_demand_normalization\nOptional\nstandard\nminmax, standard, no_normalization or None. If None, same demand_normalization\n\n\ndemand_normalization\nLiteral\nno_normalization\n‘standard’ or ‘minmax’\n\n\ndemand_unit_size\nfloat | None\nNone\nuse same convention as for other dataloaders and enviornments, but here only full decimal values are allowed\n\n\nprovide_additional_target\nbool\nFalse\nfollows ICL convention by providing actual demand to token, with the last token receiving 0\n\n\npermutate_inputs\nbool\nFalse\nif the inputs shall be permutated during training for meta-learning\n\n\nmax_feature_dim\nint | None\nNone\n\n\n\n\n\nrun_example = False\n\nif run_example:\n    from ddopai.datasets.kaggle_m5 import KaggleM5DatasetLoader\n\n    data_path = \"/Users/magnus/Documents/02_PhD/Reinforcement_Learning/general_purpose_drl/Newsvendor/kaggle_data\" # For testing purposes, please specify the path to the data on your machine\n    if data_path is not None:\n        loader = KaggleM5DatasetLoader(data_path, overwrite=False, product_as_feature=False)\n        demand, SKU_features, time_features, time_SKU_features, mask = loader.load_dataset()\n    \n    val_index_start = len(demand)-300\n    test_index_start = len(demand)-100\n\n    out_of_sample_val_SKUs = [\"HOBBIESit_1_002_CA_1\", \"HOBBIES_1_003_CA_1\"]\n    out_of_sample_test_SKUs = [\"HOBBIES_1_005_CA_1\", \"FOODS_3_819_WI_3\"]\n\n    dataloader = MultiShapeLoader(\n        demand.copy(),\n        SKU_features.copy(),\n        time_features.copy(),\n        time_SKU_features.copy(),\n        mask.copy(),\n        val_index_start=val_index_start,\n        test_index_start=test_index_start,\n        # in_sample_val_test_SKUs=[\"FOODS_3_825_WI_3\"],\n        out_of_sample_val_SKUs=out_of_sample_val_SKUs,\n        out_of_sample_test_SKUs=out_of_sample_test_SKUs,\n        lag_window_params = {'lag_window': 5, 'include_y': True, 'pre_calc': False},\n        # train_subset=300,\n        # train_subset_SKUs=[\"HOBBIES_1_001_CA_1\", \"HOBBIES_1_012_CA_1\"],\n        SKU_as_batch = True\n        )\n\n\n# dataloader.__getitem__(49844609) #986 with non-zero lag demand",
    "crumbs": [
      "Dataloaders",
      "Tabular dataloaders"
    ]
  },
  {
    "objectID": "10_dataloaders/distribution_loaders.html",
    "href": "10_dataloaders/distribution_loaders.html",
    "title": "Distribution-based dataloaders",
    "section": "",
    "text": "source",
    "crumbs": [
      "Dataloaders",
      "Distribution-based dataloaders"
    ]
  },
  {
    "objectID": "10_dataloaders/distribution_loaders.html#normaldistributiondataloader",
    "href": "10_dataloaders/distribution_loaders.html#normaldistributiondataloader",
    "title": "Distribution-based dataloaders",
    "section": "NormalDistributionDataLoader",
    "text": "NormalDistributionDataLoader\n\n NormalDistributionDataLoader (mean:float, std:float, num_units:int,\n                               truncated_low:int=0,\n                               truncated_high:int=None)\n\nA dataloader that generates a dataset of normally distributed values.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nmean\nfloat\n\n\n\n\nstd\nfloat\n\n\n\n\nnum_units\nint\n\n\n\n\ntruncated_low\nint\n0\n\n\n\ntruncated_high\nint\nNone\n\n\n\n\n\ndataloader = NormalDistributionDataLoader(mean=3, std=4, num_units=2)\n\nsample_X, sample_Y = dataloader[0]\nprint(\"sample:\", sample_X, sample_Y)\nprint(\"sample shape Y:\", sample_Y.shape)\n\n## The next print should give an error:\n#print(\"length:\", len(dataloader))\n\nsample: None [0. 0.]\nsample shape Y: (2,)\n\n\n\ndataloader.train()\ndataloader.val()\ndataloader.test()",
    "crumbs": [
      "Dataloaders",
      "Distribution-based dataloaders"
    ]
  },
  {
    "objectID": "90_datasets/default_datasets.html",
    "href": "90_datasets/default_datasets.html",
    "title": "Dataset loader",
    "section": "",
    "text": "We provide a range of synthetic and real-world datasets to enable reproducible research. Typically we have multiple datasets of the same dataset type (e.g., 16 multivariate datasets following an arma(10,10) process). The datasets are available in the releases of this repository. Below are automated functions that help to easily download those datasets. Three steps to load datasets:\n\nStep 1: Create a DatasetLoader object: datasetloader = DatasetLoader()\nStep 2: Check available dataset types: datasetloader.show_dataset_types(show_num_datasets_per_type=True)\nStep 3: Load a dataset: data = datasetloader.load_dataset(\"arma_10_10\", 1)) where the first string argument is the name of the dataset type and the second integer argument is the dataset number.",
    "crumbs": [
      "Datasets",
      "Dataset loader"
    ]
  },
  {
    "objectID": "90_datasets/default_datasets.html#info",
    "href": "90_datasets/default_datasets.html#info",
    "title": "Dataset loader",
    "section": "",
    "text": "We provide a range of synthetic and real-world datasets to enable reproducible research. Typically we have multiple datasets of the same dataset type (e.g., 16 multivariate datasets following an arma(10,10) process). The datasets are available in the releases of this repository. Below are automated functions that help to easily download those datasets. Three steps to load datasets:\n\nStep 1: Create a DatasetLoader object: datasetloader = DatasetLoader()\nStep 2: Check available dataset types: datasetloader.show_dataset_types(show_num_datasets_per_type=True)\nStep 3: Load a dataset: data = datasetloader.load_dataset(\"arma_10_10\", 1)) where the first string argument is the name of the dataset type and the second integer argument is the dataset number.",
    "crumbs": [
      "Datasets",
      "Dataset loader"
    ]
  },
  {
    "objectID": "90_datasets/default_datasets.html#helper-functions-to-load-datasets",
    "href": "90_datasets/default_datasets.html#helper-functions-to-load-datasets",
    "title": "Dataset loader",
    "section": "Helper functions to load datasets",
    "text": "Helper functions to load datasets\n\nsource\n\nload_data_from_directory\n\n load_data_from_directory (dir)\n\n\nsource\n\n\nunzip_file\n\n unzip_file (zip_file_path, output_dir, delete_zip_file=True)\n\n\nsource\n\n\ndownload_file_from_github\n\n download_file_from_github (url, output_path, token=None)\n\n\nsource\n\n\nget_asset_url\n\n get_asset_url (dataset_type, dataset_number, version='latest',\n                token=None)\n\n\nsource\n\n\nget_dataset_url\n\n get_dataset_url (dataset_type, dataset_number, release_tag, token=None)\n\n\nsource\n\n\nget_release_tag\n\n get_release_tag (dataset_type, version, token=None)\n\n\nsource\n\n\nget_all_release_tags\n\n get_all_release_tags (token=None)",
    "crumbs": [
      "Datasets",
      "Dataset loader"
    ]
  },
  {
    "objectID": "90_datasets/default_datasets.html#dataset-loader-class",
    "href": "90_datasets/default_datasets.html#dataset-loader-class",
    "title": "Dataset loader",
    "section": "Dataset Loader class",
    "text": "Dataset Loader class\n\nsource",
    "crumbs": [
      "Datasets",
      "Dataset loader"
    ]
  },
  {
    "objectID": "90_datasets/default_datasets.html#datasetloader",
    "href": "90_datasets/default_datasets.html#datasetloader",
    "title": "Dataset loader",
    "section": "DatasetLoader",
    "text": "DatasetLoader\n\n DatasetLoader ()\n\nClass to load datasets from the GitHub repository.\n\nsource\n\nDatasetLoader.show_dataset_types\n\n DatasetLoader.show_dataset_types (show_num_datasets_per_type=False)\n\nShow an overview of all dataset types available in the repository.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nshow_num_datasets_per_type\nbool\nFalse\nWhether to show the number of datasets per type\n\n\n\n\nsource\n\n\nDatasetLoader.load_dataset\n\n DatasetLoader.load_dataset (dataset_type:str, dataset_number:int,\n                             overwrite:bool=False, version:str='latest',\n                             token:str=None)\n\nLoad a dataset from the GitHub repository.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndataset_type\nstr\n\n\n\n\ndataset_number\nint\n\n\n\n\noverwrite\nbool\nFalse\nWhether to overwrite the dataset if it already exists\n\n\nversion\nstr\nlatest\nWhich version of the dataset to load, “latest” or a specific version,\n\n\ntoken\nstr\nNone\nGitHub token to enable more requests (otherwise limited to 60 requests per hour)\n\n\n\nExample usage:\n\ndatasetloader = DatasetLoader()\ndatasetloader.show_dataset_types()\n\nUnivariate datasets:\nbakery\n\nMultivariate datasets:\narma_10_10\narma_2_2\nar_1\n\n\n\ndownload_test = True\n\nif download_test:\n    data = datasetloader.load_dataset(\"bakery\", 1) #arma_10_10 bakery\n    X = data[\"data_raw_features\"]\n    y = data[\"data_raw_target\"]\n    print(X.shape, y.shape)\n\n(127575, 13) (127575, 1)\n\n\n\n\n\n\n\n\n\n\n\n\ndate\nweekday\nmonth\nyear\nis_schoolholiday\nis_holiday\nis_holiday_next2days\nstore\nproduct\nrain\ntemperature\npromotion_currentweek\npromotion_lastweek\n\n\n\n\n0\n2016-01-02\nFRI\nJAN\n2016\n1\n0\n0\n2\n101\n11.9\n2.1\n0\n0\n\n\n1\n2016-01-03\nSAT\nJAN\n2016\n1\n0\n0\n2\n101\n4.1\n2.6\n0\n0\n\n\n2\n2016-01-04\nSUN\nJAN\n2016\n1\n0\n1\n2\n101\n7.9\n3.2\n0\n0\n\n\n3\n2016-01-05\nMON\nJAN\n2016\n1\n0\n1\n2\n101\n3.5\n3.1\n0\n0\n\n\n4\n2016-01-06\nTUE\nJAN\n2016\n1\n1\n0\n2\n101\n0.1\n4.1\n0\n0\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n127570\n2019-04-26\nTHU\nAPR\n2019\n1\n0\n0\n71\n110\n4.9\n8.0\n0\n0\n\n\n127571\n2019-04-27\nFRI\nAPR\n2019\n1\n0\n0\n71\n110\n6.1\n7.8\n0\n0\n\n\n127572\n2019-04-28\nSAT\nAPR\n2019\n0\n0\n0\n71\n110\n1.0\n6.5\n0\n0\n\n\n127573\n2019-04-29\nSUN\nAPR\n2019\n0\n0\n1\n71\n110\n9.1\n6.5\n0\n0\n\n\n127574\n2019-04-30\nMON\nAPR\n2019\n0\n0\n1\n71\n110\n0.0\n10.3\n0\n0\n\n\n\n\n127575 rows × 13 columns",
    "crumbs": [
      "Datasets",
      "Dataset loader"
    ]
  },
  {
    "objectID": "90_datasets/meta_datasetloaders_utils.html",
    "href": "90_datasets/meta_datasetloaders_utils.html",
    "title": "Utils for meta-learning dataset loaders",
    "section": "",
    "text": "source\n\ngetdatasetloader\n\n getdatasetloader (dataset)"
  },
  {
    "objectID": "40_experiments/meta_experiment_functions.html",
    "href": "40_experiments/meta_experiment_functions.html",
    "title": "Meta experiment functions",
    "section": "",
    "text": "Some warnings are irrelevant for this library\n\n\nsource\n\n\n\n set_warnings (logging_level)\n\nSet warnings to be ignored for the given logging level or higher.",
    "crumbs": [
      "Experiment functions",
      "Meta experiment functions"
    ]
  },
  {
    "objectID": "40_experiments/meta_experiment_functions.html#warnings",
    "href": "40_experiments/meta_experiment_functions.html#warnings",
    "title": "Meta experiment functions",
    "section": "",
    "text": "Some warnings are irrelevant for this library\n\n\nsource\n\n\n\n set_warnings (logging_level)\n\nSet warnings to be ignored for the given logging level or higher.",
    "crumbs": [
      "Experiment functions",
      "Meta experiment functions"
    ]
  },
  {
    "objectID": "40_experiments/meta_experiment_functions.html#load-files-and-set-up-tracking",
    "href": "40_experiments/meta_experiment_functions.html#load-files-and-set-up-tracking",
    "title": "Meta experiment functions",
    "section": "Load files and set-up tracking",
    "text": "Load files and set-up tracking\n\nFist part of experiment: Log into wandb and load config files\n\n\nsource\n\nprep_experiment\n\n prep_experiment (project_name:str,\n                  libraries_to_track:List[str]=['ddopai'],\n                  config_train_name:str='config_train',\n                  config_agent_name:str='config_agent',\n                  config_env_name:str='config_env')\n\nFirst stpes to always execute when starting an experiment (using wandb for tracking)\n\nsource\n\n\ninit_wandb\n\n init_wandb (project_name:str)\n\ninit wandb\n\n\n\n\nType\nDetails\n\n\n\n\nproject_name\nstr\n\n\n\n\n\nsource\n\n\ntrack_libraries_and_git\n\n track_libraries_and_git (libraries_to_track:List[str],\n                          tracking:bool=True, tracking_tool='wandb')\n\nTrack the versions of the libraries and the git hash of the repository.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nlibraries_to_track\nList\n\n\n\n\ntracking\nbool\nTrue\n\n\n\ntracking_tool\nstr\nwandb\nCurrenty only wandb is supported\n\n\nReturns\nNone\n\n\n\n\n\n\nsource\n\n\nimport_config\n\n import_config (filename:str, path:str=None)\n\nImport a config file in YAML format\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfilename\nstr\n\nName of the file, must be a yaml file\n\n\npath\nstr\nNone\nOptional path to the file if it is not in the current directory\n\n\nReturns\nDict\n\n\n\n\n\n\nsource\n\n\ntransfer_additional_target_to_env\n\n transfer_additional_target_to_env (config_env:Dict, config_agent:Dict)\n\nTransfer the lag window from the agent configuration to the environment configuration\n\n\n\n\nType\nDetails\n\n\n\n\nconfig_env\nDict\n\n\n\nconfig_agent\nDict\n\n\n\nReturns\nNone\n\n\n\n\n\nsource\n\n\ntransfer_lag_window_to_env\n\n transfer_lag_window_to_env (config_env:Dict, config_agent:Dict)\n\nTransfer the lag window from the agent configuration to the environment configuration\n\n\n\n\nType\nDetails\n\n\n\n\nconfig_env\nDict\n\n\n\nconfig_agent\nDict\n\n\n\nReturns\nNone",
    "crumbs": [
      "Experiment functions",
      "Meta experiment functions"
    ]
  },
  {
    "objectID": "40_experiments/meta_experiment_functions.html#import-data",
    "href": "40_experiments/meta_experiment_functions.html#import-data",
    "title": "Meta experiment functions",
    "section": "Import data",
    "text": "Import data\n\nImport data from the ddop package\n\n\nsource\n\nget_ddop_data\n\n get_ddop_data (config_env:Dict, overwrite:bool=False)\n\nStandard function to load data provided by the ddop package\n\nsource\n\n\ndownload_data\n\n download_data (config_env:Dict, overwrite:bool=False)\n\nDownload standard dataset from ddop repository using the DatasetLoader class\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nconfig_env\nDict\n\n\n\n\noverwrite\nbool\nFalse\n\n\n\nReturns\nTuple\n\n\n\n\n\n\nsource\n\n\nset_indices\n\n set_indices (config_env:Dict, X:numpy.ndarray)\n\nSet the indices for the validation and test set\n\n\n\n\nType\nDetails\n\n\n\n\nconfig_env\nDict\n\n\n\nX\nndarray\n\n\n\nReturns\nTuple",
    "crumbs": [
      "Experiment functions",
      "Meta experiment functions"
    ]
  },
  {
    "objectID": "40_experiments/meta_experiment_functions.html#set-up-environment",
    "href": "40_experiments/meta_experiment_functions.html#set-up-environment",
    "title": "Meta experiment functions",
    "section": "Set up environment",
    "text": "Set up environment\n\nSome functions to set-up the environment\n\n\nsource\n\nset_up_env\n\n set_up_env (env_class, raw_data:Tuple, val_index_start:int,\n             test_index_start:int, config_env:Dict, postprocessors:List)\n\nSet up the environment\n\n\n\n\nType\nDetails\n\n\n\n\nenv_class\n\n\n\n\nraw_data\nTuple\n\n\n\nval_index_start\nint\n\n\n\ntest_index_start\nint\n\n\n\nconfig_env\nDict\n\n\n\npostprocessors\nList\n\n\n\nReturns\nobject",
    "crumbs": [
      "Experiment functions",
      "Meta experiment functions"
    ]
  },
  {
    "objectID": "40_experiments/meta_experiment_functions.html#set-up-training",
    "href": "40_experiments/meta_experiment_functions.html#set-up-training",
    "title": "Meta experiment functions",
    "section": "Set up training",
    "text": "Set up training\n\nSome functions to set-up the environment\n\n\nsource\n\nset_up_earlystoppinghandler\n\n set_up_earlystoppinghandler (config_train:Dict)\n\nSet up the early stopping handler\n\n\n\n\nType\nDetails\n\n\n\n\nconfig_train\nDict\n\n\n\nReturns\nobject",
    "crumbs": [
      "Experiment functions",
      "Meta experiment functions"
    ]
  },
  {
    "objectID": "40_experiments/meta_experiment_functions.html#testing",
    "href": "40_experiments/meta_experiment_functions.html#testing",
    "title": "Meta experiment functions",
    "section": "Testing",
    "text": "Testing\n\nSome functions to test the final model.\n\n\nsource\n\nprep_and_run_test\n\n prep_and_run_test (agent, environment, agent_dir:str=None,\n                    save_dataset:bool=True, save_features:bool=False,\n                    dataset_dir:str=None, eval_step_info=False,\n                    tracking='wandb')\n\nTest the agent in the environment.",
    "crumbs": [
      "Experiment functions",
      "Meta experiment functions"
    ]
  },
  {
    "objectID": "40_experiments/meta_experiment_functions.html#clean-up",
    "href": "40_experiments/meta_experiment_functions.html#clean-up",
    "title": "Meta experiment functions",
    "section": "Clean-up",
    "text": "Clean-up\n\nFunction to clean-up the experiment script\n\n\nsource\n\nclean_up\n\n clean_up (agent, environment)\n\nClean up agent and environment to free up GPU memory",
    "crumbs": [
      "Experiment functions",
      "Meta experiment functions"
    ]
  },
  {
    "objectID": "40_experiments/meta_experiment_functions.html#helper-functions",
    "href": "40_experiments/meta_experiment_functions.html#helper-functions",
    "title": "Meta experiment functions",
    "section": "Helper functions",
    "text": "Helper functions\n\nSome functions that are needed to run an experiment\n\n\nsource\n\nselect_agent\n\n select_agent (agent_name:str)\n\nSelect an agent class from a list of agent names and return the class\n\n\n\n\nType\nDetails\n\n\n\n\nagent_name\nstr\n\n\n\nReturns\ntype\n\n\n\n\n\nsource\n\n\nmerge_with_namespace\n\n merge_with_namespace (target_dict, source_dict, target_dict_name)\n\n*Merge source_dict into target_dict, using the keys as namespaces. For example, if target_dict_name is “agent”, the key “agent-epsilon” in source_dict will be merged into target_dict[“epsilon”]. The function is to merge hyperparameters from a config file with the default hyperparameters from the yaml files\nArgs: target_dict (dict): Target dictionary source_dict (dict): Source dictionary target_dict_name (str): Name of the target dictionary\nReturns: dict: Merged dictionary*",
    "crumbs": [
      "Experiment functions",
      "Meta experiment functions"
    ]
  },
  {
    "objectID": "30_agents/60_approximators/approximators.html",
    "href": "30_agents/60_approximators/approximators.html",
    "title": "Approximators",
    "section": "",
    "text": "source\n\nBaseModule\n\n BaseModule ()\n\n*Base class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self) -&gt; None:\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool*\n\nsource\n\n\nLinearModel\n\n LinearModel (input_size:int, output_size:int, relu_output:bool=False)\n\nLinear regression model\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ninput_size\nint\n\nnumber of features\n\n\noutput_size\nint\n\nnumber of outputs/actions\n\n\nrelu_output\nbool\nFalse\nwhether to apply ReLU activation to the output\n\n\n\n\nsource\n\n\nMLP\n\n MLP (input_size:int, output_size:int, hidden_layers:list,\n      drop_prob:float=0.0, batch_norm:bool=False, relu_output:bool=False)\n\nMultilayer perceptron model\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ninput_size\nint\n\nnumber of features\n\n\noutput_size\nint\n\nnumber of outputs/actions\n\n\nhidden_layers\nlist\n\nlist of number of neurons in each hidden layer\n\n\ndrop_prob\nfloat\n0.0\ndropout probability\n\n\nbatch_norm\nbool\nFalse\nwhether to apply batch normalization\n\n\nrelu_output\nbool\nFalse\nwhether to apply ReLU activation to the output\n\n\n\n\nsource\n\n\nTransformer\n\n Transformer (input_size:int, output_size:int, max_context_length:int=128,\n              n_layer:int=3, n_head:int=8, n_embd_per_head:int=32,\n              rope_scaling:Optional[Dict]=None, min_multiple=256,\n              gating=True, drop_prob:float=0.0, final_activation:Literal['\n              relu','sigmoid','tanh','elu','leakyrelu','identity']='identi\n              ty')\n\nMultilayer perceptron model\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ninput_size\nint\n\nnumber of (time steps, features)\n\n\noutput_size\nint\n\nnumber of outputs/actions\n\n\nmax_context_length\nint\n128\nmaximum context lenght during inference\n\n\nn_layer\nint\n3\nnumber of layers in the transformer\n\n\nn_head\nint\n8\nnumber of heads per layer\n\n\nn_embd_per_head\nint\n32\nnumber of embedding per head\n\n\nrope_scaling\nOptional\nNone\nwhether to use rope scaling, not implemented yet\n\n\nmin_multiple\nint\n256\nminimum multiple for neurons in the MLP block of the transformer\n\n\ngating\nbool\nTrue\nWhether to apply the gating mechanism from the original Llama model (used in LagLlama)\n\n\ndrop_prob\nfloat\n0.0\ndropout probability\n\n\nfinal_activation\nLiteral\nidentity\nfinal activation function\n\n\n\n\nsource\n\n\napply_rotary_pos_emb\n\n apply_rotary_pos_emb (q, k, cos, sin, position_ids)\n\n\nsource\n\n\nrotate_half\n\n rotate_half (x)\n\nRotates half the hidden dims of the input.\n\nsource\n\n\nLlamaRotaryEmbedding\n\n LlamaRotaryEmbedding (dim, max_position_embeddings=2048, base=10000,\n                       device=None)\n\nRotary positional embeddings (RoPE) based on https://arxiv.org/abs/2104.09864 Code following the implementation in https://github.com/time-series-foundation-models/lag-llama\n\nsource\n\n\nfind_multiple\n\n find_multiple (n:int, k:int)\n\n\nsource\n\n\nCausalSelfAttention\n\n CausalSelfAttention (n_embd_per_head, n_head, block_size, dropout)\n\nCauseal self-attention module Based on the implementation in https://github.com/time-series-foundation-models/lag-llama, without usage of kv_cache since we always make a prediction for only the next step\n\nsource\n\n\nMLP_block\n\n MLP_block (n_embd_per_head, n_head, min_multiple=256, gating=True)\n\n*Base class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self) -&gt; None:\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool*\n\nsource\n\n\nRMSNorm\n\n RMSNorm (size:int, dim:int=-1, eps:float=1e-05)\n\n*Root Mean Square Layer Normalization as implemented in https://github.com/time-series-foundation-models/lag-llama.\nDerived from https://github.com/bzhangGo/rmsnorm/blob/master/rmsnorm_torch.py. BSD 3-Clause License: https://github.com/bzhangGo/rmsnorm/blob/master/LICENSE.*\n\nsource\n\n\nBlock\n\n Block (n_embd_per_head, n_head, block_size, dropout, min_multiple=256,\n        gating=True)\n\n*Base class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self) -&gt; None:\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool*",
    "crumbs": [
      "Agents",
      "Approximators",
      "Approximators"
    ]
  },
  {
    "objectID": "30_agents/obsprocessors.html",
    "href": "30_agents/obsprocessors.html",
    "title": "Obsprocessors",
    "section": "",
    "text": "source",
    "crumbs": [
      "Agents",
      "Obsprocessors"
    ]
  },
  {
    "objectID": "30_agents/obsprocessors.html#flattentimedimnumpy",
    "href": "30_agents/obsprocessors.html#flattentimedimnumpy",
    "title": "Obsprocessors",
    "section": "FlattenTimeDimNumpy",
    "text": "FlattenTimeDimNumpy\n\n FlattenTimeDimNumpy (allow_2d:Optional[bool]=False,\n                      batch_dim_included:Optional[bool]=True)\n\nPreprocessor to flatten the time and feature dimension of the input. Used, e.g., to convert time-series data for models that cannot process a time dimension such as MLPs or Regression models.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nallow_2d\nOptional\nFalse\n\n\n\nbatch_dim_included\nOptional\nTrue\n\n\n\n\n\nsource\n\nFlattenTimeDimNumpy.check_input\n\n FlattenTimeDimNumpy.check_input (input:numpy.ndarray)\n\nCheck that the input is a Numpy array with the correct shape.\n\n\n\n\nType\nDetails\n\n\n\n\ninput\nndarray\n\n\n\n\n\nsource\n\n\nFlattenTimeDimNumpy.__call__\n\n FlattenTimeDimNumpy.__call__ (input:numpy.ndarray)\n\nProcess the input array by keeping the batch dimension and flattening the time and feature dimensions.\n\nsource\n\n\nConvertDictSpace\n\n ConvertDictSpace (keep_time_dim:Optional[bool]=False,\n                   hybrid_space_params:Optional[Dict]=None)\n\n*A utility class to process a dictionary of numpy arrays, with options to preserve or flatten the time dimension.\nNote, this class is only used to preprocess output from the environment without batch dimension.*\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nkeep_time_dim\nOptional\nFalse\nIf time timension should be flattened as well.\n\n\nhybrid_space_params\nOptional\nNone\ndict with keys “time” that is a list of observation keys that should keep the time dimension.\n\n\n\n\nsource\n\n\nAddParamsToFeaturesLEGACY\n\n AddParamsToFeaturesLEGACY (environment:object,\n                            keep_time_dim:Optional[bool]=False,\n                            hybrid:Optional[bool]=False,\n                            receive_batch_dim:Optional[bool]=False)\n\nA utility class to process a dictionary of numpy arrays, with options to preserve or flatten the time dimension. # TODO: Currently is mixes too many cases like batched input, hybrid input etc. Seperate into more specific obsprocessors.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nenvironment\nobject\n\nThe environment object, needed to check if val or train mode,\n\n\nkeep_time_dim\nOptional\nFalse\nIf time timension should be flattened as well.\n\n\nhybrid\nOptional\nFalse\nIf the param dim should be added as separate vector or concatenated to the features.\n\n\nreceive_batch_dim\nOptional\nFalse\nIf the input contains a batch dimension.\n\n\n\n\nsource\n\n\nAddParamsToFeatures\n\n AddParamsToFeatures (environment:object,\n                      keep_time_dim:Optional[bool]=False,\n                      receive_batch_dim:Optional[bool]=False)\n\nA utility class to process a dictionary of numpy arrays (from dict space), with options to preserve or flatten the time dimension. It always adds the parameters to the appropriate dimension. For composite spaces (partially time-series, partially not), use the separate AddParamsToFeaturesComposite class.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nenvironment\nobject\n\nThe environment object, needed to check if val or train mode,\n\n\nkeep_time_dim\nOptional\nFalse\nIf time timension should be flattened as well.\n\n\nreceive_batch_dim\nOptional\nFalse\nIf the input contains a batch dimension.",
    "crumbs": [
      "Agents",
      "Obsprocessors"
    ]
  },
  {
    "objectID": "30_agents/40_base_agents/base_agents.html",
    "href": "30_agents/40_base_agents/base_agents.html",
    "title": "Base agents",
    "section": "",
    "text": "source",
    "crumbs": [
      "Agents",
      "Base agents"
    ]
  },
  {
    "objectID": "30_agents/40_base_agents/base_agents.html#baseagent",
    "href": "30_agents/40_base_agents/base_agents.html#baseagent",
    "title": "Base agents",
    "section": "BaseAgent",
    "text": "BaseAgent\n\n BaseAgent (environment_info:ddopai.utils.MDPInfo,\n            obsprocessors:list[object]|None=None,\n            agent_name:str|None=None, receive_batch_dim:bool=False)\n\nBase class for all agents to enforce a common interface. See below for more detailed description of the requriements.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nenvironment_info\nMDPInfo\n\n\n\n\nobsprocessors\nlist[object] | None\nNone\ndefault is empty list\n\n\nagent_name\nstr | None\nNone\n\n\n\nreceive_batch_dim\nbool\nFalse\n\n\n\n\n\nImportant notes:\nAgents are, next to the environments, the core element of this library. The agents are the algorithms that take actions in the environment. They can be any type of algorithms ranging from optimization, supervised learning to reinforcement learning and any combination. Key for all the different agents to work is a common interface that allows them to interact with the environment.\nDraw action:\n\nThe draw_action function is the main interface with the environment. It receives an observation as Numpy array and returns an action as Numpy array. The function draw_action is defined in the [`BaseAgent`](https://opimwue.github.io/ddopai/30_agents/40_base_agents/base_agents.html#baseagent) and should not be overwritten as it properly applies pre- and post-processing (see below).\nAgents always expect the observation to be of shape (batch_size, observation_dim) or (batch_size, time_dim, observation_dim) to allow batch-processing during training. Most environment do not have a batch dimension as they apply the step function to a single observation. Hence, the agent will by default add an extra dimension to the observation. If this is not desired, the agent has an attribute “receive_batch_dim” that can be set to True to tell the agent that the observation already has a batch dimension.\nTo create an agent, the function draw_action_ (note the underscore!) needs to be defined that gets the pre-processed observation and returns the action for post-processing. This function should be overwritten in the derived class.\n\nobservation pre-processors and action post-processors:\n\nSometimes, it is necessary to process the observartion before giving it to the agent (e.g., changing shape) or to process the action before giving it to the environment (e.g., rounding). To ensure compatibility with mushroom_rl, the pre-processors sit with the agent (they must be added to the agent and are applied in the agent’s draw_action() method). The post-processors sit with the environment and are applied in the environment’s step() method.\nTo differenciate the pre-processors here from the pre-processors used directly inside mushroom_rl, we call them obsprocessors, short for observation pre-processors.\nDuring definition, one can already add the obsprocessors as lists (to the argument obsprocessors). After instantiation, processors are to be added using the add_obsprocessor method.\nNote that processors are applied in the order they are added.\n\nTraining:\n\nThe [`run_experiment`](https://opimwue.github.io/ddopai/40_experiments/experiment_functions.html#run_experiment)function in this library currently supports three types of training processes:\n\ntrain_directly: The agent is trained by calling agent.fit(X, Y) directly. In this case, the agent must have a fit function that takes the input and target data.\ntrain_epochs: The agent is iteratively trained on the training data (e.g., via SGD). In this case, the function fit_epoch must be implemented. fit_epoch does not get any argument, rather the dataloader from the environment needs to be given to the agent during initialization. The agent will then call the dataloader interatively to get the training data.\nenv_interaction: The agent is trained by interacting with the environment (e.g., like all reinforcement learning agents). This case build on the Core class from MushroomRL.\n\n\nLoading and saving:\n\nAll agents must implement a save and load function that allows to save and load the agent’s parameters. See the Newsvendor ERM and (w)SAA agents for examples of different ways to save and load agents.\n\nDymamic class loading:\n\nThis package allows to load agents dynamically with the [`select_agent`](https://opimwue.github.io/ddopai/40_experiments/meta_experiment_functions.html#select_agent) function that takes a string as input and returns the corresponding agent class. When creating new agents, make sure to add them to 10_AGENT_CLASSES.ipynb under the base agents folder with an appropriate name.\n\n\nsource\n\n\nBaseAgent.draw_action\n\n BaseAgent.draw_action (observation:numpy.ndarray)\n\nMain interfrace to the environemnt. Applies preprocessors to the observation. Internal logic of the agent to be implemented in draw_action_ method.\n\n\n\n\nType\nDetails\n\n\n\n\nobservation\nndarray\n\n\n\nReturns\nndarray\n\n\n\n\n\nsource\n\n\nBaseAgent.draw_action_\n\n BaseAgent.draw_action_ (observation:numpy.ndarray)\n\nGenerate an action based on the observation - this is the core method that needs to be implemented by all agents.\n\n\n\n\nType\nDetails\n\n\n\n\nobservation\nndarray\n\n\n\nReturns\nndarray\n\n\n\n\n\nsource\n\n\nBaseAgent.add_obsprocessor\n\n BaseAgent.add_obsprocessor (obsprocessor:object)\n\nAdd a preprocessor to the agent\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nobsprocessor\nobject\npre-processor object that can be called via the “call” method\n\n\n\n\nsource\n\n\nBaseAgent.train\n\n BaseAgent.train ()\n\nSet the internal state of the agent to train\n\nsource\n\n\nBaseAgent.eval\n\n BaseAgent.eval ()\n\nSet the internal state of the agent to eval. Note that for agents we do not differentiate between val and test modes.\n\nsource\n\n\nBaseAgent.add_batch_dim\n\n BaseAgent.add_batch_dim (input:numpy.ndarray|dict[str,numpy.ndarray])\n\nAdd a batch dimension to the input array if it doesn’t already have one. This is necessary because most environments do not have a batch dimension, but agents typically expect one. If the environment does have a batch dimension, the agent can set the receive_batch_dim attribute to True to skip this step.\n\n\n\n\nType\nDetails\n\n\n\n\ninput\nnumpy.ndarray | dict[str, numpy.ndarray]\n\n\n\nReturns\nnumpy.ndarray | dict[str, numpy.ndarray]\n\n\n\n\n\nsource\n\n\nBaseAgent.save\n\n BaseAgent.save ()\n\nSave the agent’s parameters to a file.\n\nsource\n\n\nBaseAgent.load\n\n BaseAgent.load ()\n\nLoad the agent’s parameters from a file.\n\nsource\n\n\nBaseAgent.update_model_params\n\n BaseAgent.update_model_params (default_params:dict, custom_params:dict)\n\noverride default parameters with custom parameters in a dictionary\n\n\n\n\nType\nDetails\n\n\n\n\ndefault_params\ndict\n\n\n\ncustom_params\ndict\n\n\n\nReturns\ndict\n\n\n\n\n\nsource\n\n\nBaseAgent.convert_to_numpy_array\n\n BaseAgent.convert_to_numpy_array (input:Union[numpy.ndarray,List,float,in\n                                   t,ddopai.utils.Parameter,NoneType])\n\nconvert input to numpy array or keep as Parameter\n\n\n\n\nType\nDetails\n\n\n\n\ninput\nUnion",
    "crumbs": [
      "Agents",
      "Base agents"
    ]
  },
  {
    "objectID": "30_agents/51_RL_agents/ppo_agents.html",
    "href": "30_agents/51_RL_agents/ppo_agents.html",
    "title": "PPO agents",
    "section": "",
    "text": "source\n\nPPOAgent\n\n PPOAgent (environment_info:ddopai.utils.MDPInfo,\n           learning_rate_actor:float=0.0003,\n           learning_rate_critic:float|None=None, batch_size:int=64,\n           hidden_layers:List=None, activation:str='relu',\n           std_0:float=0.1, n_epochs_policy:int=4, eps_ppo:float=0.2,\n           lam:float=0.95, ent_coeff:float=0.0, n_steps_per_fit=1000,\n           drop_prob:float=0.0, batch_norm:bool=False,\n           init_method:str='xavier_uniform', optimizer:str='Adam',\n           loss:str='MSE', obsprocessors:list|None=None, device:str='cpu',\n           agent_name:str|None='SAC')\n\nXXX\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nenvironment_info\nMDPInfo\n\n\n\n\nlearning_rate_actor\nfloat\n0.0003\n\n\n\nlearning_rate_critic\nfloat | None\nNone\nIf none, then it is set to learning_rate_actor\n\n\nbatch_size\nint\n64\n\n\n\nhidden_layers\nList\nNone\nif None, then default is [64, 64]\n\n\nactivation\nstr\nrelu\n“relu”, “sigmoid”, “tanh”, “leakyrelu”, “elu”\n\n\nstd_0\nfloat\n0.1\ntau: float = 0.005,\n\n\nn_epochs_policy\nint\n4\n\n\n\neps_ppo\nfloat\n0.2\n\n\n\nlam\nfloat\n0.95\n\n\n\nent_coeff\nfloat\n0.0\n\n\n\nn_steps_per_fit\nint\n1000\n\n\n\ndrop_prob\nfloat\n0.0\n\n\n\nbatch_norm\nbool\nFalse\n\n\n\ninit_method\nstr\nxavier_uniform\n“xavier_uniform”, “xavier_normal”, “he_normal”, “he_uniform”, “normal”, “uniform”\n\n\noptimizer\nstr\nAdam\n“Adam” or “SGD” or “RMSprop”\n\n\nloss\nstr\nMSE\ncurrently only MSE is supported\n\n\nobsprocessors\nlist | None\nNone\ndefault: []\n\n\ndevice\nstr\ncpu\n“cuda” or “cpu”\n\n\nagent_name\nstr | None\nSAC\n\n\n\n\n\nfrom ddopai.envs.inventory.single_period import NewsvendorEnv\nfrom ddopai.dataloaders.tabular import XYDataLoader\nfrom ddopai.experiments.experiment_functions import run_experiment, test_agent\n\n\nval_index_start = 8000 #90_000\ntest_index_start = 9000 #100_000\n\nX = np.random.standard_normal((10000, 2))\nY = np.random.standard_normal((10000, 1))\nY += 2*X[:,0].reshape(-1, 1) + 3*X[:,1].reshape(-1, 1)\nY = X[:,0].reshape(-1, 1)\n# truncate Y at 0:\nY = np.maximum(Y, 0)\n# normalize Y max to 1\nY = Y/np.max(Y)\n\nprint(np.max(Y))\n\nprint(X.shape, Y.shape)\n\nclip_action = ClipAction(0., 1.)\n\ndataloader = XYDataLoader(X, Y, val_index_start, test_index_start, lag_window_params =  {'lag_window': 0, 'include_y': False, 'pre_calc': True})\n\nenvironment = NewsvendorEnv(\n    dataloader = dataloader,\n    underage_cost = 0.42857,\n    overage_cost = 1.0,\n    gamma = 0.999,\n    horizon_train = 365,\n    q_bound_high = 1.0,\n    q_bound_low = -0.1,\n    postprocessors = [clip_action],\n)\n\nagent = PPOAgent(environment.mdp_info,\n                obsprocessors = None,      # default: []\n                device=\"cpu\", # \"cuda\" or \"cpu\"\n)\n\nenvironment.test()\nagent.eval()\n\nR, J = test_agent(agent, environment)\n\nprint(R, J)\n\nenvironment.train()\nagent.train()\nenvironment.print=False\n\n# run_experiment(agent, environment, n_epochs=50, n_steps=1000, run_id = \"test\", save_best=True, print_freq=1) # fit agent via run_experiment function\n\nenvironment.test()\nagent.eval()\n\nR, J = test_agent(agent, environment)\n\nprint(R, J)\n\n1.0\n(10000, 2) (10000, 1)\n\n\n/Users/magnus/miniforge3/envs/inventory_gym_2/lib/python3.11/site-packages/gymnasium/spaces/box.py:130: UserWarning: WARN: Box bound precision lowered by casting to float32\n  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\nINFO:root:Actor network:\n/Users/magnus/miniforge3/envs/inventory_gym_2/lib/python3.11/site-packages/torchinfo/torchinfo.py:462: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  action_fn=lambda data: sys.getsizeof(data.storage()),\n\n\n==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nMLPActor                                 [1, 1]                    --\n├─Sequential: 1-1                        [1, 1]                    --\n│    └─Linear: 2-1                       [1, 64]                   192\n│    └─ReLU: 2-2                         [1, 64]                   --\n│    └─Dropout: 2-3                      [1, 64]                   --\n│    └─Linear: 2-4                       [1, 64]                   4,160\n│    └─ReLU: 2-5                         [1, 64]                   --\n│    └─Dropout: 2-6                      [1, 64]                   --\n│    └─Linear: 2-7                       [1, 1]                    65\n│    └─Identity: 2-8                     [1, 1]                    --\n==========================================================================================\nTotal params: 4,417\nTrainable params: 4,417\nNon-trainable params: 0\nTotal mult-adds (M): 0.00\n==========================================================================================\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.00\nParams size (MB): 0.02\nEstimated Total Size (MB): 0.02\n==========================================================================================\n\n\nINFO:root:Critic network:\n\n\n==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nMLPState                                 [1, 1]                    --\n├─Sequential: 1-1                        [1, 1]                    --\n│    └─Linear: 2-1                       [1, 64]                   192\n│    └─ReLU: 2-2                         [1, 64]                   --\n│    └─Dropout: 2-3                      [1, 64]                   --\n│    └─Linear: 2-4                       [1, 64]                   4,160\n│    └─ReLU: 2-5                         [1, 64]                   --\n│    └─Dropout: 2-6                      [1, 64]                   --\n│    └─Linear: 2-7                       [1, 1]                    65\n│    └─Identity: 2-8                     [1, 1]                    --\n==========================================================================================\nTotal params: 4,417\nTrainable params: 4,417\nNon-trainable params: 0\nTotal mult-adds (M): 0.00\n==========================================================================================\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.00\nParams size (MB): 0.02\nEstimated Total Size (MB): 0.02\n==========================================================================================\n-44.039980104932894 -28.64890791879266\n-44.039980104932894 -28.64890791879266",
    "crumbs": [
      "Agents",
      "Reinforcement Learning agents",
      "PPO agents"
    ]
  },
  {
    "objectID": "30_agents/51_RL_agents/sac_agents.html",
    "href": "30_agents/51_RL_agents/sac_agents.html",
    "title": "SAC agents",
    "section": "",
    "text": "source\n\nSACBaseAgent\n\n SACBaseAgent (environment_info:ddopai.utils.MDPInfo,\n               learning_rate_actor:float=0.0003,\n               learning_rate_critic:float|None=None,\n               initial_replay_size:int=64, max_replay_size:int=50000,\n               batch_size:int=64, warmup_transitions:int=100,\n               lr_alpha:float=0.0003, tau:float=0.005,\n               log_std_min:float=-20.0, log_std_max:float=2.0,\n               use_log_alpha_loss=False, target_entropy:float|None=None,\n               drop_prob:float=0.0, batch_norm:bool=False,\n               init_method:str='xavier_uniform', optimizer:str='Adam',\n               loss:str='MSE', obsprocessors:list|None=None,\n               device:str='cpu', agent_name:str|None='SAC',\n               network_actor_mu_params:dict=None,\n               network_actor_sigma_params:dict=None,\n               network_critic_params:dict=None)\n\nBase agent for the Soft Actor-Critic (SAC) algorithm.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nenvironment_info\nMDPInfo\n\n\n\n\nlearning_rate_actor\nfloat\n0.0003\n\n\n\nlearning_rate_critic\nfloat | None\nNone\nIf none, then it is set to learning_rate_actor\n\n\ninitial_replay_size\nint\n64\n\n\n\nmax_replay_size\nint\n50000\n\n\n\nbatch_size\nint\n64\n\n\n\nwarmup_transitions\nint\n100\n\n\n\nlr_alpha\nfloat\n0.0003\n\n\n\ntau\nfloat\n0.005\n\n\n\nlog_std_min\nfloat\n-20.0\n\n\n\nlog_std_max\nfloat\n2.0\n\n\n\nuse_log_alpha_loss\nbool\nFalse\n\n\n\ntarget_entropy\nfloat | None\nNone\n\n\n\ndrop_prob\nfloat\n0.0\n\n\n\nbatch_norm\nbool\nFalse\n\n\n\ninit_method\nstr\nxavier_uniform\n“xavier_uniform”, “xavier_normal”, “he_normal”, “he_uniform”, “normal”, “uniform”\n\n\noptimizer\nstr\nAdam\n“Adam” or “SGD” or “RMSprop”\n\n\nloss\nstr\nMSE\ncurrently only MSE is supported\n\n\nobsprocessors\nlist | None\nNone\ndefault: []\n\n\ndevice\nstr\ncpu\n“cuda” or “cpu”\n\n\nagent_name\nstr | None\nSAC\n\n\n\nnetwork_actor_mu_params\ndict\nNone\n\n\n\nnetwork_actor_sigma_params\ndict\nNone\n\n\n\nnetwork_critic_params\ndict\nNone\n\n\n\n\n\nsource\n\n\nSACAgent\n\n SACAgent (environment_info:ddopai.utils.MDPInfo, hidden_layers:List=None,\n           activation:str='relu', learning_rate_actor:float=0.0003,\n           learning_rate_critic:float|None=None,\n           initial_replay_size:int=64, max_replay_size:int=50000,\n           batch_size:int=64, warmup_transitions:int=100,\n           lr_alpha:float=0.0003, tau:float=0.005,\n           log_std_min:float=-20.0, log_std_max:float=2.0,\n           use_log_alpha_loss=False, target_entropy:float|None=None,\n           drop_prob:float=0.0, batch_norm:bool=False,\n           init_method:str='xavier_uniform', optimizer:str='Adam',\n           loss:str='MSE', obsprocessors:list|None=None, device:str='cpu',\n           agent_name:str|None='SAC', observation_space_shape=None,\n           action_space_shape=None)\n\nXXX\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nenvironment_info\nMDPInfo\n\n\n\n\nhidden_layers\nList\nNone\nif None, then default is [64, 64]\n\n\nactivation\nstr\nrelu\n“relu”, “sigmoid”, “tanh”, “leakyrelu”, “elu”\n\n\nlearning_rate_actor\nfloat\n0.0003\n\n\n\nlearning_rate_critic\nfloat | None\nNone\nIf none, then it is set to learning_rate_actor\n\n\ninitial_replay_size\nint\n64\n\n\n\nmax_replay_size\nint\n50000\n\n\n\nbatch_size\nint\n64\n\n\n\nwarmup_transitions\nint\n100\n\n\n\nlr_alpha\nfloat\n0.0003\n\n\n\ntau\nfloat\n0.005\n\n\n\nlog_std_min\nfloat\n-20.0\n\n\n\nlog_std_max\nfloat\n2.0\n\n\n\nuse_log_alpha_loss\nbool\nFalse\n\n\n\ntarget_entropy\nfloat | None\nNone\n\n\n\ndrop_prob\nfloat\n0.0\n\n\n\nbatch_norm\nbool\nFalse\n\n\n\ninit_method\nstr\nxavier_uniform\n“xavier_uniform”, “xavier_normal”, “he_normal”, “he_uniform”, “normal”, “uniform”\n\n\noptimizer\nstr\nAdam\n“Adam” or “SGD” or “RMSprop”\n\n\nloss\nstr\nMSE\ncurrently only MSE is supported\n\n\nobsprocessors\nlist | None\nNone\ndefault: []\n\n\ndevice\nstr\ncpu\n“cuda” or “cpu”\n\n\nagent_name\nstr | None\nSAC\n\n\n\nobservation_space_shape\nNoneType\nNone\noptional when it cannot be inferred from environment_info (e.g. for dict spaces)\n\n\naction_space_shape\nNoneType\nNone\noptional when it cannot be inferred from environment_info (e.g. for dict spaces)\n\n\n\n\nfrom ddopai.envs.inventory.single_period import NewsvendorEnv\nfrom ddopai.dataloaders.tabular import XYDataLoader\nfrom ddopai.experiments.experiment_functions import run_experiment, test_agent\n\nINFO:numexpr.utils:Note: NumExpr detected 10 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\nINFO:numexpr.utils:NumExpr defaulting to 8 threads.\n\n\n\nval_index_start = 8000 #90_000\ntest_index_start = 9000 #100_000\n\nX = np.random.standard_normal((10000, 2))\nY = np.random.standard_normal((10000, 1))\nY += 2*X[:,0].reshape(-1, 1) + 3*X[:,1].reshape(-1, 1)\nY = X[:,0].reshape(-1, 1)\n# truncate Y at 0:\nY = np.maximum(Y, 0)\n# normalize Y max to 1\nY = Y/np.max(Y)\n\n# print(np.max(Y))\n# print(X.shape, Y.shape)\n\nclip_action = ClipAction(0., 1.)\n\ndataloader = XYDataLoader(X, Y, val_index_start, test_index_start, lag_window_params =  {'lag_window': 0, 'include_y': False, 'pre_calc': True})\n\nenvironment = NewsvendorEnv(\n    dataloader = dataloader,\n    underage_cost = 0.42857,\n    overage_cost = 1.0,\n    gamma = 0.999,\n    horizon_train = 365,\n    q_bound_high = 1.0,\n    q_bound_low = -0.1,\n    postprocessors = [clip_action],\n)\n\nagent = SACAgent(environment.mdp_info,\n                obsprocessors = None,      # default: []\n                device=\"cpu\", # \"cuda\" or \"cpu\"\n)\n\nenvironment.test()\nagent.eval()\n\nR, J = test_agent(agent, environment)\n\nprint(R, J)\n\nenvironment.train()\nagent.train()\nenvironment.print=False\n\n# run_experiment(agent, environment, n_epochs=50, n_steps=1000, run_id = \"test\", save_best=True, print_freq=1) # fit agent via run_experiment function\n\nenvironment.test()\nagent.eval()\n\nR, J = test_agent(agent, environment)\n\nprint(R, J)\n\n/Users/magnus/miniforge3/envs/inventory_gym_2/lib/python3.11/site-packages/gymnasium/spaces/box.py:130: UserWarning: WARN: Box bound precision lowered by casting to float32\n  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\nINFO:root:Actor network (mu network):\n/Users/magnus/miniforge3/envs/inventory_gym_2/lib/python3.11/site-packages/torchinfo/torchinfo.py:462: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  action_fn=lambda data: sys.getsizeof(data.storage()),\n\n\n==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nMLPActor                                 [1, 1]                    --\n├─Sequential: 1-1                        [1, 1]                    --\n│    └─Linear: 2-1                       [1, 64]                   192\n│    └─ReLU: 2-2                         [1, 64]                   --\n│    └─Dropout: 2-3                      [1, 64]                   --\n│    └─Linear: 2-4                       [1, 64]                   4,160\n│    └─ReLU: 2-5                         [1, 64]                   --\n│    └─Dropout: 2-6                      [1, 64]                   --\n│    └─Linear: 2-7                       [1, 1]                    65\n│    └─Identity: 2-8                     [1, 1]                    --\n==========================================================================================\nTotal params: 4,417\nTrainable params: 4,417\nNon-trainable params: 0\nTotal mult-adds (M): 0.00\n==========================================================================================\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.00\nParams size (MB): 0.02\nEstimated Total Size (MB): 0.02\n==========================================================================================\n\n\nINFO:root:################################################################################\nINFO:root:Critic network:\n\n\n==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nMLPStateAction                           --                        --\n├─Sequential: 1-1                        [1, 1]                    --\n│    └─Linear: 2-1                       [1, 64]                   256\n│    └─ReLU: 2-2                         [1, 64]                   --\n│    └─Dropout: 2-3                      [1, 64]                   --\n│    └─Linear: 2-4                       [1, 64]                   4,160\n│    └─ReLU: 2-5                         [1, 64]                   --\n│    └─Dropout: 2-6                      [1, 64]                   --\n│    └─Linear: 2-7                       [1, 1]                    65\n│    └─Identity: 2-8                     [1, 1]                    --\n==========================================================================================\nTotal params: 4,481\nTrainable params: 4,481\nNon-trainable params: 0\nTotal mult-adds (M): 0.00\n==========================================================================================\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.00\nParams size (MB): 0.02\nEstimated Total Size (MB): 0.02\n==========================================================================================\n-245.3059010258002 -154.16627214771364\n-245.3059010258002 -154.16627214771364\n\n\n\nsource\n\n\nSACRNNAgent\n\n SACRNNAgent (environment_info:ddopai.utils.MDPInfo,\n              hidden_layers_RNN:int=1, num_hidden_units_RNN:int=64,\n              RNN_cell:str='GRU', hidden_layers_MLP:List=None,\n              hidden_layers_input_MLP:List=None, activation:str='relu',\n              learning_rate_actor:float=0.0003,\n              learning_rate_critic:float|None=None,\n              initial_replay_size:int=64, max_replay_size:int=50000,\n              batch_size:int=64, warmup_transitions:int=100,\n              lr_alpha:float=0.0003, tau:float=0.005,\n              log_std_min:float=-20.0, log_std_max:float=2.0,\n              use_log_alpha_loss=False, target_entropy:float|None=None,\n              drop_prob:float=0.0, batch_norm:bool=False,\n              init_method:str='xavier_uniform', optimizer:str='Adam',\n              loss:str='MSE', obsprocessors:list|None=None,\n              device:str='cpu', agent_name:str|None='SAC',\n              observation_space_shape=None, action_space_shape=None)\n\nXXX\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nenvironment_info\nMDPInfo\n\n\n\n\nhidden_layers_RNN\nint\n1\nInitial RNN layers\n\n\nnum_hidden_units_RNN\nint\n64\nInitial number of hidden units in RNN layers\n\n\nRNN_cell\nstr\nGRU\n“LSTM”, “GRU”, “RNN”\n\n\nhidden_layers_MLP\nList\nNone\nMLP layers behind RNN: if None, then default is [64, 64]\n\n\nhidden_layers_input_MLP\nList\nNone\nMLP layers for non-time features. Default is None\n\n\nactivation\nstr\nrelu\n“relu”, “sigmoid”, “tanh”, “leakyrelu”, “elu”\n\n\nlearning_rate_actor\nfloat\n0.0003\n\n\n\nlearning_rate_critic\nfloat | None\nNone\nIf none, then it is set to learning_rate_actor\n\n\ninitial_replay_size\nint\n64\n\n\n\nmax_replay_size\nint\n50000\n\n\n\nbatch_size\nint\n64\n\n\n\nwarmup_transitions\nint\n100\n\n\n\nlr_alpha\nfloat\n0.0003\n\n\n\ntau\nfloat\n0.005\n\n\n\nlog_std_min\nfloat\n-20.0\n\n\n\nlog_std_max\nfloat\n2.0\n\n\n\nuse_log_alpha_loss\nbool\nFalse\n\n\n\ntarget_entropy\nfloat | None\nNone\n\n\n\ndrop_prob\nfloat\n0.0\n\n\n\nbatch_norm\nbool\nFalse\n\n\n\ninit_method\nstr\nxavier_uniform\n“xavier_uniform”, “xavier_normal”, “he_normal”, “he_uniform”, “normal”, “uniform”\n\n\noptimizer\nstr\nAdam\n“Adam” or “SGD” or “RMSprop”\n\n\nloss\nstr\nMSE\ncurrently only MSE is supported\n\n\nobsprocessors\nlist | None\nNone\ndefault: []\n\n\ndevice\nstr\ncpu\n“cuda” or “cpu”\n\n\nagent_name\nstr | None\nSAC\n\n\n\nobservation_space_shape\nNoneType\nNone\noptional when it cannot be inferred from environment_info (e.g. for dict spaces)\n\n\naction_space_shape\nNoneType\nNone\noptional when it cannot be inferred from environment_info (e.g. for dict spaces)\n\n\n\n\nfrom ddopai.envs.inventory.single_period import NewsvendorEnv\nfrom ddopai.dataloaders.tabular import XYDataLoader\nfrom ddopai.experiments.experiment_functions import run_experiment, test_agent\n\n\nval_index_start = 8000 #90_000\ntest_index_start = 9000 #100_000\n\nX = np.random.standard_normal((10000, 2))\nY = np.random.standard_normal((10000, 1))\nY += 2*X[:,0].reshape(-1, 1) + 3*X[:,1].reshape(-1, 1)\nY = X[:,0].reshape(-1, 1)\n# truncate Y at 0:\nY = np.maximum(Y, 0)\n# normalize Y max to 1\nY = Y/np.max(Y)\n\nclip_action = ClipAction(0., 1.)\n\ndataloader = XYDataLoader(X, Y, val_index_start, test_index_start, lag_window_params =  {'lag_window': 5, 'include_y': True, 'pre_calc': True})\n\nenvironment = NewsvendorEnv(\n    dataloader = dataloader,\n    underage_cost = 0.42857,\n    overage_cost = 1.0,\n    gamma = 0.999,\n    horizon_train = 365,\n    q_bound_high = 1.0,\n    q_bound_low = -0.1,\n    postprocessors = [clip_action],\n)\n\nagent = SACRNNAgent(environment.mdp_info,\n                obsprocessors = None,      # default: []\n                device=\"cpu\", # \"cuda\" or \"cpu\"\n)\n\nenvironment.test()\nagent.eval()\n\nR, J = test_agent(agent, environment)\n\nprint(R, J)\n\nenvironment.train()\nagent.train()\nenvironment.print=False\n\n# run_experiment(agent, environment, n_epochs=50, n_steps=1000, run_id = \"test\", save_best=True, print_freq=1) # fit agent via run_experiment function\n\nenvironment.test()\nagent.eval()\n\nR, J = test_agent(agent, environment)\n\nprint(R, J)\n\n/Users/magnus/miniforge3/envs/inventory_gym_2/lib/python3.11/site-packages/gymnasium/spaces/box.py:130: UserWarning: WARN: Box bound precision lowered by casting to float32\n  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\nINFO:root:Actor network (mu network):\n\n\n==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nRNNActor                                 [1, 1]                    --\n├─RNNMLPHybrid: 1-1                      [1, 1]                    --\n│    └─Sequential: 2-1                   [1, 6, 64]                --\n│    │    └─SpecificRNNWrapper: 3-1      [1, 6, 64]                13,248\n│    │    └─ReLU: 3-2                    [1, 6, 64]                --\n│    └─Sequential: 2-2                   [1, 1]                    --\n│    │    └─Linear: 3-3                  [1, 64]                   4,160\n│    │    └─ReLU: 3-4                    [1, 64]                   --\n│    │    └─Dropout: 3-5                 [1, 64]                   --\n│    │    └─Linear: 3-6                  [1, 64]                   4,160\n│    │    └─ReLU: 3-7                    [1, 64]                   --\n│    │    └─Dropout: 3-8                 [1, 64]                   --\n│    │    └─Linear: 3-9                  [1, 1]                    65\n==========================================================================================\nTotal params: 21,633\nTrainable params: 21,633\nNon-trainable params: 0\nTotal mult-adds (M): 0.09\n==========================================================================================\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.00\nParams size (MB): 0.09\nEstimated Total Size (MB): 0.09\n==========================================================================================\n\n\nINFO:root:################################################################################\nINFO:root:Critic network:\n\n\n==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nRNNStateAction                           --                        --\n├─RNNMLPHybrid: 1-1                      [1, 1]                    --\n│    └─Sequential: 2-1                   [1, 6, 64]                --\n│    │    └─SpecificRNNWrapper: 3-1      [1, 6, 64]                13,248\n│    │    └─ReLU: 3-2                    [1, 6, 64]                --\n│    └─Sequential: 2-2                   [1, 1]                    --\n│    │    └─Linear: 3-3                  [1, 64]                   4,224\n│    │    └─ReLU: 3-4                    [1, 64]                   --\n│    │    └─Dropout: 3-5                 [1, 64]                   --\n│    │    └─Linear: 3-6                  [1, 64]                   4,160\n│    │    └─ReLU: 3-7                    [1, 64]                   --\n│    │    └─Dropout: 3-8                 [1, 64]                   --\n│    │    └─Linear: 3-9                  [1, 1]                    65\n==========================================================================================\nTotal params: 21,697\nTrainable params: 21,697\nNon-trainable params: 0\nTotal mult-adds (M): 0.09\n==========================================================================================\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.00\nParams size (MB): 0.09\nEstimated Total Size (MB): 0.09\n==========================================================================================\n-383.1306977574299 -243.60956423506602\n-383.1306977574299 -243.60956423506602",
    "crumbs": [
      "Agents",
      "Reinforcement Learning agents",
      "SAC agents"
    ]
  },
  {
    "objectID": "30_agents/ml_utils.html",
    "href": "30_agents/ml_utils.html",
    "title": "ML utils",
    "section": "",
    "text": "source\n\nLRSchedulerPerStep\n\n LRSchedulerPerStep (optimizer:torch.optim.optimizer.Optimizer,\n                     base_learning_rate:float=0.0001, warmup:int=4000)\n\nLearning rate scheduler from Attention is all you need paper (https://arxiv.org/abs/1706.03762) One ajustment: Added base LR as tunable parameter rather than setting it automated based on model dimension\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\noptimizer\nOptimizer\n\nOptimizer to adjust learning rate for\n\n\nbase_learning_rate\nfloat\n0.0001\n\n\n\nwarmup\nint\n4000",
    "crumbs": [
      "Agents",
      "ML utils"
    ]
  },
  {
    "objectID": "30_agents/41_NV_agents/nv_erm_agents.html",
    "href": "30_agents/41_NV_agents/nv_erm_agents.html",
    "title": "ERM agents",
    "section": "",
    "text": "source",
    "crumbs": [
      "Agents",
      "Newsvendor_agents",
      "ERM agents"
    ]
  },
  {
    "objectID": "30_agents/41_NV_agents/nv_erm_agents.html#sgdbaseagent",
    "href": "30_agents/41_NV_agents/nv_erm_agents.html#sgdbaseagent",
    "title": "ERM agents",
    "section": "SGDBaseAgent",
    "text": "SGDBaseAgent\n\n SGDBaseAgent (environment_info:ddopai.utils.MDPInfo,\n               dataloader:ddopai.dataloaders.base.BaseDataLoader,\n               input_shape:Tuple, output_shape:Tuple,\n               dataset_params:Optional[dict]=None,\n               dataloader_params:Optional[dict]=None,\n               optimizer_params:Optional[dict]=None,\n               learning_rate_scheduler_params:Optional[Dict]=None,\n               obsprocessors:Optional[List]=None, device:str='cpu',\n               agent_name:str|None=None, test_batch_size:int=1024,\n               receive_batch_dim:bool=False)\n\nBase class for Agents that are trained using Stochastic Gradient Descent (SGD) on PyTorch models.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nenvironment_info\nMDPInfo\n\n\n\n\ndataloader\nBaseDataLoader\n\n\n\n\ninput_shape\nTuple\n\n\n\n\noutput_shape\nTuple\n\n\n\n\ndataset_params\nOptional\nNone\nparameters needed to convert the dataloader to a torch dataset\n\n\ndataloader_params\nOptional\nNone\ndefault: {“batch_size”: 32, “shuffle”: True}\n\n\noptimizer_params\nOptional\nNone\ndefault: {“optimizer”: “Adam”, “lr”: 0.01, “weight_decay”: 0.0}\n\n\nlearning_rate_scheduler_params\nOptional\nNone\ndefault: None. If dict, then first key is “scheduler” and the rest are the parameters\n\n\nobsprocessors\nOptional\nNone\ndefault: []\n\n\ndevice\nstr\ncpu\n“cuda” or “cpu”\n\n\nagent_name\nstr | None\nNone\n\n\n\ntest_batch_size\nint\n1024\n\n\n\nreceive_batch_dim\nbool\nFalse\n\n\n\n\n\nImportant notes:\nSGD-based agents are all agents that are trained via SGD such as Linear Models or Neural Networks. Some specific requirements are necessary to make them interface properly with the environment.\nTorch perprocessors:\n\nIn addition to the general Numpy-based pre-processor, we also provide pre-processors that work on tensor level within the fit_epoch method and the predict method. They can be used in addition to the numpy-based pre-processors or instead of them. It’s important to ensure that the shape of observations (after pre-processing) is the same for those from the environemnt and those from the dataloader during training.\n\nDataloader:\n\nAs for normal supervised learning via Torch, we make use of the Torch dataloader to load the data. Instead of defining a custom dataset class, we provide a Wrapper that can be used around our dataloader to make its output and interface the same as a Torch dataset. The dataloader is then initialized when the agent is created such that the agent has access to the same dataloader as the environment.\n\nTraining process:\n\nThe outper loop of the training process (epochs) is handled outside the agent by the [`run_experiment`](https://opimwue.github.io/ddopai/40_experiments/experiment_functions.html#run_experiment)functions (or can also be customized). The agent needs to have a fit_epoch method that tells the agent what to do within an epoch. This includes:\n\nGetting the data from the dataloader\nPre-processing the data\nForward pass\nLoss calculation\nBackward pass\n\n\n\nsource\n\n\nSGDBaseAgent.set_dataloader\n\n SGDBaseAgent.set_dataloader\n                              (dataloader:ddopai.dataloaders.base.BaseData\n                              Loader, dataset_params:dict,\n                              dataloader_params:dict)\n\nSet the dataloader for the agent by wrapping it into a Torch Dataset\n\n\n\n\nType\nDetails\n\n\n\n\ndataloader\nBaseDataLoader\n\n\n\ndataset_params\ndict\n\n\n\ndataloader_params\ndict\ndict with keys: batch_size, shuffle\n\n\nReturns\nNone\n\n\n\n\n\nsource\n\n\nSGDBaseAgent.set_loss_function\n\n SGDBaseAgent.set_loss_function ()\n\nSet loss function for the model\n\nsource\n\n\nSGDBaseAgent.set_model\n\n SGDBaseAgent.set_model (input_shape:Tuple, output_shape:Tuple)\n\nSet the model for the agent\n\nsource\n\n\nSGDBaseAgent.set_optimizer\n\n SGDBaseAgent.set_optimizer (optimizer_params:dict)\n\nSet the optimizer for the model\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\noptimizer_params\ndict\ndict with keys: optimizer, lr, weight_decay\n\n\n\n\nsource\n\n\nSGDBaseAgent.set_learning_rate_scheduler\n\n SGDBaseAgent.set_learning_rate_scheduler (learning_rate_scheduler_params)\n\nSet learning rate scheudler (can be None)\n\n\n\n\nDetails\n\n\n\n\nlearning_rate_scheduler_params\n\n\n\n\n\nsource\n\n\nSGDBaseAgent.fit_epoch\n\n SGDBaseAgent.fit_epoch ()\n\nFit the model for one epoch using the dataloader\n\nsource\n\n\nSGDBaseAgent.draw_action_\n\n SGDBaseAgent.draw_action_ (observation:numpy.ndarray)\n\nDraw an action based on the fitted model (see predict method)\n\n\n\n\nType\nDetails\n\n\n\n\nobservation\nndarray\n\n\n\nReturns\nndarray\n\n\n\n\n\nsource\n\n\nSGDBaseAgent.predict\n\n SGDBaseAgent.predict (X:numpy.ndarray)\n\nDo one forward pass of the model and return the prediction\n\n\n\n\nType\nDetails\n\n\n\n\nX\nndarray\n\n\n\nReturns\nndarray\n\n\n\n\n\nsource\n\n\nSGDBaseAgent.train\n\n SGDBaseAgent.train ()\n\nset the internal state of the agent and its model to train\n\nsource\n\n\nSGDBaseAgent.eval\n\n SGDBaseAgent.eval ()\n\nset the internal state of the agent and its model to eval\n\nsource\n\n\nSGDBaseAgent.to\n\n SGDBaseAgent.to (device:str)\n\nMove the model to the specified device\n\n\n\n\nType\nDetails\n\n\n\n\ndevice\nstr\n\n\n\n\n\nsource\n\n\nSGDBaseAgent.save\n\n SGDBaseAgent.save (path:str, overwrite:bool=True)\n\nSave the PyTorch model to a file in the specified directory.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\n\nThe directory where the file will be saved.\n\n\noverwrite\nbool\nTrue\nAllow overwriting; if False, a FileExistsError will be raised if the file exists.\n\n\n\n\nsource\n\n\nSGDBaseAgent.load\n\n SGDBaseAgent.load (path:str)\n\nLoad the PyTorch model from a file.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\npath\nstr\nOnly the path to the folder is needed, not the file itself\n\n\n\n\nsource",
    "crumbs": [
      "Agents",
      "Newsvendor_agents",
      "ERM agents"
    ]
  },
  {
    "objectID": "30_agents/41_NV_agents/nv_erm_agents.html#nvbaseagent",
    "href": "30_agents/41_NV_agents/nv_erm_agents.html#nvbaseagent",
    "title": "ERM agents",
    "section": "NVBaseAgent",
    "text": "NVBaseAgent\n\n NVBaseAgent (environment_info:ddopai.utils.MDPInfo,\n              dataloader:ddopai.dataloaders.base.BaseDataLoader,\n              cu:numpy.ndarray|ddopai.utils.Parameter,\n              co:numpy.ndarray|ddopai.utils.Parameter, input_shape:Tuple,\n              output_shape:Tuple, optimizer_params:dict|None=None,\n              learning_rate_scheduler_params=None,\n              dataset_params:dict|None=None,\n              dataloader_params:dict|None=None,\n              obsprocessors:list|None=None, device:str='cpu',\n              agent_name:str|None=None, test_batch_size:int=1024,\n              receive_batch_dim:bool=False,\n              loss_function:Literal['quantile','pinball']='quantile')\n\nBase agent for the Newsvendor problem implementing the loss function for the Empirical Risk Minimization (ERM) approach based on quantile loss.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nenvironment_info\nMDPInfo\n\n\n\n\ndataloader\nBaseDataLoader\n\n\n\n\ncu\nnumpy.ndarray | ddopai.utils.Parameter\n\n\n\n\nco\nnumpy.ndarray | ddopai.utils.Parameter\n\n\n\n\ninput_shape\nTuple\n\n\n\n\noutput_shape\nTuple\n\n\n\n\noptimizer_params\ndict | None\nNone\ndefault: {“optimizer”: “Adam”, “lr”: 0.01, “weight_decay”: 0.0}\n\n\nlearning_rate_scheduler_params\nNoneType\nNone\nTODO: add base class for learning rate scheduler for typing\n\n\ndataset_params\ndict | None\nNone\nparameters needed to convert the dataloader to a torch dataset\n\n\ndataloader_params\ndict | None\nNone\ndefault: {“batch_size”: 32, “shuffle”: True}\n\n\nobsprocessors\nlist | None\nNone\ndefault: []\n\n\ndevice\nstr\ncpu\n“cuda” or “cpu”\n\n\nagent_name\nstr | None\nNone\n\n\n\ntest_batch_size\nint\n1024\n\n\n\nreceive_batch_dim\nbool\nFalse\n\n\n\nloss_function\nLiteral\nquantile\n\n\n\n\n\nsource\n\nNVBaseAgent.set_loss_function\n\n NVBaseAgent.set_loss_function ()\n\nSet the loss function for the model to the quantile loss. For training the model uses quantile loss and not the pinball loss with specific cu and co values to ensure similar scale of the feedback signal during training.\n\nsource",
    "crumbs": [
      "Agents",
      "Newsvendor_agents",
      "ERM agents"
    ]
  },
  {
    "objectID": "30_agents/41_NV_agents/nv_erm_agents.html#newsvendorlermagent",
    "href": "30_agents/41_NV_agents/nv_erm_agents.html#newsvendorlermagent",
    "title": "ERM agents",
    "section": "NewsvendorlERMAgent",
    "text": "NewsvendorlERMAgent\n\n NewsvendorlERMAgent (environment_info:ddopai.utils.MDPInfo,\n                      dataloader:ddopai.dataloaders.base.BaseDataLoader,\n                      cu:numpy.ndarray|ddopai.utils.Parameter,\n                      co:numpy.ndarray|ddopai.utils.Parameter,\n                      input_shape:Tuple, output_shape:Tuple,\n                      optimizer_params:dict|None=None,\n                      learning_rate_scheduler_params=None,\n                      model_params:dict|None=None,\n                      dataset_params:dict|None=None,\n                      dataloader_params:dict|None=None,\n                      obsprocessors:list|None=None, device:str='cpu',\n                      agent_name:str|None='lERM',\n                      test_batch_size:int=1024,\n                      receive_batch_dim:bool=False, loss_function:Literal[\n                      'quantile','pinball']='quantile')\n\nNewsvendor agent implementing Empirical Risk Minimization (ERM) approach based on a linear (regression) model. Note that this implementation finds the optimal regression parameters via SGD.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nenvironment_info\nMDPInfo\n\n\n\n\ndataloader\nBaseDataLoader\n\n\n\n\ncu\nnumpy.ndarray | ddopai.utils.Parameter\n\n\n\n\nco\nnumpy.ndarray | ddopai.utils.Parameter\n\n\n\n\ninput_shape\nTuple\n\n\n\n\noutput_shape\nTuple\n\n\n\n\noptimizer_params\ndict | None\nNone\ndefault: {“optimizer”: “Adam”, “lr”: 0.01, “weight_decay”: 0.0}\n\n\nlearning_rate_scheduler_params\nNoneType\nNone\nTODO: add base class for learning rate scheduler for typing\n\n\nmodel_params\ndict | None\nNone\ndefault: {“relu_output”: False}\n\n\ndataset_params\ndict | None\nNone\nparameters needed to convert the dataloader to a torch dataset\n\n\ndataloader_params\ndict | None\nNone\ndefault: {“batch_size”: 32, “shuffle”: True}\n\n\nobsprocessors\nlist | None\nNone\ndefault: []\n\n\ndevice\nstr\ncpu\n“cuda” or “cpu”\n\n\nagent_name\nstr | None\nlERM\n\n\n\ntest_batch_size\nint\n1024\n\n\n\nreceive_batch_dim\nbool\nFalse\n\n\n\nloss_function\nLiteral\nquantile\n\n\n\n\n\nFurther information:\nReferences\n----------\n\n.. [1] Gah-Yi Ban, Cynthia Rudin, \"The Big Data Newsvendor: Practical Insights\n    from Machine Learning\", 2018.\n\nsource\n\n\nNewsvendorlERMAgent.set_model\n\n NewsvendorlERMAgent.set_model (input_shape, output_shape)\n\nSet the model for the agent to a linear model\nExample usage:\n\nfrom ddopai.envs.inventory.single_period import NewsvendorEnv\nfrom ddopai.dataloaders.tabular import XYDataLoader\nfrom ddopai.experiments.experiment_functions import run_experiment, test_agent\n\n\nval_index_start = 800 #90_000\ntest_index_start = 900 #100_000\n\nX = np.random.rand(1000, 2)\nY = np.random.rand(1000, 1)\n\ndataloader = XYDataLoader(X, Y, val_index_start, test_index_start)\n\nenvironment = NewsvendorEnv(\n    dataloader = dataloader,\n    underage_cost = 0.42857,\n    overage_cost = 1.0,\n    gamma = 0.999,\n    horizon_train = 365,\n)\n\nagent = NewsvendorlERMAgent(environment.mdp_info,\n                            dataloader,\n                            cu=np.array([0.42857]),\n                            co=np.array([1.0]),\n                            input_shape=(2,),\n                            output_shape=(1,),\n                            optimizer_params= {\"optimizer\": \"Adam\", \"lr\": 0.01, \"weight_decay\": 0.0}, # other optimizers: \"SGD\", \"RMSprop\"\n                            learning_rate_scheduler_params = None, # TODO add base class for learning rate scheduler for typing\n                            model_params = {\"relu_output\": False}, #\n                            dataloader_params={\"batch_size\": 32, \"shuffle\": True},\n                            device = \"cpu\", # \"cuda\" or \"cpu\"\n)\n\nenvironment.test()\nagent.eval()\n\nR, J = test_agent(agent, environment)\n\nprint(R, J)\n\nrun_experiment(agent, environment, 2, run_id = \"test\") # fit agent via run_experiment function\n\nenvironment.test()\nagent.eval()\n\nR, J = test_agent(agent, environment)\n\nprint(R, J)\n\ninput shape (2,)\n\n\nINFO:root:Network architecture:\n/Users/magnus/miniforge3/envs/inventory_gym_2/lib/python3.11/site-packages/torchinfo/torchinfo.py:462: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  action_fn=lambda data: sys.getsizeof(data.storage()),\n\n\n==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nLinearModel                              [1, 1]                    --\n├─Linear: 1-1                            [1, 1]                    3\n├─Identity: 1-2                          [1, 1]                    --\n==========================================================================================\nTotal params: 3\nTrainable params: 3\nNon-trainable params: 0\nTotal mult-adds (M): 0.00\n==========================================================================================\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.00\nParams size (MB): 0.00\nEstimated Total Size (MB): 0.00\n==========================================================================================\n\n\nINFO:root:Starting experiment\nINFO:root:Initial evaluation: R=-29.736253318797445, J=-28.287550833928687\nINFO:root:Starting training with epochs fit\n\n\n-23.17678889235405 -22.124720267178684\nExperiment directory: results/test\n\n\n100%|██████████| 25/25 [00:00&lt;00:00, 903.73it/s]\n100%|██████████| 25/25 [00:00&lt;00:00, 1999.34it/s]\n100%|██████████| 2/2 [00:00&lt;00:00, 35.22it/s]\nINFO:root:Finished training with epochs fit\nINFO:root:Evaluation after training: R=-15.499745268755348, J=-14.77032101771835\n\n\n-16.54230338871762 -15.75806274718322\n\n\n\nsource",
    "crumbs": [
      "Agents",
      "Newsvendor_agents",
      "ERM agents"
    ]
  },
  {
    "objectID": "30_agents/41_NV_agents/nv_erm_agents.html#newsvendordlagent",
    "href": "30_agents/41_NV_agents/nv_erm_agents.html#newsvendordlagent",
    "title": "ERM agents",
    "section": "NewsvendorDLAgent",
    "text": "NewsvendorDLAgent\n\n NewsvendorDLAgent (environment_info:ddopai.utils.MDPInfo,\n                    dataloader:ddopai.dataloaders.base.BaseDataLoader,\n                    cu:numpy.ndarray|ddopai.utils.Parameter,\n                    co:numpy.ndarray|ddopai.utils.Parameter,\n                    input_shape:Tuple, output_shape:Tuple,\n                    learning_rate_scheduler_params:Optional[Dict]=None,\n                    optimizer_params:dict|None=None,\n                    model_params:dict|None=None,\n                    dataloader_params:dict|None=None,\n                    dataset_params:dict|None=None, device:str='cpu',\n                    obsprocessors:list|None=None,\n                    agent_name:str|None='DLNV', test_batch_size:int=1024,\n                    receive_batch_dim:bool=False, loss_function:Literal['q\n                    uantile','pinball']='quantile')\n\nNewsvendor agent implementing Empirical Risk Minimization (ERM) approach based on a deep learning model.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nenvironment_info\nMDPInfo\n\n\n\n\ndataloader\nBaseDataLoader\n\n\n\n\ncu\nnumpy.ndarray | ddopai.utils.Parameter\n\n\n\n\nco\nnumpy.ndarray | ddopai.utils.Parameter\n\n\n\n\ninput_shape\nTuple\n\n\n\n\noutput_shape\nTuple\n\n\n\n\nlearning_rate_scheduler_params\nOptional\nNone\n\n\n\noptimizer_params\ndict | None\nNone\ndefault: {“optimizer”: “Adam”, “lr”: 0.01, “weight_decay”: 0.0}\n\n\nmodel_params\ndict | None\nNone\ndefault: {“hidden_layers”: [64, 64], “drop_prob”: 0.0, “batch_norm”: False, “relu_output”: False}\n\n\ndataloader_params\ndict | None\nNone\ndefault: {“batch_size”: 32, “shuffle”: True}\n\n\ndataset_params\ndict | None\nNone\nparameters needed to convert the dataloader to a torch dataset\n\n\ndevice\nstr\ncpu\n“cuda” or “cpu”\n\n\nobsprocessors\nlist | None\nNone\ndefault: []\n\n\nagent_name\nstr | None\nDLNV\n\n\n\ntest_batch_size\nint\n1024\n\n\n\nreceive_batch_dim\nbool\nFalse\n\n\n\nloss_function\nLiteral\nquantile\n\n\n\n\n\nFurther information:\nReferences\n----------\n\n.. [1] Afshin Oroojlooyjadid, Lawrence V. Snyder, Martin Takáˇc,\n        \"Applying Deep Learning to the Newsvendor Problem\", 2018.\n\nsource\n\n\nNewsvendorDLAgent.set_model\n\n NewsvendorDLAgent.set_model (input_shape, output_shape)\n\nSet the model for the agent to an MLP\nExample usage:\n\ndataloader = XYDataLoader(X, Y, val_index_start, test_index_start)\n\nenvironment = NewsvendorEnv(\n    dataloader = dataloader,\n    underage_cost = 0.42857,\n    overage_cost = 1.0,\n    gamma = 0.999,\n    horizon_train = 365,\n)\n\nmodel_params = {\n    \"hidden_layers\": [64, 64],\n}\n\nagent = NewsvendorDLAgent(environment.mdp_info,\n                            dataloader,\n                            cu=np.array([0.42857]),\n                            co=np.array([1.0]),\n                            input_shape=(2,),\n                            output_shape=(1,),\n                            optimizer_params= {\"optimizer\": \"Adam\", \"lr\": 0.01, \"weight_decay\": 0.0}, # other optimizers: \"SGD\", \"RMSprop\"\n                            learning_rate_scheduler_params = None, # TODO add base class for learning rate scheduler for typing\n                            model_params = model_params, #\n                            dataloader_params={\"batch_size\": 32, \"shuffle\": True},\n                            device = \"cpu\" # \"cuda\" or \"cpu\"\n)\n\nenvironment.test()\nagent.eval()\n\nR, J = test_agent(agent, environment)\n\nprint(R, J)\n\nrun_experiment(agent, environment, 2, run_id = \"test\") # fit agent via run_experiment function\n\nenvironment.test()\nagent.eval()\n\nR, J = test_agent(agent, environment)\n\nprint(R, J)\n\nINFO:root:Network architecture:\n\n\ninput shape (2,)\n==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nMLP                                      [1, 1]                    --\n├─Sequential: 1-1                        [1, 1]                    --\n│    └─Linear: 2-1                       [1, 64]                   192\n│    └─ReLU: 2-2                         [1, 64]                   --\n│    └─Dropout: 2-3                      [1, 64]                   --\n│    └─Linear: 2-4                       [1, 64]                   4,160\n│    └─ReLU: 2-5                         [1, 64]                   --\n│    └─Dropout: 2-6                      [1, 64]                   --\n│    └─Linear: 2-7                       [1, 1]                    65\n│    └─Identity: 2-8                     [1, 1]                    --\n==========================================================================================\nTotal params: 4,417\nTrainable params: 4,417\nNon-trainable params: 0\nTotal mult-adds (M): 0.00\n==========================================================================================\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.00\nParams size (MB): 0.02\nEstimated Total Size (MB): 0.02\n==========================================================================================\n\n\nINFO:root:Starting experiment\nINFO:root:Initial evaluation: R=-20.030297947350757, J=-19.11491558256756\nINFO:root:Starting training with epochs fit\n\n\n-22.66337395888819 -21.548795898866043\nExperiment directory: results/test\n\n\n100%|██████████| 25/25 [00:00&lt;00:00, 1212.35it/s]\n100%|██████████| 25/25 [00:00&lt;00:00, 1277.10it/s]\n100%|██████████| 2/2 [00:00&lt;00:00, 32.30it/s]\nINFO:root:Finished training with epochs fit\nINFO:root:Evaluation after training: R=-15.082729205825588, J=-14.380392673719802\n\n\n-16.096224629924393 -15.338865711420437\n\n\n\nsource\n\n\nBaseMetaAgent\n\n BaseMetaAgent ()\n\nInitialize self. See help(type(self)) for accurate signature.\n\nsource\n\n\nNewsvendorlERMMetaAgent\n\n NewsvendorlERMMetaAgent (environment_info:ddopai.utils.MDPInfo,\n                          dataloader:ddopai.dataloaders.base.BaseDataLoade\n                          r, cu:numpy.ndarray|ddopai.utils.Parameter,\n                          co:numpy.ndarray|ddopai.utils.Parameter,\n                          input_shape:Tuple, output_shape:Tuple,\n                          optimizer_params:dict|None=None,\n                          learning_rate_scheduler_params=None,\n                          model_params:dict|None=None,\n                          dataset_params:dict|None=None,\n                          dataloader_params:dict|None=None,\n                          obsprocessors:list|None=None, device:str='cpu',\n                          agent_name:str|None='lERMMeta',\n                          test_batch_size:int=1024,\n                          receive_batch_dim:bool=False, loss_function:Lite\n                          ral['quantile','pinball']='quantile')\n\nNewsvendor agent implementing Empirical Risk Minimization (ERM) approach based on a linear (regression) model. In addition to the features, the agent also gets the sl as input to be able to forecast the optimal order quantity for different sl values. Depending on the training pipeline, this model can be adapted to become a full meta-learning algorithm cross products and cross sls.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nenvironment_info\nMDPInfo\n\nParameters for lERM agent\n\n\ndataloader\nBaseDataLoader\n\n\n\n\ncu\nnumpy.ndarray | ddopai.utils.Parameter\n\n\n\n\nco\nnumpy.ndarray | ddopai.utils.Parameter\n\n\n\n\ninput_shape\nTuple\n\n\n\n\noutput_shape\nTuple\n\n\n\n\noptimizer_params\ndict | None\nNone\ndefault: {“optimizer”: “Adam”, “lr”: 0.01, “weight_decay”: 0.0}\n\n\nlearning_rate_scheduler_params\nNoneType\nNone\nTODO: add base class for learning rate scheduler for typing\n\n\nmodel_params\ndict | None\nNone\ndefault: {“relu_output”: False}\n\n\ndataset_params\ndict | None\nNone\nparameters needed to convert the dataloader to a torch dataset\n\n\ndataloader_params\ndict | None\nNone\ndefault: {“batch_size”: 32, “shuffle”: True}\n\n\nobsprocessors\nlist | None\nNone\ndefault: []\n\n\ndevice\nstr\ncpu\n“cuda” or “cpu”\n\n\nagent_name\nstr | None\nlERMMeta\n\n\n\ntest_batch_size\nint\n1024\n\n\n\nreceive_batch_dim\nbool\nFalse\n\n\n\nloss_function\nLiteral\nquantile\n\n\n\n\n\nsource\n\n\nNewsvendorDLMetaAgent\n\n NewsvendorDLMetaAgent (environment_info:ddopai.utils.MDPInfo,\n                        dataloader:ddopai.dataloaders.base.BaseDataLoader,\n                        cu:numpy.ndarray|ddopai.utils.Parameter,\n                        co:numpy.ndarray|ddopai.utils.Parameter,\n                        input_shape:Tuple, output_shape:Tuple,\n                        learning_rate_scheduler_params=None,\n                        optimizer_params:dict|None=None,\n                        model_params:dict|None=None,\n                        dataset_params:dict|None=None,\n                        dataloader_params:dict|None=None,\n                        device:str='cpu', obsprocessors:list|None=None,\n                        agent_name:str|None='DLNV',\n                        test_batch_size:int=1024,\n                        receive_batch_dim:bool=False, loss_function:Litera\n                        l['quantile','pinball']='quantile')\n\nNewsvendor agent implementing Empirical Risk Minimization (ERM) approach based on a Neural Network. In addition to the features, the agent also gets the sl as input to be able to forecast the optimal order quantity for different sl values. Depending on the training pipeline, this model can be adapted to become a full meta-learning algorithm cross products and cross sls.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nenvironment_info\nMDPInfo\n\n\n\n\ndataloader\nBaseDataLoader\n\n\n\n\ncu\nnumpy.ndarray | ddopai.utils.Parameter\n\n\n\n\nco\nnumpy.ndarray | ddopai.utils.Parameter\n\n\n\n\ninput_shape\nTuple\n\n\n\n\noutput_shape\nTuple\n\n\n\n\nlearning_rate_scheduler_params\nNoneType\nNone\nTODO: add base class for learning rate scheduler for typing\n\n\noptimizer_params\ndict | None\nNone\ndefault: {“optimizer”: “Adam”, “lr”: 0.01, “weight_decay”: 0.0}\n\n\nmodel_params\ndict | None\nNone\ndefault: {“hidden_layers”: [64, 64], “drop_prob”: 0.0, “batch_norm”: False, “relu_output”: False}\n\n\ndataset_params\ndict | None\nNone\nparameters needed to convert the dataloader to a torch dataset\n\n\ndataloader_params\ndict | None\nNone\ndefault: {“batch_size”: 32, “shuffle”: True}\n\n\ndevice\nstr\ncpu\n“cuda” or “cpu”\n\n\nobsprocessors\nlist | None\nNone\ndefault: []\n\n\nagent_name\nstr | None\nDLNV\n\n\n\ntest_batch_size\nint\n1024\n\n\n\nreceive_batch_dim\nbool\nFalse\n\n\n\nloss_function\nLiteral\nquantile\n\n\n\n\n\nsource\n\n\nNewsvendorDLTransformerAgent\n\n NewsvendorDLTransformerAgent (environment_info:ddopai.utils.MDPInfo,\n                               dataloader:ddopai.dataloaders.base.BaseData\n                               Loader,\n                               cu:numpy.ndarray|ddopai.utils.Parameter,\n                               co:numpy.ndarray|ddopai.utils.Parameter,\n                               input_shape:Tuple, output_shape:Tuple, lear\n                               ning_rate_scheduler_params:Optional[Dict]=N\n                               one, optimizer_params:dict|None=None,\n                               model_params:dict|None=None,\n                               dataset_params:dict|None=None,\n                               dataloader_params:dict|None=None,\n                               device:str='cpu',\n                               obsprocessors:list|None=None,\n                               agent_name:str|None='DLNV',\n                               test_batch_size:int=1024,\n                               receive_batch_dim:bool=False, loss_function\n                               :Literal['quantile','pinball']='quantile')\n\nNewsvendor agent implementing Empirical Risk Minimization (ERM) approach based on a deep learning model with a Transformer architecture.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nenvironment_info\nMDPInfo\n\n\n\n\ndataloader\nBaseDataLoader\n\n\n\n\ncu\nnumpy.ndarray | ddopai.utils.Parameter\n\n\n\n\nco\nnumpy.ndarray | ddopai.utils.Parameter\n\n\n\n\ninput_shape\nTuple\n\n\n\n\noutput_shape\nTuple\n\n\n\n\nlearning_rate_scheduler_params\nOptional\nNone\n\n\n\noptimizer_params\ndict | None\nNone\ndefault: {“optimizer”: “Adam”, “lr”: 0.01, “weight_decay”: 0.0}\n\n\nmodel_params\ndict | None\nNone\ndefault: {“max_context_length”: 128, “n_layer”: 3, “n_head”: 8, “n_embd_per_head”: 32, “rope_scaling”: None, “min_multiple”: 256, “gating”: True, “drop_prob”: 0.0, “final_activation”: “identity”}\n\n\ndataset_params\ndict | None\nNone\nparameters needed to convert the dataloader to a torch dataset\n\n\ndataloader_params\ndict | None\nNone\ndefault: {“batch_size”: 32, “shuffle”: True}\n\n\ndevice\nstr\ncpu\n“cuda” or “cpu”\n\n\nobsprocessors\nlist | None\nNone\ndefault: []\n\n\nagent_name\nstr | None\nDLNV\n\n\n\ntest_batch_size\nint\n1024\n\n\n\nreceive_batch_dim\nbool\nFalse\n\n\n\nloss_function\nLiteral\nquantile\n\n\n\n\n\nsource\n\n\nNewsvendorDLTransformerMetaAgent\n\n NewsvendorDLTransformerMetaAgent (environment_info:ddopai.utils.MDPInfo,\n                                   dataloader:ddopai.dataloaders.base.Base\n                                   DataLoader, cu:numpy.ndarray|ddopai.uti\n                                   ls.Parameter, co:numpy.ndarray|ddopai.u\n                                   tils.Parameter, input_shape:Tuple,\n                                   output_shape:Tuple, learning_rate_sched\n                                   uler_params:Optional[Dict]=None,\n                                   optimizer_params:dict|None=None,\n                                   model_params:dict|None=None,\n                                   dataset_params:dict|None=None,\n                                   dataloader_params:dict|None=None,\n                                   device:str='cpu',\n                                   obsprocessors:list|None=None,\n                                   agent_name:str|None='DLNV',\n                                   test_batch_size:int=1024,\n                                   receive_batch_dim:bool=False, loss_func\n                                   tion:Literal['quantile','pinball']='qua\n                                   ntile')\n\nNewsvendor agent implementing Empirical Risk Minimization (ERM) approach based on a Neural Network using the attention mechanism. In addition to the features, the agent also gets the sl as input to be able to forecast the optimal order quantity for different sl values. Depending on the training pipeline, this model can be adapted to become a full meta-learning algorithm cross products and cross sls.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nenvironment_info\nMDPInfo\n\n\n\n\ndataloader\nBaseDataLoader\n\n\n\n\ncu\nnumpy.ndarray | ddopai.utils.Parameter\n\n\n\n\nco\nnumpy.ndarray | ddopai.utils.Parameter\n\n\n\n\ninput_shape\nTuple\n\n\n\n\noutput_shape\nTuple\n\n\n\n\nlearning_rate_scheduler_params\nOptional\nNone\n\n\n\noptimizer_params\ndict | None\nNone\ndefault: {“optimizer”: “Adam”, “lr”: 0.01, “weight_decay”: 0.0}\n\n\nmodel_params\ndict | None\nNone\ndefault: {“hidden_layers”: [64, 64], “drop_prob”: 0.0, “batch_norm”: False, “relu_output”: False}\n\n\ndataset_params\ndict | None\nNone\nparameters needed to convert the dataloader to a torch dataset\n\n\ndataloader_params\ndict | None\nNone\ndefault: {“batch_size”: 32, “shuffle”: True}\n\n\ndevice\nstr\ncpu\n“cuda” or “cpu”\n\n\nobsprocessors\nlist | None\nNone\ndefault: []\n\n\nagent_name\nstr | None\nDLNV\n\n\n\ntest_batch_size\nint\n1024\n\n\n\nreceive_batch_dim\nbool\nFalse\n\n\n\nloss_function\nLiteral\nquantile",
    "crumbs": [
      "Agents",
      "Newsvendor_agents",
      "ERM agents"
    ]
  },
  {
    "objectID": "20_environments/21_envs_inventory/single_period_envs.html",
    "href": "20_environments/21_envs_inventory/single_period_envs.html",
    "title": "Single period inventory environments",
    "section": "",
    "text": "source",
    "crumbs": [
      "Environments",
      "Inventory environments",
      "Single period inventory environments"
    ]
  },
  {
    "objectID": "20_environments/21_envs_inventory/single_period_envs.html#newsvendorenv",
    "href": "20_environments/21_envs_inventory/single_period_envs.html#newsvendorenv",
    "title": "Single period inventory environments",
    "section": "NewsvendorEnv",
    "text": "NewsvendorEnv\n\n NewsvendorEnv\n                (underage_cost:Union[numpy.ndarray,ddopai.utils.Parameter,\n                int,float]=1, overage_cost:Union[numpy.ndarray,ddopai.util\n                s.Parameter,int,float]=1, q_bound_low:Union[numpy.ndarray,\n                ddopai.utils.Parameter,int,float]=0, q_bound_high:Union[nu\n                mpy.ndarray,ddopai.utils.Parameter,int,float]=inf,\n                dataloader:ddopai.dataloaders.base.BaseDataLoader=None,\n                num_SKUs:int=None, gamma:float=1,\n                horizon_train:int|str='use_all_data',\n                postprocessors:list[object]|None=None, mode:str='train',\n                return_truncation:str=True)\n\nClass implementing the Newsvendor problem, working for the single- and multi-item case. If underage_cost and overage_cost are scalars and there are multiple SKUs, then the same cost is used for all SKUs. If underage_cost and overage_cost are arrays, then they must have the same length as the number of SKUs. Num_SKUs can be set as parameter or inferred from the DataLoader.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nunderage_cost\nUnion\n1\nunderage cost per unit\n\n\noverage_cost\nUnion\n1\noverage cost per unit\n\n\nq_bound_low\nUnion\n0\nlower bound of the order quantity\n\n\nq_bound_high\nUnion\ninf\nupper bound of the order quantity\n\n\ndataloader\nBaseDataLoader\nNone\ndataloader\n\n\nnum_SKUs\nint\nNone\nif None it will be inferred from the DataLoader\n\n\ngamma\nfloat\n1\ndiscount factor\n\n\nhorizon_train\nint | str\nuse_all_data\nif “use_all_data” then horizon is inferred from the DataLoader\n\n\npostprocessors\nlist[object] | None\nNone\ndefault is empty list\n\n\nmode\nstr\ntrain\nInitial mode (train, val, test) of the environment\n\n\nreturn_truncation\nstr\nTrue\nwhether to return a truncated condition in step function\n\n\nReturns\nNone\n\n\n\n\n\n\nsource\n\nNewsvendorEnv.step_\n\n NewsvendorEnv.step_ (action:numpy.ndarray)\n\nStep function implementing the Newsvendor logic. Note that the dataloader will return an observation and a demand, which will be relevant in the next period. The observation will be returned directly, while the demand will be temporarily stored under self.demand and used in the next step.\n\n\n\n\nType\nDetails\n\n\n\n\naction\nndarray\norder quantity\n\n\nReturns\nTuple\n\n\n\n\n\nsource\n\n\nNewsvendorEnv.determine_cost\n\n NewsvendorEnv.determine_cost (action:numpy.ndarray)\n\nDetermine the cost per SKU given the action taken. The cost is the sum of underage and overage costs.\n\nsource\n\n\nNewsvendorEnv.update_cu_co\n\n NewsvendorEnv.update_cu_co (cu=None, co=None)\n\nExample usage of [`NewsvendorEnv`](https://opimwue.github.io/ddopai/20_environments/21_envs_inventory/single_period_envs.html#newsvendorenv) with a distributional dataloader:\n\nfrom ddopai.dataloaders.distribution import NormalDistributionDataLoader\n\ndef run_test_loop(env):\n    truncated = False\n    while not truncated:\n        action = env.action_space.sample()\n        obs, reward, terminated, truncated, info = env.step(action)\n        print(\"##### STEP: \", env.index, \"#####\")\n        print(\"reward:\", reward)\n        print(\"info:\", info)\n        print(\"next observation:\", obs)\n        print(\"truncated:\", truncated)\n\ndataloader = NormalDistributionDataLoader(mean=[4, 3], std=[1, 2], num_units=2)\n\ntest_env = NewsvendorEnv(underage_cost=1, overage_cost=2, dataloader=dataloader, horizon_train=3)\n\nobs = test_env.reset(start_index=0)\nprint(\"##### RESET #####\")\n\nrun_test_loop(test_env)\n\n##### RESET #####\n##### STEP:  1 #####\nreward: -5.549075627672828\ninfo: {'demand': array([2.48613144, 4.94828011]), 'action': array([0.2829225, 1.6024134], dtype=float32), 'cost_per_SKU': array([2.20320894, 3.34586669])}\nnext observation: None\ntruncated: False\n##### STEP:  2 #####\nreward: -1.9300547300834316\ninfo: {'demand': array([3.86237064, 1.66660444]), 'action': array([2.0144682, 1.5844522], dtype=float32), 'cost_per_SKU': array([1.84790245, 0.08215228])}\nnext observation: None\ntruncated: False\n##### STEP:  3 #####\nreward: -5.19810850869845\ninfo: {'demand': array([3.45984581, 0.        ]), 'action': array([0.10056694, 0.9194148 ], dtype=float32), 'cost_per_SKU': array([3.35927887, 1.83882964])}\nnext observation: None\ntruncated: True\n\n\nExample usage of [`NewsvendorEnv`](https://opimwue.github.io/ddopai/20_environments/21_envs_inventory/single_period_envs.html#newsvendorenv) using a fixed dataset:\n\nfrom sklearn.datasets import make_regression\nfrom sklearn.preprocessing import MinMaxScaler\n\nfrom ddopai.dataloaders.tabular import XYDataLoader\n\n\n# create a simple dataset bounded between 0 and 1.\n# We just scale all the data, pretending that it is the demand.\n# When using real data, one should only fit the scaler on the training data\nX, Y = make_regression(n_samples=8, n_features=2, n_targets=2, noise=0.1, random_state=42)\nscaler = MinMaxScaler()\nX = scaler.fit_transform(X)\nY = scaler.fit_transform(Y)\n\ndataloader = XYDataLoader(X, Y, val_index_start = 4, test_index_start = 6)\ntest_env = NewsvendorEnv(underage_cost=np.array([1,1]), overage_cost=np.array([0.5,0.5]), dataloader=dataloader, horizon_train=\"use_all_data\")\n\nobs = test_env.reset(start_index=0)\nprint(\"#################### RESET ####################\")\n\nprint(\"#################### RUN IN TRAIN MODE ####################\")\nrun_test_loop(test_env)\n\nprint(\"#################### RUN IN VAL MODE ####################\")\ntest_env.val()\nrun_test_loop(test_env)\n\nprint(\"#################### RUN IN TEST MODE ####################\")\ntest_env.test()\nrun_test_loop(test_env)\n\nprint(\"#################### RUN IN TRAIN MODE AGAIN ####################\")\ntest_env.train()\nrun_test_loop(test_env)\n\n#################### RESET ####################\n#################### RUN IN TRAIN MODE ####################\n##### STEP:  1 #####\nreward: -0.5507963668644685\ninfo: {'demand': array([0.41801109, 0.41814421]), 'action': array([0.70588326, 0.01128393], dtype=float32), 'cost_per_SKU': array([0.14393609, 0.40686028])}\nnext observation: [0.51654708 0.67238019]\ntruncated: False\n##### STEP:  2 #####\nreward: -0.8714066300571378\ninfo: {'demand': array([0.61617324, 0.52211535]), 'action': array([0.180223 , 1.3930281], dtype=float32), 'cost_per_SKU': array([0.43595024, 0.43545639])}\nnext observation: [0.71467365 0.37996181]\ntruncated: False\n##### STEP:  3 #####\nreward: -1.6119519129489481\ninfo: {'demand': array([0.45242345, 0.60924132]), 'action': array([1.8277601, 2.4578085], dtype=float32), 'cost_per_SKU': array([0.68766832, 0.92428359])}\nnext observation: [0.78011439 1.        ]\ntruncated: True\n#################### RUN IN VAL MODE ####################\n##### STEP:  1 #####\nreward: -0.5815800605970438\ninfo: {'demand': array([0.        , 0.16760013]), 'action': array([0.11117006, 1.2195902 ], dtype=float32), 'cost_per_SKU': array([0.05558503, 0.52599503])}\nnext observation: [0.         0.59527916]\ntruncated: False\n##### STEP:  2 #####\nreward: -0.5828876160320575\ninfo: {'demand': array([0.33549548, 0.        ]), 'action': array([0.4501956, 1.0510751], dtype=float32), 'cost_per_SKU': array([0.05735007, 0.52553755])}\nnext observation: None\ntruncated: True\n#################### RUN IN TEST MODE ####################\n##### STEP:  1 #####\nreward: -0.7298214633019249\ninfo: {'demand': array([0.3316407 , 0.33063685]), 'action': array([0.06531169, 1.2576218 ], dtype=float32), 'cost_per_SKU': array([0.266329  , 0.46349246])}\nnext observation: [1.         0.71807281]\ntruncated: False\n##### STEP:  2 #####\nreward: -0.5407586979670338\ninfo: {'demand': array([0.8554925, 1.       ]), 'action': array([0.5619696, 1.4944715], dtype=float32), 'cost_per_SKU': array([0.29352292, 0.24723577])}\nnext observation: None\ntruncated: True\n#################### RUN IN TRAIN MODE AGAIN ####################\n##### STEP:  1 #####\nreward: -0.9409223786788338\ninfo: {'demand': array([0.41801109, 0.41814421]), 'action': array([1.3812015, 1.3367985], dtype=float32), 'cost_per_SKU': array([0.48159521, 0.45932717])}\nnext observation: [0.51654708 0.67238019]\ntruncated: False\n##### STEP:  2 #####\nreward: -0.7144824568212446\ninfo: {'demand': array([0.61617324, 0.52211535]), 'action': array([0.07493836, 0.8686105 ], dtype=float32), 'cost_per_SKU': array([0.54123488, 0.17324757])}\nnext observation: [0.71467365 0.37996181]\ntruncated: False\n##### STEP:  3 #####\nreward: -1.2616030231212196\ninfo: {'demand': array([0.45242345, 0.60924132]), 'action': array([0.84109116, 2.7437797 ], dtype=float32), 'cost_per_SKU': array([0.19433385, 1.06726917])}\nnext observation: [0.78011439 1.        ]\ntruncated: True",
    "crumbs": [
      "Environments",
      "Inventory environments",
      "Single period inventory environments"
    ]
  },
  {
    "objectID": "20_environments/21_envs_inventory/single_period_envs.html#newsvendorenvvariablesl",
    "href": "20_environments/21_envs_inventory/single_period_envs.html#newsvendorenvvariablesl",
    "title": "Single period inventory environments",
    "section": "NewsvendorEnvVariableSL",
    "text": "NewsvendorEnvVariableSL\n\n NewsvendorEnvVariableSL\n                          (sl_bound_low:Union[numpy.ndarray,ddopai.utils.P\n                          arameter,int,float]=0.1, sl_bound_high:Union[num\n                          py.ndarray,ddopai.utils.Parameter,int,float]=0.9\n                          , sl_distribution:Literal['fixed','uniform']='fi\n                          xed', evaluation_metric:Literal['pinball_loss','\n                          quantile_loss']='quantile_loss', sl_test_val:Uni\n                          on[numpy.ndarray,ddopai.utils.Parameter,int,floa\n                          t]=None, underage_cost:Union[numpy.ndarray,ddopa\n                          i.utils.Parameter,int,float]=1, overage_cost:Uni\n                          on[numpy.ndarray,ddopai.utils.Parameter,int,floa\n                          t]=1, q_bound_low:Union[numpy.ndarray,ddopai.uti\n                          ls.Parameter,int,float]=0, q_bound_high:Union[nu\n                          mpy.ndarray,ddopai.utils.Parameter,int,float]=in\n                          f, dataloader:ddopai.dataloaders.base.BaseDataLo\n                          ader=None, num_SKUs:int=None, gamma:float=1,\n                          horizon_train:int|str='use_all_data',\n                          postprocessors:list[object]|None=None,\n                          mode:str='train', return_truncation:str=True,\n                          SKUs_in_batch_dimension:bool=True)\n\nClass implementing the Newsvendor problem, working for the single- and multi-item case. If underage_cost and overage_cost are scalars and there are multiple SKUs, then the same cost is used for all SKUs. If underage_cost and overage_cost are arrays, then they must have the same length as the number of SKUs. Num_SKUs can be set as parameter or inferred from the DataLoader.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nsl_bound_low\nUnion\n0.1\nlower bound of the service level during training\n\n\nsl_bound_high\nUnion\n0.9\nupper bound of the service level during training\n\n\nsl_distribution\nLiteral\nfixed\ndistribution of the random service level during training, if fixed then the service level is fixed to sl_test_val\n\n\nevaluation_metric\nLiteral\nquantile_loss\nquantile loss is the generic quantile loss (independent of cost levels) while pinball loss uses the specific under- and overage costs\n\n\nsl_test_val\nUnion\nNone\nservice level during test and validation, alternatively use cu and co\n\n\nunderage_cost\nUnion\n1\nunderage cost per unit\n\n\noverage_cost\nUnion\n1\noverage cost per unit\n\n\nq_bound_low\nUnion\n0\nlower bound of the order quantity\n\n\nq_bound_high\nUnion\ninf\nupper bound of the order quantity\n\n\ndataloader\nBaseDataLoader\nNone\ndataloader\n\n\nnum_SKUs\nint\nNone\nif None it will be inferred from the DataLoader\n\n\ngamma\nfloat\n1\ndiscount factor\n\n\nhorizon_train\nint | str\nuse_all_data\nif “use_all_data” then horizon is inferred from the DataLoader\n\n\npostprocessors\nlist[object] | None\nNone\ndefault is empty list\n\n\nmode\nstr\ntrain\nInitial mode (train, val, test) of the environment\n\n\nreturn_truncation\nstr\nTrue\nwhether to return a truncated condition in step function\n\n\nSKUs_in_batch_dimension\nbool\nTrue\nwhether SKUs in the observation space are in the batch dimension (used for meta-learning)\n\n\nReturns\nNone\n\n\n\n\n\n\nsource\n\nNewsvendorEnvVariableSL.determine_cost\n\n NewsvendorEnvVariableSL.determine_cost (action:numpy.ndarray)\n\nDetermine the cost per SKU given the action taken. The cost is the sum of underage and overage costs.\n\n\n\n\nType\nDetails\n\n\n\n\naction\nndarray\n\n\n\nReturns\nndarray\n\n\n\n\n\nsource\n\n\nNewsvendorEnvVariableSL.set_observation_space\n\n NewsvendorEnvVariableSL.set_observation_space (shape:tuple,\n                                                low:Union[numpy.ndarray,fl\n                                                oat]=-inf, high:Union[nump\n                                                y.ndarray,float]=inf,\n                                                samples_dim_included=True)\n\nSet the observation space of the environment. This is a standard function for simple observation spaces. For more complex observation spaces, this function should be overwritten. Note that it is assumped that the first dimension is n_samples that is not relevant for the observation space.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nshape\ntuple\n\nshape of the dataloader features\n\n\nlow\nUnion\n-inf\nlower bound of the observation space\n\n\nhigh\nUnion\ninf\nupper bound of the observation space\n\n\nsamples_dim_included\nbool\nTrue\nwhether the first dimension of the shape input is the number of samples\n\n\nReturns\nNone\n\n\n\n\n\n\nsource\n\n\nNewsvendorEnvVariableSL.draw_parameter\n\n NewsvendorEnvVariableSL.draw_parameter (distribution, sl_bound_low,\n                                         sl_bound_high, samples)\n\n\n\n\n\nDetails\n\n\n\n\ndistribution\n\n\n\nsl_bound_low\n\n\n\nsl_bound_high\n\n\n\nsamples\n\n\n\n\n\nsource\n\n\nNewsvendorEnvVariableSL.get_observation\n\n NewsvendorEnvVariableSL.get_observation ()\n\nReturn the current observation. This function is for the simple case where the observation is only an x,y pair. For more complex observations, this function should be overwritten.\n\nsource\n\n\nNewsvendorEnvVariableSL.check_evaluation_metric\n\n NewsvendorEnvVariableSL.check_evaluation_metric ()\n\n\nsource\n\n\nNewsvendorEnvVariableSL.check_sl_distribution\n\n NewsvendorEnvVariableSL.check_sl_distribution ()\n\n\nsource\n\n\nNewsvendorEnvVariableSL.set_val_test_sl\n\n NewsvendorEnvVariableSL.set_val_test_sl (sl_test_val)\n\n\n\n\n\nDetails\n\n\n\n\nsl_test_val",
    "crumbs": [
      "Environments",
      "Inventory environments",
      "Single period inventory environments"
    ]
  },
  {
    "objectID": "20_environments/21_envs_inventory/multi_period_envs.html",
    "href": "20_environments/21_envs_inventory/multi_period_envs.html",
    "title": "Multi-Period Inventory Management",
    "section": "",
    "text": "run_test = False\n\nif run_test:\n    from sklearn.datasets import make_regression\n    from sklearn.preprocessing import MinMaxScaler\n    from ddopai.dataloaders.tabular import XYDataLoader\n\n    def run_test_loop(env):\n        truncated = False\n        while not truncated:\n            action = env.action_space.sample()\n            obs, reward, terminated, truncated, info = env.step(action)\n            print(\"##### STEP: \", env.index, \"#####\")\n            print(\"reward:\", reward)\n            print(\"info:\", info)\n            print(\"next observation:\")\n            for key, value in obs.items():\n                print(\"     \", key, \":\")\n                print(value)\n            print(\"truncated:\", truncated)\n\n    # create a simple dataset bounded between 0 and 1.\n    # We just scale all the data, pretending that it is the demand.\n    # When using real data, one should only fit the scaler on the training data\n    X, Y = make_regression(n_samples=8, n_features=2, n_targets=1, noise=0.1, random_state=42)\n    if len(Y.shape) == 1:\n        Y = Y.reshape(-1, 1)\n    scaler = MinMaxScaler()\n    X = scaler.fit_transform(X)\n    Y = scaler.fit_transform(Y)\n\n    dataloader = XYDataLoader(X, Y, val_index_start = 4, test_index_start = 6)\n\n    env_kwargs = dict(\n\n        q_bound_low = 0, # lower bound of the order quantity\n        q_bound_high= 1, # upper bound of the order quantity\n\n        underage_cost=0.5, # underage cost per unit\n        overage_cost=0.5, # overage cost per unit (zero in most cases)\n\n        fixed_ordering_cost=[2], # fixed ordering cost\n        variable_ordering_cost=[0.5], # variable ordering cost per unit\n\n        inventory_pipeline_params = dict(\n                                            lead_time_mean=[2], \n                                            lead_time_stochasticity=\"normal_relative\",\n                                            lead_time_variance=[0.2],\n                                            max_lead_time=[3],\n                                            min_lead_time=[1],\n                                            ),\n    )\n\n    test_env = MultiPeriodEnv(\n                            dataloader=dataloader,\n                            horizon_train=\"use_all_data\",\n                            **env_kwargs\n    )\n\n    obs = test_env.reset(start_index=0)\n    print(\"#################### RESET ####################\")\n\n    print(\"#################### RUN IN TRAIN MODE ####################\")\n    run_test_loop(test_env)\n\n    print(\"#################### RUN IN VAL MODE ####################\")\n    test_env.val()\n    run_test_loop(test_env)\n\n    print(\"#################### RUN IN TEST MODE ####################\")\n    test_env.test()\n    run_test_loop(test_env)\n\n    print(\"#################### RUN IN TRAIN MODE AGAIN ####################\")\n    test_env.train()\n    run_test_loop(test_env)\nsource",
    "crumbs": [
      "Environments",
      "Inventory environments",
      "Multi-Period Inventory Management"
    ]
  },
  {
    "objectID": "20_environments/21_envs_inventory/multi_period_envs.html#multiperiodenv",
    "href": "20_environments/21_envs_inventory/multi_period_envs.html#multiperiodenv",
    "title": "Multi-Period Inventory Management",
    "section": "MultiPeriodEnv",
    "text": "MultiPeriodEnv\n\n MultiPeriodEnv\n                 (underage_cost:numpy.ndarray|ddopai.utils.Parameter|int|f\n                 loat=1, overage_cost:numpy.ndarray|ddopai.utils.Parameter\n                 |int|float=0, fixed_ordering_cost:numpy.ndarray|ddopai.ut\n                 ils.Parameter|int|float=0, variable_ordering_cost:numpy.n\n                 darray|ddopai.utils.Parameter|int|float=0, holding_cost:n\n                 umpy.ndarray|ddopai.utils.Parameter|int|float=1, start_in\n                 ventory:numpy.ndarray|ddopai.utils.Parameter|int|float=0,\n                 max_inventory:numpy.ndarray|ddopai.utils.Parameter|int|fl\n                 oat=inf, inventory_pipeline_params:dict|None=None, q_boun\n                 d_low:numpy.ndarray|ddopai.utils.Parameter|int|float=0, q\n                 _bound_high:numpy.ndarray|ddopai.utils.Parameter|int|floa\n                 t=inf,\n                 dataloader:ddopai.dataloaders.base.BaseDataLoader=None,\n                 num_SKUs:int|None=None, gamma:float=1,\n                 horizon_train:int|str=100,\n                 postprocessors:list[object]|None=None, mode:str='train',\n                 return_truncation:bool=True, step_info_verbosity=0)\n\nXXX\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nunderage_cost\nnumpy.ndarray | ddopai.utils.Parameter | int | float\n1\nunderage cost per unit\n\n\noverage_cost\nnumpy.ndarray | ddopai.utils.Parameter | int | float\n0\noverage cost per unit (zero in most cases)\n\n\nfixed_ordering_cost\nnumpy.ndarray | ddopai.utils.Parameter | int | float\n0\nfixed ordering cost (applies per SKU, not jointly)\n\n\nvariable_ordering_cost\nnumpy.ndarray | ddopai.utils.Parameter | int | float\n0\nvariable ordering cost per unit\n\n\nholding_cost\nnumpy.ndarray | ddopai.utils.Parameter | int | float\n1\nholding cost per unit\n\n\nstart_inventory\nnumpy.ndarray | ddopai.utils.Parameter | int | float\n0\ninitial inventory\n\n\nmax_inventory\nnumpy.ndarray | ddopai.utils.Parameter | int | float\ninf\nmaximum inventory\n\n\ninventory_pipeline_params\ndict | None\nNone\nparameters for the inventory pipeline, only lead_time_mean must be given.\n\n\nq_bound_low\nnumpy.ndarray | ddopai.utils.Parameter | int | float\n0\nlower bound of the order quantity\n\n\nq_bound_high\nnumpy.ndarray | ddopai.utils.Parameter | int | float\ninf\nupper bound of the order quantity\n\n\ndataloader\nBaseDataLoader\nNone\ndataloader\n\n\nnum_SKUs\nint | None\nNone\nif None, it will be inferred from the DataLoader\n\n\ngamma\nfloat\n1\ndiscount factor\n\n\nhorizon_train\nint | str\n100\nif “use_all_data”, then horizon is inferred from the DataLoader\n\n\npostprocessors\nlist[object] | None\nNone\ndefault is an empty list\n\n\nmode\nstr\ntrain\nInitial mode (train, val, test) of the environment\n\n\nreturn_truncation\nbool\nTrue\nwhether to return a truncated condition in step function\n\n\nstep_info_verbosity\nint\n0\n0: no info, 1: some info, 2: all info\n\n\nReturns\nNone\n\n\n\n\n\n\nsource\n\nMultiPeriodEnv.step_\n\n MultiPeriodEnv.step_ (action:numpy.ndarray)\n\nXXX.\n\n\n\n\nType\nDetails\n\n\n\n\naction\nndarray\norder quantity\n\n\nReturns\nTuple\n\n\n\n\nExample usage of [`NewsvendorEnv`](https://opimwue.github.io/ddopai/20_environments/21_envs_inventory/single_period_envs.html#newsvendorenv) with a distributional dataloader:\n\n# from ddopai.dataloaders.distribution import NormalDistributionDataLoader\n\n# def run_test_loop(env):\n#     truncated = False\n#     while not truncated:\n#         action = env.action_space.sample()\n#         obs, reward, terminated, truncated, info = env.step(action)\n#         print(\"##### STEP: \", env.index, \"#####\")\n#         print(\"reward:\", reward)\n#         print(\"info:\", info)\n#         print(\"next observation:\", obs)\n#         print(\"truncated:\", truncated)\n\n# dataloader = NormalDistributionDataLoader(mean=[4, 3], std=[1, 2], num_units=2)\n\n# test_env = MultiPeriodEnv(underage_cost=1, overage_cost=2, dataloader=dataloader, horizon_train=3)\n\n# obs = test_env.reset(start_index=0)\n# print(\"##### RESET #####\")\n\n# run_test_loop(test_env)\n\nExample usage of [`NewsvendorEnv`](https://opimwue.github.io/ddopai/20_environments/21_envs_inventory/single_period_envs.html#newsvendorenv) using a fixed dataset:\n\n# from sklearn.datasets import make_regression\n# from sklearn.preprocessing import MinMaxScaler\n\n# from ddopai.dataloaders.tabular import XYDataLoader\n\n# # create a simple dataset bounded between 0 and 1.\n# # We just scale all the data, pretending that it is the demand.\n# # When using real data, one should only fit the scaler on the training data\n# X, Y = make_regression(n_samples=8, n_features=2, n_targets=2, noise=0.1, random_state=42)\n# scaler = MinMaxScaler()\n# X = scaler.fit_transform(X)\n# Y = scaler.fit_transform(Y)\n\n# dataloader = XYDataLoader(X, Y, val_index_start = 4, test_index_start = 6)\n# test_env = NewsvendorEnv(underage_cost=Parameter(np.array([1,1]), shape = (2,)), overage_cost=Parameter(np.array([0.5,0.5]), shape = (2,)), dataloader=dataloader, horizon_train=\"use_all_data\")\n\n# obs = test_env.reset(start_index=0)\n# print(\"#################### RESET ####################\")\n\n# print(\"#################### RUN IN TRAIN MODE ####################\")\n# run_test_loop(test_env)\n\n# print(\"#################### RUN IN VAL MODE ####################\")\n# test_env.val()\n# run_test_loop(test_env)\n\n# print(\"#################### RUN IN TEST MODE ####################\")\n# test_env.test()\n# run_test_loop(test_env)\n\n# print(\"#################### RUN IN TRAIN MODE AGAIN ####################\")\n# test_env.train()\n# run_test_loop(test_env)",
    "crumbs": [
      "Environments",
      "Inventory environments",
      "Multi-Period Inventory Management"
    ]
  },
  {
    "objectID": "20_environments/20_base_env/base_env.html",
    "href": "20_environments/20_base_env/base_env.html",
    "title": "Base Environment",
    "section": "",
    "text": "source",
    "crumbs": [
      "Environments",
      "Base Environment"
    ]
  },
  {
    "objectID": "20_environments/20_base_env/base_env.html#baseenvironment",
    "href": "20_environments/20_base_env/base_env.html#baseenvironment",
    "title": "Base Environment",
    "section": "BaseEnvironment",
    "text": "BaseEnvironment\n\n BaseEnvironment (mdp_info:ddopai.utils.MDPInfo,\n                  postprocessors:list[object]|None=None, mode:str='train',\n                  return_truncation:str=True,\n                  horizon_train:int|str='use_all_data')\n\nBase class for environments enforcing a common interface that works with MushroomRL, as well as other RL libraries.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nmdp_info\nMDPInfo\n\nMDPInfo object to ensure compatibility with the agents\n\n\npostprocessors\nlist[object] | None\nNone\ndefault is empty list\n\n\nmode\nstr\ntrain\nInitial mode (train, val, test) of the environment\n\n\nreturn_truncation\nstr\nTrue\nwhether to return a truncated condition in step function\n\n\nhorizon_train\nint | str\nuse_all_data\nhorizon of the training data\n\n\nReturns\nNone\n\n\n\n\n\n\nImportant notes:\ninit method:\n\nWhen adding parameters to the environment, make sure to always add them via set_param(...). This ensures all parameters are of the correct types and shapes.\nDuring the init method, any Gymnasium environment expects the action and observation space to be defined. For clarity, avoid doing it directly in the init, but rather use the functions set_action_space() and set_observation_space() and call them in the ___init___ method.\n\ntrain, val, test, and horizon (episode length):\n\nWhen the __init__ method is called, the environment executes the train(), val() or test() methods. Therefore, they must be implemented in a way that they work right during set-up.\ntrain(), val() and test() methods are provided in the base class, but can also be overwritten if necessary. In any case, they must set the dataloader to the correct dataset to ensure no data leakage. They also need to update mdp_info to update the horizon (episode length) of the environment\nThe horizon for validation and testing will be equal to the length of those datasets. For training, there is a parameter horizon_train that either contains a string “use_all_data” or an integer. If it is the former, the horizon will be the length of the training dataset. If it is the latter, the environment will play an episode of length horizon_train starting at a random point of the training dataset.\n\nstep method:\n\nThe step method is the core of the environment, calculating the next state (observation) and reward given an action. Since some frameworks expect a truncation condition (standard implementation in Gymnasium now) while others (e.g., mushroom_rl), do not, the step function is implemented in the base class and handles this (via a flag in in the environment called return_truncation). DO NOT OVERWRITE the step function, but rather implement the step_(self, action) (underscore) method in the specific environment. This function shall always return a tuple of the form (observation, reward, terminated, truncated, info).\nFor clarity, the construction of the next state (we call it more general observation to include POMDPs) is done in a separate method called get_observation() that must be called inside the step function. See documentation below and the Newsvendor environment envs.inventory.NewsvendorEnv for an example.\nThe dataloader will typically return an X,Y pair (where X are some features and Y typically is demand) The X is necessary at the end of the step to construct the next observation to be returned to the agent. The Y is only relevant one step later to calculate the reward. Hence, Y is typically transferred to the next step method via an object variable like self.demand (see envs.inventory.NewsvendorEnv as an example).\n\nobservation pre-processors and action post-processors:\n\nSometimes, it is necessary to process the observartion before giving it to the agent (e.g., changing shape) or to process the action before giving it to the environment (e.g., rounding). To ensure compatibility with mushroom_rl, the pre-processors (also called observationprocessors) sit with the agent (they must be added to the agent and are applied in the agent’s draw_action() method). The post-processors (also called actionprocessors) sit with the environment and are applied in the environment’s step() method.\n\nreset method:\n\nThe reset method may depend strongly on the environment dynamics, so it must be implemented for the specific environment. It needs to fulfill two requirements: 1) it needs to differenticate between train, val, and test mode and 2) when setting the training mode, it needs to take the horizon_train parameter into account.\nAt the end of the function, first the reset_index() method should be called (either with a specific index as integer or the flag \"random\"as input) and then the get_observation() method to construct the first observation.\n\n\nsource\n\n\nBaseEnvironment.set_param\n\n BaseEnvironment.set_param (name:str, input:Union[ddopai.utils.Parameter,i\n                            nt,float,numpy.ndarray,List,Dict,NoneType],\n                            shape:tuple=(1,), new:bool=False)\n\nSet a parameter for the environment. It converts scalar values to numpy arrays and ensures that environment parameters are either of the Parameter class of Numpy arrays. If new is set to True, the function will create a new parameter or update an existing one otherwise. If new is set to False, the function will raise an error if the parameter does not exist.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nname\nstr\n\nname of the parameter (will become the attribute name)\n\n\ninput\nUnion\n\ninput value of the parameter\n\n\nshape\ntuple\n(1,)\nshape of the parameter\n\n\nnew\nbool\nFalse\nwhether to create a new parameter or update an existing one\n\n\nReturns\nNone\n\n\n\n\n\n\nsource\n\n\nBaseEnvironment.return_truncation_handler\n\n BaseEnvironment.return_truncation_handler (observation, reward,\n                                            terminated, truncated, info)\n\nHandle the return_truncation attribute of the environment. This function is called by the step function\n\nsource\n\n\nBaseEnvironment.step\n\n BaseEnvironment.step (action)\n\nStep function of the environment. Do not overwrite this function. Instead, write the step_ function. Note that the postprocessor is applied here.\n\nsource\n\n\nBaseEnvironment.add_postprocessor\n\n BaseEnvironment.add_postprocessor (postprocessor:object)\n\nAdd a postprocessor (also called actionprocessor) to the agent\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\npostprocessor\nobject\npost-processor object that can be called via the “call” method\n\n\n\n\nsource\n\n\nBaseEnvironment.step_\n\n BaseEnvironment.step_ (action)\n\nStep function of the environment. This function contains the logic of the environment and must be provided. It will be called by the step function that applies the actionprocessor and handles the return_truncation attribute.\n\nsource\n\n\nBaseEnvironment.mdp_info\n\n BaseEnvironment.mdp_info ()\n\nReturns: The MDPInfo object of the environment.\n\nsource\n\n\nBaseEnvironment.info\n\n BaseEnvironment.info ()\n\nReturns: Alternative call to the method for mushroom_rl.\n\nsource\n\n\nBaseEnvironment.mode\n\n BaseEnvironment.mode ()\n\nReturns: A string with the current mode (train, test val) of the environment.\n\nsource\n\n\nBaseEnvironment.set_action_space\n\n BaseEnvironment.set_action_space ()\n\nSet the action space of the environment.\n\nsource\n\n\nBaseEnvironment.set_observation_space\n\n BaseEnvironment.set_observation_space ()\n\nSet the observation space of the environment. In general, this can be also a dict space, but the agent must have the appropriate pre-processor.\n\nsource\n\n\nBaseEnvironment.get_observation\n\n BaseEnvironment.get_observation ()\n\nReturn the current observation. Typically constructed from the output of the dataloader and internal dynamics (such as inventory levels, pipeline vectors, etc.) of the environment.\n\nsource\n\n\nBaseEnvironment.reset\n\n BaseEnvironment.reset ()\n\nReset the environment. This function must be provided, using the function self.reset_index() to handle indexing. It needs to account for the current training mode train, val, or test and handle the horizon_train param. See the reset function for the NewsvendorEnv for an example.\n\nsource\n\n\nBaseEnvironment.set_index\n\n BaseEnvironment.set_index (index=None)\n\nHandle the index of the environment.\n\nsource\n\n\nBaseEnvironment.get_start_index\n\n BaseEnvironment.get_start_index (start_index:int|str=None)\n\nDetermine if the start index is random or 0, depending on the state of the environment and training process (over entire train set or in shorter episodes)\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nstart_index\nint | str\nNone\nindex to start from\n\n\nReturns\nint\n\n\n\n\n\n\nsource\n\n\nBaseEnvironment.reset_index\n\n BaseEnvironment.reset_index (start_index:Union[int,str])\n\nReset the index of the environment. If start_index is an integer, the index is set to this value. If start_index is “random”, the index is set to a random integer between 0 and the length of the training data.\n\nsource\n\n\nBaseEnvironment.update_mdp_info\n\n BaseEnvironment.update_mdp_info (gamma=None, horizon=None)\n\nUpdate the MDP info of the environment.\n\nsource\n\n\nBaseEnvironment.train\n\n BaseEnvironment.train (update_mdp_info=True)\n\nSet the environment in training mode by both setting the internal state self._train and the dataloader. If the horizon is set to “use_all_data”, the horizon is set to the length of the training data, otherwise it is set to the horizon_train attribute of the environment. Finally, the function updates the MDP info and resets with the new state.\n\nsource\n\n\nBaseEnvironment.val\n\n BaseEnvironment.val (update_mdp_info=True)\n\nSet the environment in validation mode by both setting the internal state self._val and the dataloader. The horizon of val is always set to the length of the validation data. Finally, the function updates the MDP info and resets with the new state.\n\nsource\n\n\nBaseEnvironment.test\n\n BaseEnvironment.test (update_mdp_info=True)\n\nSet the environment in testing mode by both setting the internal state self._test and the dataloader. The horizon of test is always set to the length of the test data. Finally, the function updates the MDP info and resets with the new state.\n\nsource\n\n\nBaseEnvironment.set_return_truncation\n\n BaseEnvironment.set_return_truncation (return_truncation:bool)\n\nSet the return_truncation attribute of the environment.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\nreturn_truncation\nbool\nwhether or not to return the truncated condition in the step function\n\n\n\n\nsource\n\n\nBaseEnvironment.stop\n\n BaseEnvironment.stop ()\n\nStop the environment. This function is used to ensure compatibility with the Core of mushroom_rl.",
    "crumbs": [
      "Environments",
      "Base Environment"
    ]
  },
  {
    "objectID": "00_utils/loss_functions.html",
    "href": "00_utils/loss_functions.html",
    "title": "Loss functions",
    "section": "",
    "text": "source",
    "crumbs": [
      "Utils",
      "Loss functions"
    ]
  },
  {
    "objectID": "00_utils/loss_functions.html#pinball_loss",
    "href": "00_utils/loss_functions.html#pinball_loss",
    "title": "Loss functions",
    "section": "pinball_loss",
    "text": "pinball_loss\n\n pinball_loss (Y_true:numpy.ndarray, Y_pred:numpy.ndarray,\n               underage_cost:ddopai.utils.Parameter|numpy.ndarray,\n               overage_cost:ddopai.utils.Parameter|numpy.ndarray)\n\nPinball loss calculating the cost of underestimating and overestimating the target value based on specific underage and overage costs. Used to evaulate the Newsvendor cost.\n\n\n\n\nType\nDetails\n\n\n\n\nY_true\nndarray\n\n\n\nY_pred\nndarray\n\n\n\nunderage_cost\nddopai.utils.Parameter | numpy.ndarray\n\n\n\noverage_cost\nddopai.utils.Parameter | numpy.ndarray\n\n\n\nReturns\nndarray\nreturns the cost per observation\n\n\n\n\nsource",
    "crumbs": [
      "Utils",
      "Loss functions"
    ]
  },
  {
    "objectID": "00_utils/loss_functions.html#quantile_loss",
    "href": "00_utils/loss_functions.html#quantile_loss",
    "title": "Loss functions",
    "section": "quantile_loss",
    "text": "quantile_loss\n\n quantile_loss (Y_true:numpy.ndarray, Y_pred:numpy.ndarray,\n                quantile:Union[float,ddopai.utils.Parameter])\n\nSimilar evaluation function to the pinball loss, but with the quantile of range [0, 1] as a parameter instead of SKU-specific cost levels for underage and overage.\n\n\n\n\nType\nDetails\n\n\n\n\nY_true\nndarray\n\n\n\nY_pred\nndarray\n\n\n\nquantile\nUnion\n\n\n\nReturns\nndarray\nreturns the cost per observation",
    "crumbs": [
      "Utils",
      "Loss functions"
    ]
  },
  {
    "objectID": "00_utils/utils.html",
    "href": "00_utils/utils.html",
    "title": "General utils",
    "section": "",
    "text": "source",
    "crumbs": [
      "Utils",
      "General utils"
    ]
  },
  {
    "objectID": "00_utils/utils.html#mdpinfo",
    "href": "00_utils/utils.html#mdpinfo",
    "title": "General utils",
    "section": "MDPInfo",
    "text": "MDPInfo\n\n MDPInfo (observation_space:gymnasium.spaces.space.Space,\n          action_space:gymnasium.spaces.space.Space, gamma:float,\n          horizon:int, dt:float=0.1, backend:Literal['numpy']='numpy')\n\n*This class is used to store the information of the environment. It is based on MushroomRL (https://github.com/MushroomRL). It can be accessed by agents that need the information of the environment, such as the state and action spaces.\nKey difference with MushroomRL is that the state and action spaces are gymnasium spaces.*\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nobservation_space\nSpace\n\n\n\n\naction_space\nSpace\n\n\n\n\ngamma\nfloat\n\n\n\n\nhorizon\nint\n\n\n\n\ndt\nfloat\n0.1\n\n\n\nbackend\nLiteral\nnumpy\nCurrently only numpy is supported\n\n\nReturns\nNone\n\n\n\n\n\n\nsource\n\nMDPInfo.size\n\n MDPInfo.size ()\n\nReturns: The sum of the number of discrete states and discrete actions. Only works for discrete spaces.\n\nsource\n\n\nMDPInfo.shape\n\n MDPInfo.shape ()\n\nReturns: The concatenation of the shape tuple of the state and action spaces.\n\nsource",
    "crumbs": [
      "Utils",
      "General utils"
    ]
  },
  {
    "objectID": "00_utils/utils.html#datasetwrapper",
    "href": "00_utils/utils.html#datasetwrapper",
    "title": "General utils",
    "section": "DatasetWrapper",
    "text": "DatasetWrapper\n\n DatasetWrapper (dataloader:ddopai.dataloaders.base.BaseDataLoader,\n                 obsprocessors:List=None)\n\nThis class is used to wrap a Pytorch Dataset around the ddopai dataloader to enable the usage of the Pytorch Dataloader during training. This way, agents that are trained using Pytorch without interacting with the environment can directly train on the data generated by the dataloader.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndataloader\nBaseDataLoader\n\nAny dataloader that inherits from BaseDataLoader\n\n\nobsprocessors\nList\nNone\nprocessors (to mimic the environment processors)\n\n\n\n\nsource\n\nDatasetWrapper.__getitem__\n\n DatasetWrapper.__getitem__ (idx)\n\nGet the item at the provided idx.\n\nsource\n\n\nDatasetWrapper.__len__\n\n DatasetWrapper.__len__ ()\n\nReturns the length of the dataset. Depends on the state of the dataloader (train, val, test).\n\nsource\n\n\nDatasetWrapperMeta\n\n DatasetWrapperMeta (dataloader:ddopai.dataloaders.base.BaseDataLoader,\n                     draw_parameter_function:&lt;built-\n                     infunctioncallable&gt;=None, distribution:Union[Literal[\n                     'fixed','uniform'],List]='fixed',\n                     parameter_names:List[str]=None,\n                     bounds_low:Union[int,float,List]=0,\n                     bounds_high:Union[int,float,List]=1,\n                     obsprocessors:List=None)\n\nThis class is used to wrap a Pytorch Dataset around the ddopai dataloader to enable the usage of the Pytorch Dataloader during training. This way, agents that are trained using Pytorch without interacting with the environment can directly train on the data generated by the dataloader.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndataloader\nBaseDataLoader\n\nAny dataloader that inherits from BaseDataLoader\n\n\ndraw_parameter_function\ncallable\nNone\nfunction to draw parameters from distribution\n\n\ndistribution\nUnion\nfixed\ndistribution for params during training, can be List for multiple parameters\n\n\nparameter_names\nList\nNone\nnames of the parameters\n\n\nbounds_low\nUnion\n0\nlower bound for params during training, can be List for multiple parameters\n\n\nbounds_high\nUnion\n1\nupper bound for params during training, can be List for multiple parameters\n\n\nobsprocessors\nList\nNone\nprocessors (to mimic the environment processors)\n\n\n\n\nsource",
    "crumbs": [
      "Utils",
      "General utils"
    ]
  },
  {
    "objectID": "00_utils/utils.html#merge_dictionaries",
    "href": "00_utils/utils.html#merge_dictionaries",
    "title": "General utils",
    "section": "merge_dictionaries",
    "text": "merge_dictionaries\n\n merge_dictionaries (dict1, dict2)\n\nMerge two dictionaries. If a key is found in both dictionaries, raise a KeyError.\n\nsource",
    "crumbs": [
      "Utils",
      "General utils"
    ]
  },
  {
    "objectID": "00_utils/utils.html#set_param",
    "href": "00_utils/utils.html#set_param",
    "title": "General utils",
    "section": "set_param",
    "text": "set_param\n\n set_param (obj, name:str, input:Union[__main__.Parameter,int,float,numpy.\n            ndarray,List,Dict,NoneType], shape:tuple=(1,), new:bool=False)\n\nSet a parameter for the class. It converts scalar values to numpy arrays and ensures that environment parameters are either of the Parameter class of Numpy arrays. If new is set to True, the function will create a new parameter or update an existing one otherwise. If new is set to False, the function will raise an error if the parameter does not exist.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nobj\n\n\n\n\n\nname\nstr\n\nname of the parameter (will become the attribute name)\n\n\ninput\nUnion\n\ninput value of the parameter\n\n\nshape\ntuple\n(1,)\nshape of the parameter\n\n\nnew\nbool\nFalse\nwhether to create a new parameter or update an existing one",
    "crumbs": [
      "Utils",
      "General utils"
    ]
  },
  {
    "objectID": "00_utils/torch_loss_functions.html",
    "href": "00_utils/torch_loss_functions.html",
    "title": "Torch loss functions",
    "section": "",
    "text": "source",
    "crumbs": [
      "Utils",
      "Torch loss functions"
    ]
  },
  {
    "objectID": "00_utils/torch_loss_functions.html#torchquantileloss",
    "href": "00_utils/torch_loss_functions.html#torchquantileloss",
    "title": "Torch loss functions",
    "section": "TorchQuantileLoss",
    "text": "TorchQuantileLoss\n\n TorchQuantileLoss (reduction:str='mean')\n\nImplmentation of the quantile loss in Pytorch. Unlike the Numpy-based implementation [`quantile_loss`](https://opimwue.github.io/ddopai/00_utils/torch_loss_functions.html#quantile_loss) in the loss_functions module, this implementation this implementation reduces the results to a scalar value using the specified reduction method. This class is used to train Pytorch models using the quantile loss.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nreduction\nstr\nmean\n\n\n\nReturns\nNone\n\n\n\n\n\n\nsource\n\nTorchQuantileLoss.forward\n\n TorchQuantileLoss.forward (input:torch.Tensor, target:torch.Tensor,\n                            quantile:ddopai.utils.Parameter|numpy.ndarray)\n\nForward pass of the quantile loss function.\n\n\n\n\nType\nDetails\n\n\n\n\ninput\nTensor\n\n\n\ntarget\nTensor\n\n\n\nquantile\nddopai.utils.Parameter | numpy.ndarray\n\n\n\nReturns\nTensor\n\n\n\n\n\nsource\n\n\npinball_loss\n\n pinball_loss (input:torch.Tensor, target:torch.Tensor,\n               underage:torch.Tensor, overage:torch.Tensor,\n               reduction:str='mean')\n\n\nsource",
    "crumbs": [
      "Utils",
      "Torch loss functions"
    ]
  },
  {
    "objectID": "00_utils/torch_loss_functions.html#torchpinballloss",
    "href": "00_utils/torch_loss_functions.html#torchpinballloss",
    "title": "Torch loss functions",
    "section": "TorchPinballLoss",
    "text": "TorchPinballLoss\n\n TorchPinballLoss (reduction:str='mean')\n\nImplmentation of the pinball loss in Pytorch using specific overage and underage cost. For the pinball loss based on quantiles directly, use the TorchQuantileLoss class. Unlike the Numpy-based implementation [`pinball_loss`](https://opimwue.github.io/ddopai/00_utils/torch_loss_functions.html#pinball_loss) in the loss_functions module, this implementation this implementation reduces the results to a scalar value using the specified reduction method. This class is used to train Pytorch models using the pinball loss.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nreduction\nstr\nmean\n\n\n\nReturns\nNone\n\n\n\n\n\n\nsource\n\nTorchPinballLoss.forward\n\n TorchPinballLoss.forward (input:torch.Tensor, target:torch.Tensor,\n                           underage:ddopai.utils.Parameter|numpy.ndarray,\n                           overage:ddopai.utils.Parameter|numpy.ndarray)\n\nForward pass of the pinball loss function.\n\n\n\n\nType\nDetails\n\n\n\n\ninput\nTensor\n\n\n\ntarget\nTensor\n\n\n\nunderage\nddopai.utils.Parameter | numpy.ndarray\n\n\n\noverage\nddopai.utils.Parameter | numpy.ndarray\n\n\n\nReturns\nTensor",
    "crumbs": [
      "Utils",
      "Torch loss functions"
    ]
  },
  {
    "objectID": "20_environments/actionprocessors.html",
    "href": "20_environments/actionprocessors.html",
    "title": "Actionprocessors",
    "section": "",
    "text": "source",
    "crumbs": [
      "Environments",
      "Actionprocessors"
    ]
  },
  {
    "objectID": "20_environments/actionprocessors.html#roundaction",
    "href": "20_environments/actionprocessors.html#roundaction",
    "title": "Actionprocessors",
    "section": "RoundAction",
    "text": "RoundAction\n\n RoundAction (unit_size:Union[float,int,numpy.ndarray])\n\nA class to round input values to the nearest specified unit size. Unit size can be any decimal value like 10, 3, 1, 0.1, 0.03, etc.\n\n\n\n\nType\nDetails\n\n\n\n\nunit_size\nUnion\n\n\n\n\n\nsource\n\nRoundAction._validate_unit_size\n\n RoundAction._validate_unit_size\n                                  (unit_size:Union[float,int,numpy.ndarray\n                                  ])\n\nEnsures that the unit size is a positive float, int, or a numpy array of positive values.\n\nsource\n\n\nRoundAction.__call__\n\n RoundAction.__call__ (input:numpy.ndarray)\n\nRounds the input array to the nearest specified unit size.\nExample usage of [`RoundAction`](https://opimwue.github.io/ddopai/20_environments/actionprocessors.html#roundaction). Expected result:\n[1. 2. 4. 5. 6.]\n[0.1 0.4]\n[ 0. 12. 6. 0. 0. 0. 3.]\n\ninput = np.array([1.1, 2.5, 3.5, 4.6, 5.9])\nround_action = RoundAction(1)\nprint(round_action(input))\n\ninput = np.array([0.12, 0.39])\nround_action = RoundAction(0.1)\nprint(round_action(input))\n\ninput = np.array([1.1231, 12.13, 7, 0.5, 1.4, 1.5, 1.6])\nround_action = RoundAction(3)\nprint(round_action(input))\n\n[1. 2. 4. 5. 6.]\n[0.1 0.4]\n[ 0. 12.  6.  0.  0.  0.  3.]\n\n\n\nsource",
    "crumbs": [
      "Environments",
      "Actionprocessors"
    ]
  },
  {
    "objectID": "20_environments/actionprocessors.html#movebatchtoproductdim",
    "href": "20_environments/actionprocessors.html#movebatchtoproductdim",
    "title": "Actionprocessors",
    "section": "MoveBatchToProductDim",
    "text": "MoveBatchToProductDim\n\n MoveBatchToProductDim (remove_action_per_unit_dim:bool=False)\n\nA class that moves the first dimension to the last place. Usefull for meta learners that return the predictions of various units in the batch dimension while in environment the num_unit (e.g., num_SKU) dimension is usually the last one\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nremove_action_per_unit_dim\nbool\nFalse\nIf there is only one action per unit, the action dimension can be removed by setting this to True\n\n\n\n\nsource\n\nMoveBatchToProductDim.__call__\n\n MoveBatchToProductDim.__call__ (input:numpy.ndarray)\n\nMoves the first dimension to the last place.",
    "crumbs": [
      "Environments",
      "Actionprocessors"
    ]
  },
  {
    "objectID": "20_environments/21_envs_inventory/base_inventory_env.html",
    "href": "20_environments/21_envs_inventory/base_inventory_env.html",
    "title": "Base inventory env",
    "section": "",
    "text": "source",
    "crumbs": [
      "Environments",
      "Inventory environments",
      "Base inventory env"
    ]
  },
  {
    "objectID": "20_environments/21_envs_inventory/base_inventory_env.html#baseinventoryenv",
    "href": "20_environments/21_envs_inventory/base_inventory_env.html#baseinventoryenv",
    "title": "Base inventory env",
    "section": "BaseInventoryEnv",
    "text": "BaseInventoryEnv\n\n BaseInventoryEnv (mdp_info:ddopai.utils.MDPInfo,\n                   postprocessors:list[object]|None=None,\n                   mode:str='train', return_truncation:str=True,\n                   dataloader:ddopai.dataloaders.base.BaseDataLoader=None,\n                   horizon_train:int=100, underage_cost:Union[numpy.ndarra\n                   y,ddopai.utils.Parameter,int,float]=1, overage_cost:Uni\n                   on[numpy.ndarray,ddopai.utils.Parameter,int,float]=0)\n\nBase class for inventory management environments. This class inherits from BaseEnvironment.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nmdp_info\nMDPInfo\n\n\n\n\npostprocessors\nlist[object] | None\nNone\ndefault is empty list\n\n\nmode\nstr\ntrain\nInitial mode (train, val, test) of the environment\n\n\nreturn_truncation\nstr\nTrue\nwhether to return a truncated condition in step function\n\n\ndataloader\nBaseDataLoader\nNone\ndataloader for the environment\n\n\nhorizon_train\nint\n100\nhorizon for training mode\n\n\nunderage_cost\nUnion\n1\nunderage cost per unit\n\n\noverage_cost\nUnion\n0\noverage cost per unit (zero in most cases)\n\n\nReturns\nNone\n\n\n\n\n\n\nsource\n\nBaseInventoryEnv.set_observation_space\n\n BaseInventoryEnv.set_observation_space (shape:tuple,\n                                         low:Union[numpy.ndarray,float]=-\n                                         inf, high:Union[numpy.ndarray,flo\n                                         at]=inf,\n                                         samples_dim_included=True)\n\nSet the observation space of the environment. This is a standard function for simple observation spaces. For more complex observation spaces, this function should be overwritten. Note that it is assumped that the first dimension is n_samples that is not relevant for the observation space.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nshape\ntuple\n\nshape of the dataloader features\n\n\nlow\nUnion\n-inf\nlower bound of the observation space\n\n\nhigh\nUnion\ninf\nupper bound of the observation space\n\n\nsamples_dim_included\nbool\nTrue\nwhether the first dimension of the shape input is the number of samples\n\n\nReturns\nNone\n\n\n\n\n\n\nsource\n\n\nBaseInventoryEnv.set_action_space\n\n BaseInventoryEnv.set_action_space (shape:tuple,\n                                    low:Union[numpy.ndarray,float]=-inf,\n                                    high:Union[numpy.ndarray,float]=inf,\n                                    samples_dim_included=True)\n\nSet the action space of the environment. This is a standard function for simple action spaces. For more complex action spaces, this function should be overwritten. Note that it is assumped that the first dimension is n_samples that is not relevant for the action space.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nshape\ntuple\n\nshape of the dataloader target\n\n\nlow\nUnion\n-inf\nlower bound of the observation space\n\n\nhigh\nUnion\ninf\nupper bound of the observation space\n\n\nsamples_dim_included\nbool\nTrue\nwhether the first dimension of the shape input is the number of samples\n\n\nReturns\nNone\n\n\n\n\n\n\nsource\n\n\nBaseInventoryEnv.reset\n\n BaseInventoryEnv.reset (start_index:int|str=None,\n                         state:numpy.ndarray=None)\n\nReset function for the Newsvendor problem. It will return the first observation and demand. For val and test modes, it will by default reset to 0, while for the train mode it depends on the paramter “horizon_train” whether a random point in the training data is selected or 0\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nstart_index\nint | str\nNone\nindex to start from\n\n\nstate\nndarray\nNone\ninitial state\n\n\nReturns\nTuple\n\n\n\n\n\n\nsource\n\n\nBaseInventoryEnv.get_observation\n\n BaseInventoryEnv.get_observation ()\n\nReturn the current observation. This function is for the simple case where the observation is only an x,y pair. For more complex observations, this function should be overwritten.",
    "crumbs": [
      "Environments",
      "Inventory environments",
      "Base inventory env"
    ]
  },
  {
    "objectID": "20_environments/21_envs_inventory/inventory_utils.html",
    "href": "20_environments/21_envs_inventory/inventory_utils.html",
    "title": "Inventory utils",
    "section": "",
    "text": "source",
    "crumbs": [
      "Environments",
      "Inventory environments",
      "Inventory utils"
    ]
  },
  {
    "objectID": "20_environments/21_envs_inventory/inventory_utils.html#orderpipeline",
    "href": "20_environments/21_envs_inventory/inventory_utils.html#orderpipeline",
    "title": "Inventory utils",
    "section": "OrderPipeline",
    "text": "OrderPipeline\n\n OrderPipeline (num_units:int, lead_time_mean:Union[ddopai.utils.Parameter\n                ,numpy.ndarray,List,int,float], lead_time_stochasticity:Li\n                teral['fixed','gamma','normal_absolute','normal_relative']\n                ='fixed', lead_time_variance:Union[ddopai.utils.Parameter,\n                numpy.ndarray,List,int,float,NoneType]=None,\n                max_lead_time:list[object]|None=None,\n                min_lead_time:list[object]|None=1)\n\nClass to handle the order pipeline in the inventory environments. It is used to keep track of the orders that are placed. It can account for fixed and variable lead times.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nnum_units\nint\n\nnumber of units (SKUs)\n\n\nlead_time_mean\nUnion\n\nmean lead time\n\n\nlead_time_stochasticity\nLiteral\nfixed\n“fixed”, “gamma”, “normal_absolute”, “normal_relative”\n\n\nlead_time_variance\nUnion\nNone\nvariance of the lead time\n\n\nmax_lead_time\nlist[object] | None\nNone\nmaximum lead time in case of stochastic lead times\n\n\nmin_lead_time\nlist[object] | None\n1\nminimum lead time in case of stochastic lead times\n\n\nReturns\nNone\n\n\n\n\n\n\nsource\n\nOrderPipeline.get_pipeline\n\n OrderPipeline.get_pipeline ()\n\nGet the current pipeline\n\nsource\n\n\nOrderPipeline.reset\n\n OrderPipeline.reset ()\n\nReset the pipeline\n\nsource\n\n\nOrderPipeline.step\n\n OrderPipeline.step (orders:numpy.ndarray)\n\nAdd orders to the pipeline and return the orders that are arriving\n\nsource\n\n\nOrderPipeline.get_orders_arriving\n\n OrderPipeline.get_orders_arriving ()\n\nGet the orders that are arriving in the current period\n\nsource\n\n\nOrderPipeline.draw_lead_times\n\n OrderPipeline.draw_lead_times ()\n\nDraw lead times for the orders\n\nsource\n\n\nOrderPipeline.check_stochasticity\n\n OrderPipeline.check_stochasticity (max_lead_time)\n\nCheck that params for stochastic lead times are set correctly\n\nsource\n\n\nOrderPipeline.check_max_min_mean_lt\n\n OrderPipeline.check_max_min_mean_lt ()\n\n\nsource\n\n\nOrderPipeline.set_param\n\n OrderPipeline.set_param (name:str,\n                          input:Union[ddopai.utils.Parameter,int,float,num\n                          py.ndarray,List], shape:tuple=(1,),\n                          new:bool=False)\n\nSet a parameter for the environment. It converts scalar values to numpy arrays and ensures that environment parameters are either of the Parameter class of Numpy arrays. If new is set to True, the function will create a new parameter or update an existing one otherwise. If new is set to False, the function will raise an error if the parameter does not exist.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nname\nstr\n\nname of the parameter (will become the attribute name)\n\n\ninput\nUnion\n\ninput value of the parameter\n\n\nshape\ntuple\n(1,)\nshape of the parameter\n\n\nnew\nbool\nFalse\nwhether to create a new parameter or update an existing one\n\n\nReturns\nNone\n\n\n\n\n\n\nsource\n\n\nOrderPipeline.shape\n\n OrderPipeline.shape ()\n\nGet the shape of the pipeline",
    "crumbs": [
      "Environments",
      "Inventory environments",
      "Inventory utils"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ddopai",
    "section": "",
    "text": "pip install ddopai",
    "crumbs": [
      "ddopai"
    ]
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "ddopai",
    "section": "",
    "text": "pip install ddopai",
    "crumbs": [
      "ddopai"
    ]
  },
  {
    "objectID": "index.html#what-is-ddopai",
    "href": "index.html#what-is-ddopai",
    "title": "ddopai",
    "section": "What is ddopai?",
    "text": "What is ddopai?\nTo be written.",
    "crumbs": [
      "ddopai"
    ]
  },
  {
    "objectID": "index.html#what-is-the-difference-to-gymnasium-and-how-to-convert-gymnasium-environments",
    "href": "index.html#what-is-the-difference-to-gymnasium-and-how-to-convert-gymnasium-environments",
    "title": "ddopai",
    "section": "What is the difference to Gymnasium and how to convert Gymnasium Environments?",
    "text": "What is the difference to Gymnasium and how to convert Gymnasium Environments?\nTo make any enviroment compatible with mushroomRL and other agents defined within ddopai, there are some additional requirements when defining the environment. Instead of inheriting from gym.Env, the environment should inherit from ddopai.envs.base.BaseEnvironment. This base class provides some additional necessary methods and attributes to ensure compatibility with the agents. Below are the steps to convert a Gym environment to a ddopai environment. We strongly recommend you to also look at the implementation of the NewsvendorEnv (nbs/20_environments/21_envs_inventory/20_single_period_envs.ipynb) as an example.\n\n1. Initialization and Parameter Setup\n\nIn the __init__ method of your environment, ensure that any environment-specific parameters are added using the set_param(...) method. This guarantees the correct types and shapes for the parameters.\nDefine the action and observation spaces using set_action_space() and set_observation_space() respectively. These should be called within the __init__ method, rather than defining the spaces directly.\nIn the __init__, and MDPInfo object needs to be created mdp_info = MDPInfo(self.observation_space, self.action_space, gamma=gamma, horizon=horizon_train)\n\n\n\n2. Handling Train, Validation, Test, and Horizon\n\nImplement or override the train(), val(), and test() methods to configure the correct datasets for each phase, ensuring no data leakage. The base class provides these methods, but you may need to adapt them based on your environment.\nUpdate the mdp_info to set the horizon (episode length). For validation and testing, the horizon corresponds to the length of the dataset, while for training, the horizon is determined by the horizon_train parameter. If horizon_train is \"use_all_data\", the full dataset is used; if it’s an integer, a random subset is used.\n\n\n\n3. Step Method\n\nThe step() method is handled in the base class, so instead of overriding it, implement a step_(self, action) method for the specific environment. This method should return a tuple: (observation, reward, terminated, truncated, info).\nThe next observation should be constructed using the get_observation() method, which must be called inside the step_() method. Make sure to correctly pass the demand (or equivalent) to the next step to calculate rewards.\n\n\n\n4. Pre- and Post-Processing\n\nAction post-processing should be done within the environment, in the step() method, to ensure the action is in the correct form for the environment.\nObservation pre-processing, however, is handled by the agent in MushroomRL. This processing takes place in the agent’s draw_action() method.\n\n\n\n5. Reset Method\n\nThe reset() method must differentiate between the training, validation, and testing modes, and it should consider the horizon_train parameter for training.\nAfter setting up the mode and horizon, call reset_index() (with an integer index or \"random\") to initialize the environment. Finally, use get_observation() to provide the initial observation to the agent.",
    "crumbs": [
      "ddopai"
    ]
  },
  {
    "objectID": "30_agents/41_NV_agents/nv_saa_agents.html",
    "href": "30_agents/41_NV_agents/nv_saa_agents.html",
    "title": "SAA based agents",
    "section": "",
    "text": "source",
    "crumbs": [
      "Agents",
      "Newsvendor_agents",
      "SAA based agents"
    ]
  },
  {
    "objectID": "30_agents/41_NV_agents/nv_saa_agents.html#basesaaagent",
    "href": "30_agents/41_NV_agents/nv_saa_agents.html#basesaaagent",
    "title": "SAA based agents",
    "section": "BaseSAAagent",
    "text": "BaseSAAagent\n\n BaseSAAagent (environment_info:ddopai.utils.MDPInfo,\n               obsprocessors:Optional[List[object]]=None,\n               agent_name:str|None=None)\n\nBase class for Sample Average Approximation Agents, implementing the main method to find the quntile of some (weighted) empirical distribution.\n\nsource\n\nBaseSAAagent._validate_X_predict\n\n BaseSAAagent._validate_X_predict (X)\n\nValidate X data before prediction\n\nsource\n\n\nBaseSAAagent.find_weighted_quantiles\n\n BaseSAAagent.find_weighted_quantiles (weights, weightPosIndices, sl, y)\n\nFind the weighted quantile of a range of data y. It assumes that all arrays are of shape (n_samples, n_outputs). Note that it has not been tested for n_outputs &gt; 1.\n\nsource",
    "crumbs": [
      "Agents",
      "Newsvendor_agents",
      "SAA based agents"
    ]
  },
  {
    "objectID": "30_agents/41_NV_agents/nv_saa_agents.html#newsvendorsaaagent",
    "href": "30_agents/41_NV_agents/nv_saa_agents.html#newsvendorsaaagent",
    "title": "SAA based agents",
    "section": "NewsvendorSAAagent",
    "text": "NewsvendorSAAagent\n\n NewsvendorSAAagent (environment_info:ddopai.utils.MDPInfo,\n                     cu:float|numpy.ndarray, co:float|numpy.ndarray,\n                     obsprocessors:list[object]|None=None,\n                     agent_name:str='SAA')\n\nNewsvendor agent that uses Sample Average Approximation to find the quantile of the empirical distribution\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nenvironment_info\nMDPInfo\n\n\n\n\ncu\nfloat | numpy.ndarray\n\nunderage cost\n\n\nco\nfloat | numpy.ndarray\n\noverage cost\n\n\nobsprocessors\nlist[object] | None\nNone\n\n\n\nagent_name\nstr\nSAA\n\n\n\n\n\nFurther information:\nReferences:\n.. [1] Levi, Retsef, Georgia Perakis, and Joline Uichanco. \"The data-driven newsvendor problem: new bounds and insights.\"\n       Operations Research 63.6 (2015): 1294-1306.\n\nsource\n\n\nNewsvendorSAAagent.fit\n\n NewsvendorSAAagent.fit (X:numpy.ndarray, Y:numpy.ndarray)\n\nFit the agent to the data. The agent will find the quantile of the empirical distribution of the data.\n\n\n\n\nType\nDetails\n\n\n\n\nX\nndarray\nfeatures will be ignored\n\n\nY\nndarray\n\n\n\nReturns\nNone\n\n\n\n\n\nsource\n\n\nNewsvendorSAAagent.draw_action_\n\n NewsvendorSAAagent.draw_action_ (observation:numpy.ndarray)\n\nDraw an action from the quantile of the empirical distribution.\n\n\n\n\nType\nDetails\n\n\n\n\nobservation\nndarray\n\n\n\nReturns\nndarray\n\n\n\n\n\nsource\n\n\nNewsvendorSAAagent.save\n\n NewsvendorSAAagent.save (path:str, overwrite:bool=True)\n\nSave the quantiles to a file in the specified directory.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\n\nThe directory where the file will be saved.\n\n\noverwrite\nbool\nTrue\nAllow overwriting; if False, a FileExistsError will be raised if the file exists.\n\n\n\n\nsource\n\n\nNewsvendorSAAagent.load\n\n NewsvendorSAAagent.load (path:str)\n\nLoad the quantiles from a file.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\npath\nstr\nOnly the path to the folder is needed, not the file itself\n\n\n\n\nsource",
    "crumbs": [
      "Agents",
      "Newsvendor_agents",
      "SAA based agents"
    ]
  },
  {
    "objectID": "30_agents/41_NV_agents/nv_saa_agents.html#basewsaaagent",
    "href": "30_agents/41_NV_agents/nv_saa_agents.html#basewsaaagent",
    "title": "SAA based agents",
    "section": "BasewSAAagent",
    "text": "BasewSAAagent\n\n BasewSAAagent (environment_info:ddopai.utils.MDPInfo,\n                cu:float|numpy.ndarray, co:float|numpy.ndarray,\n                obsprocessors:list[object]|None=None,\n                agent_name:str='wSAA')\n\nBase class for weighted Sample Average Approximation (wSAA) Agents\n\nsource\n\nBasewSAAagent.fit\n\n BasewSAAagent.fit (X:numpy.ndarray, Y:numpy.ndarray)\n\n*Fit the agent to the data. The function will call _get_fitted_model which will train a machine learning model to determine the sample weightes (e.g., kNN, DT, RF).*\n\n\n\n\nType\nDetails\n\n\n\n\nX\nndarray\n\n\n\nY\nndarray\n\n\n\n\n\nsource\n\n\nBaseAgent.draw_action\n\n BaseAgent.draw_action (observation:numpy.ndarray)\n\nMain interfrace to the environemnt. Applies preprocessors to the observation. Internal logic of the agent to be implemented in draw_action_ method.\n\n\n\n\nType\nDetails\n\n\n\n\nobservation\nndarray\n\n\n\nReturns\nndarray\n\n\n\n\n\nsource\n\n\nBasewSAAagent._get_fitted_model\n\n BasewSAAagent._get_fitted_model (X, y)\n\nInitialise the underlying model - depending on the underlying machine learning model\n\nsource\n\n\nBasewSAAagent._calc_weights\n\n BasewSAAagent._calc_weights (sample)\n\nCalculate the sample weights - depending on the underlying machine learning model\n\nsource\n\n\nBasewSAAagent.predict\n\n BasewSAAagent.predict (X:numpy.ndarray)\n\nPredict value for X by finding the quantiles of the empirical distribution based on the sample weights predicted by the underlying machine learning model.\n\n\n\n\nType\nDetails\n\n\n\n\nX\nndarray\n\n\n\nReturns\nndarray\n\n\n\n\n\nsource\n\n\nBasewSAAagent.save\n\n BasewSAAagent.save (path:str, overwrite:bool=True)\n\nSave the scikit-learn model to a file in the specified directory.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npath\nstr\n\nThe directory where the file will be saved.\n\n\noverwrite\nbool\nTrue\nAllow overwriting; if False, a FileExistsError will be raised if the file exists.\n\n\n\n\nsource\n\n\nBasewSAAagent.load\n\n BasewSAAagent.load (path:str)\n\nLoad the scikit-learn model from a file.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\npath\nstr\nOnly the path to the folder is needed, not the file itself\n\n\n\n\nsource",
    "crumbs": [
      "Agents",
      "Newsvendor_agents",
      "SAA based agents"
    ]
  },
  {
    "objectID": "30_agents/41_NV_agents/nv_saa_agents.html#newsvendorrfwsaaagent",
    "href": "30_agents/41_NV_agents/nv_saa_agents.html#newsvendorrfwsaaagent",
    "title": "SAA based agents",
    "section": "NewsvendorRFwSAAagent",
    "text": "NewsvendorRFwSAAagent\n\n NewsvendorRFwSAAagent (environment_info:ddopai.utils.MDPInfo,\n                        cu:float|numpy.ndarray, co:float|numpy.ndarray,\n                        obsprocessors:list[object]|None=None,\n                        n_estimators:int=100,\n                        criterion:str='squared_error',\n                        max_depth:int|None=None, min_samples_split:int=2,\n                        min_samples_leaf:int=1,\n                        min_weight_fraction_leaf:float=0.0,\n                        max_features:int|float|str|None=1.0,\n                        max_leaf_nodes:int|None=None,\n                        min_impurity_decrease:float=0.0,\n                        bootstrap:bool=True, oob_score:bool=False,\n                        n_jobs:int|None=None, random_state:int|numpy.rando\n                        m.mtrand.RandomState|None=None, verbose:int=0,\n                        warm_start:bool=False, ccp_alpha:float=0.0,\n                        max_samples:int|float|None=None,\n                        monotonic_cst:numpy.ndarray|None=None,\n                        agent_name:str='wSAA')\n\nNewsvendor agent that uses weighted Sample Average Approximation based on Random Forest\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nenvironment_info\nMDPInfo\n\n\n\n\ncu\nfloat | numpy.ndarray\n\nunderage cost\n\n\nco\nfloat | numpy.ndarray\n\noverage cost\n\n\nobsprocessors\nlist[object] | None\nNone\nList of obsprocessors to apply to the observation\n\n\nn_estimators\nint\n100\nThe number of trees in the forest.\n\n\ncriterion\nstr\nsquared_error\nFunction to measure the quality of a split.\n\n\nmax_depth\nint | None\nNone\nMaximum depth of the tree; None means unlimited.\n\n\nmin_samples_split\nint\n2\nMinimum samples required to split a node.\n\n\nmin_samples_leaf\nint\n1\nMinimum samples required to be at a leaf node.\n\n\nmin_weight_fraction_leaf\nfloat\n0.0\nMinimum weighted fraction of the total weights at a leaf node.\n\n\nmax_features\nint | float | str | None\n1.0\nNumber of features to consider when looking for the best split.\n\n\nmax_leaf_nodes\nint | None\nNone\nMaximum number of leaf nodes; None means unlimited.\n\n\nmin_impurity_decrease\nfloat\n0.0\nMinimum impurity decrease required to split a node.\n\n\nbootstrap\nbool\nTrue\nWhether to use bootstrap samples when building trees.\n\n\noob_score\nbool\nFalse\nWhether to use out-of-bag samples to estimate R^2 on unseen data.\n\n\nn_jobs\nint | None\nNone\nNumber of jobs to run in parallel; None means 1.\n\n\nrandom_state\nint | numpy.random.mtrand.RandomState | None\nNone\nControls randomness for bootstrapping and feature sampling.\n\n\nverbose\nint\n0\nControls the verbosity when fitting and predicting.\n\n\nwarm_start\nbool\nFalse\nIf True, reuse solution from previous fit and add more estimators.\n\n\nccp_alpha\nfloat\n0.0\nComplexity parameter for Minimal Cost-Complexity Pruning.\n\n\nmax_samples\nint | float | None\nNone\nNumber of samples to draw when bootstrap is True.\n\n\nmonotonic_cst\nnumpy.ndarray | None\nNone\nMonotonic constraints for features.\n\n\nagent_name\nstr\nwSAA\nDefault wSAA, change if it is needed to differentiate among different ML models\n\n\n\n\nFurther information:\nNotes —–\nThe default values for the parameters controlling the size of the trees (e.g. max_depth, min_samples_leaf, etc.) lead to fully grown and unpruned trees which can potentially be very large on some data sets. To reduce memory consumption, the complexity and size of the trees should be controlled by setting those parameter values. The features are always randomly permuted at each split. Therefore, the best found split may vary, even with the same training data, max_features=n_features and bootstrap=False, if the improvement of the criterion is identical for several splits enumerated during the search of the best split. To obtain a deterministic behaviour during fitting, random_state has to be fixed.\nReferences ———-\n.. [1] L. Breiman, \"Random Forests\", Machine Learning, 45(1), 5-32, 2001.\n\n.. [2] P. Geurts, D. Ernst., and L. Wehenkel, \"Extremely randomized\n       trees\", Machine Learning, 63(1), 3-42, 2006.\n\n.. [3] Bertsimas, Dimitris, and Nathan Kallus, \"From predictive to prescriptive analytics.\"\n       arXiv preprint arXiv:1402.5481 (2014).\n\n.. [4] scikit-learn, RandomForestRegressor,\n       &lt;https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/ensemble/_forest.py&gt;\n       \n.. [5] Scornet, Erwan. \"Random forests and kernel methods.\"\n       IEEE Transactions on Information Theory 62.3 (2016): 1485-1500.\n\nsource\n\n\nNewsvendorRFwSAAagent._get_fitted_model\n\n NewsvendorRFwSAAagent._get_fitted_model (X:numpy.ndarray,\n                                          Y:numpy.ndarray)\n\nFit the underlying machine learning model using all X and Y data in the train set.\n\n\n\n\nType\nDetails\n\n\n\n\nX\nndarray\n\n\n\nY\nndarray\n\n\n\n\n\nsource\n\n\nNewsvendorRFwSAAagent._calc_weights\n\n NewsvendorRFwSAAagent._calc_weights (sample:numpy.ndarray)\n\nCalculate the sample weights based on the Random Forest model.\n\n\n\n\nType\nDetails\n\n\n\n\nsample\nndarray\n\n\n\nReturns\ntuple\n\n\n\n\nExample usage:\n\nfrom ddopai.envs.inventory.single_period import NewsvendorEnv\nfrom ddopai.dataloaders.tabular import XYDataLoader\nfrom ddopai.experiments.experiment_functions import run_experiment, test_agent\n\n\nval_index_start = 800 #90_000\ntest_index_start = 900 #100_000\n\nX = np.random.rand(1000, 2)\nY = np.random.rand(1000, 1)\n\ndataloader = XYDataLoader(X, Y, val_index_start, test_index_start)\n\nenvironment = NewsvendorEnv(\n    dataloader = dataloader,\n    underage_cost = 0.42857,\n    overage_cost = 1.0,\n    gamma = 0.999,\n    horizon_train = 365,\n)\n\nagent = NewsvendorSAAagent(environment.mdp_info, cu=0.42857, co=1.0)\nagent = NewsvendorRFwSAAagent(environment.mdp_info, cu=0.42857, co=1.0)\n\nenvironment.test()\nagent.eval()\n\nR, J = test_agent(agent, environment)\n\nprint(R, J)\n\nrun_experiment(agent, environment, 100, run_id = \"test\", save_best=True) # fit agent via run_experiment function\n    \nenvironment.test()\nagent.eval()\n\nR, J = test_agent(agent, environment)\n\nprint(R, J)\n\n-18.01888542213257 -17.142493964355882\n\n\nWARNING:root:Overwriting file results/test/saved_models/best/model.joblib\n\n\nresults\n-15.763567080255545 -15.022369246527656 -15.763567080255545 -15.022369246527656\n-17.334785352427232 -16.554914069406784",
    "crumbs": [
      "Agents",
      "Newsvendor_agents",
      "SAA based agents"
    ]
  },
  {
    "objectID": "30_agents/51_RL_agents/td3_agents.html",
    "href": "30_agents/51_RL_agents/td3_agents.html",
    "title": "TD3 agents",
    "section": "",
    "text": "source\n\nTD3Agent\n\n TD3Agent (environment_info:ddopai.utils.MDPInfo,\n           learning_rate_actor:float=0.0003,\n           learning_rate_critic:float|None=None,\n           initial_replay_size:int=1024, max_replay_size:int=50000,\n           batch_size:int=64, hidden_layers:List=None,\n           activation:str='relu', tau:float=0.005, policy_delay:int=2,\n           noise_std:float=0.2, sigma_scale:float=0.5, theta:float=0.15,\n           dt=0.02, drop_prob:float=0.0, batch_norm:bool=False,\n           init_method:str='xavier_uniform', optimizer:str='Adam',\n           loss:str='MSE', obsprocessors:list|None=None, device:str='cpu',\n           agent_name:str|None='SAC')\n\nXXX\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nenvironment_info\nMDPInfo\n\n\n\n\nlearning_rate_actor\nfloat\n0.0003\n\n\n\nlearning_rate_critic\nfloat | None\nNone\nIf none, then it is set to learning_rate_actor\n\n\ninitial_replay_size\nint\n1024\n\n\n\nmax_replay_size\nint\n50000\n\n\n\nbatch_size\nint\n64\n\n\n\nhidden_layers\nList\nNone\nif None, then default is [64, 64]\n\n\nactivation\nstr\nrelu\n“relu”, “sigmoid”, “tanh”, “leakyrelu”, “elu”\n\n\ntau\nfloat\n0.005\n\n\n\npolicy_delay\nint\n2\n\n\n\nnoise_std\nfloat\n0.2\n\n\n\nsigma_scale\nfloat\n0.5\n\n\n\ntheta\nfloat\n0.15\n\n\n\ndt\nfloat\n0.02\n\n\n\ndrop_prob\nfloat\n0.0\n\n\n\nbatch_norm\nbool\nFalse\n\n\n\ninit_method\nstr\nxavier_uniform\n“xavier_uniform”, “xavier_normal”, “he_normal”, “he_uniform”, “normal”, “uniform”\n\n\noptimizer\nstr\nAdam\n“Adam” or “SGD” or “RMSprop”\n\n\nloss\nstr\nMSE\ncurrently only MSE is supported\n\n\nobsprocessors\nlist | None\nNone\ndefault: []\n\n\ndevice\nstr\ncpu\n“cuda” or “cpu”\n\n\nagent_name\nstr | None\nSAC\n\n\n\n\n\n# #| export\n\n# class TD3Agent():\n\n#     train_mode = \"env_interaction\"\n\n#     \"\"\"\n#     Soft Actor Critic (SAC) agent with hybrid action, both based on Gaussian. The binary action is \n#     0 if the output of the network is less or equal than 0, and 1 otherwise.\n\n#     Args:\n#         mdp_info (MDPInfo): Contains relevant information about the environment.\n#         learning_rate_actor (float): Learning rate for the actor.\n#         learning_rate_critic (float): Learning rate for the critic.\n#         learning_rate_alpha (float): Learning rate for the temperature parameter.\n#         initial_replay_size (int): Number of transitions to save in the replay buffer during startup.\n#         max_replay_size (int): Maximum number of transitions to save in the replay buffer.\n#         batch_size (int): Number of transitions to sample each time experience is replayed.\n#         n_features (int): Number of features for the hidden layers of the networks.\n#         lr_alpha (float): Learning rate for the temperature parameter.\n#         tau (float): Parameter for the soft update of the target networks.\n#         optimizer (torch.optim): Optimizer to use for the networks.\n#         squeeze_output (bool): Whether to squeeze the output of the actor network or not.\n#         use_cuda (bool): Whether to use CUDA or not. If True and not available, it will use CPU.\n#         agent_name (str): Name of the agent. If set to None will use some default name.\n\n#     \"\"\"\n\n#     def __init__(\n#             self,\n#             environment_info: MDPInfo,\n#             learning_rate_actor = 3e-4,\n#             learning_rate_critic = None,\n#             initial_replay_size = 1024,\n#             max_replay_size = 50000,\n#             batch_size = 64,\n#             hidden_layers = [64, 64],\n#             tau = 0.005,\n#             policy_delay = 2,\n#             noise_std = 0.2,\n#             optimizer = optim.Adam,\n#             sigma_scale = 0.5,\n\n#             loss = \"MSE\",\n\n#             theta=0.15,\n#             dt=0.02,\n#             squeeze_output = True,\n#             device = \"cuda\",\n#             agent_name = None): \n        \n#         # print(\"in init fubction\")\n\n#         self.warmup_training_steps = initial_replay_size\n\n#         mdp_info = environment_info\n#         optimizer = optim.Adam\n        \n#         self.policy_class = OrnsteinUhlenbeckPolicy\n#         self.policy_params = dict(sigma=np.ones(1) * sigma_scale, theta=theta, dt=dt)\n\n#         if len(mdp_info.observation_space.shape) == 2:\n#             input_shape = (mdp_info.observation_space.shape[0]*mdp_info.observation_space.shape[1],)\n#         else:\n#             input_shape = mdp_info.observation_space.shape\n\n#         actor_output_shape = (mdp_info.action_space.shape[0],) \n\n#         print(input_shape)\n\n#         use_cuda = False\n\n#         if learning_rate_critic is None:\n#             learning_rate_critic = learning_rate_actor\n\n#         actor_params = dict(network=MLPActor,\n#                                 hidden_layers=hidden_layers,\n#                                 input_shape=input_shape,\n#                                 output_shape=actor_output_shape,\n#                                 use_cuda=use_cuda)\n        \n#         # print(\"setting optimizer class\")\n#         actor_optimizer = {'class': optimizer,\n#                     'params': {'lr': learning_rate_actor}} \n        \n#         critic_input_shape = (input_shape[0] + actor_output_shape[0],)\n#         critic_params = dict(network=MLPStateAction,\n#                         optimizer={'class': optimizer,\n#                                 'params': {'lr': learning_rate_critic}}, \n#                         loss=F.mse_loss,\n#                         hidden_layers=hidden_layers,\n#                         input_shape=critic_input_shape,\n#                         output_shape=(1,),\n#                         squeeze_output=squeeze_output,\n#                         use_cuda=use_cuda)\n        \n#         # print(\"creating agent from mushroom\")\n        \n#         self.agent = TD3(mdp_info, self.policy_class, self.policy_params,\n#                     actor_params, actor_optimizer, critic_params, batch_size,\n#                     initial_replay_size, max_replay_size, tau, policy_delay, noise_std)\n                \n#         self.network_list, self.actor, self.critic = self.get_network_list(set_actor_critic_attributes=True)\n    \n#         # print(\"created agent from mushroom\")\n\n#         if agent_name is None:\n#             self.agent.name = 'TD3_classic'\n#         else:\n#             self.agent.name = agent_name\n\n#     def __getattr__(self, attr):\n#         return getattr(self.agent, attr)\n\n#     def train(self,):\n#         self.agent.policy.train()\n    \n#     def eval(self,):\n#         self.agent.policy.eval()\n\n#     def get_network_list(self, set_actor_critic_attributes: bool = True):\n#         \"\"\" Get the list of networks in the agent for the save and load functions\n#         Get the actor for the predict function in eval mode \"\"\"\n\n#         networks = []\n#         ensemble_critic = self.agent._critic_approximator._impl.model\n#         for i, model in enumerate(ensemble_critic):\n#             networks.append(model.network)\n#         networks.append(self.agent.policy._approximator._impl.model.network)\n\n#         actor = self.agent.policy._approximator._impl.model.network\n#         critic = ensemble_critic[0].network\n\n#         if set_actor_critic_attributes:\n#             return networks, actor, critic\n#         else:\n#             return networks\n        \n#     def save(self,\n#                 path: str, # The directory where the file will be saved.\n#                 overwrite: bool=True): # Allow overwriting; if False, a FileExistsError will be raised if the file exists.\n        \n#         \"\"\"\n#         Save the PyTorch model to a file in the specified directory.\n\n#         \"\"\"\n        \n#         if not hasattr(self, 'network_list') or self.network_list is None:\n#             raise AttributeError(\"Cannot find networks.\")\n\n#         # Create the directory path if it does not exist\n#         os.makedirs(path, exist_ok=True)\n\n#         # Construct the file path using os.path.join for better cross-platform compatibility\n\n#         for network_number, network in enumerate(self.network_list):\n#             full_path = os.path.join(path, f\"network_{network_number}.pth\")\n\n#             if os.path.exists(full_path):\n#                 if not overwrite:\n#                     raise FileExistsError(f\"The file {full_path} already exists and will not be overwritten.\")\n#                 else:\n#                     logging.debug(f\"Overwriting file {full_path}\") # Only log with info as during training we will continuously overwrite the model\n            \n#             # Save the model's state_dict using torch.save\n#             torch.save(network.state_dict(), full_path)\n#         logging.debug(f\"Model saved successfully to {full_path}\")\n    \n#     def load(self, path: str):\n#         \"\"\"\n#         Load the PyTorch models from files in the specified directory.\n#         \"\"\"\n        \n#         if not hasattr(self, 'network_list') or self.network_list is None:\n#             raise AttributeError(\"Cannot find networks to load.\")\n\n#         # Check for the presence of model files\n#         for network_number, network in enumerate(self.network_list):\n#             full_path = os.path.join(path, f\"network_{network_number}.pth\")\n\n#             if not os.path.exists(full_path):\n#                 raise FileNotFoundError(f\"The file {full_path} does not exist.\")\n            \n#             try:\n#                 # Load each network's state_dict\n#                 network.load_state_dict(torch.load(full_path))\n#                 logging.info(f\"Network {network_number} loaded successfully from {full_path}\")\n#             except Exception as e:\n#                 raise RuntimeError(f\"An error occurred while loading network {network_number}: {e}\")\n\n\nfrom ddopai.envs.inventory.single_period import NewsvendorEnv\nfrom ddopai.dataloaders.tabular import XYDataLoader\nfrom ddopai.experiments.experiment_functions import run_experiment, test_agent\n\n\nval_index_start = 8000 #90_000\ntest_index_start = 9000 #100_000\n\nX = np.random.standard_normal((10000, 2))\nY = np.random.standard_normal((10000, 1))\nY += 2*X[:,0].reshape(-1, 1) + 3*X[:,1].reshape(-1, 1)\nY = X[:,0].reshape(-1, 1)\n# truncate Y at 0:\nY = np.maximum(Y, 0)\n# normalize Y max to 1\nY = Y/np.max(Y)\n\nprint(np.max(Y))\n\nprint(X.shape, Y.shape)\n\nclip_action = ClipAction(0., 1.)\n\ndataloader = XYDataLoader(X, Y, val_index_start, test_index_start, lag_window_params =  {'lag_window': 0, 'include_y': False, 'pre_calc': True})\n\nenvironment = NewsvendorEnv(\n    dataloader = dataloader,\n    underage_cost = 0.42857,\n    overage_cost = 1.0,\n    gamma = 0.999,\n    horizon_train = 365,\n    q_bound_high = 1.0,\n    q_bound_low = -0.1,\n    postprocessors = [clip_action],\n)\n\n\n\nagent = TD3Agent(environment.mdp_info,\n                obsprocessors = None,      # default: []\n                device=\"cpu\", # \"cuda\" or \"cpu\"\n)\n\nenvironment.test()\nagent.eval()\n\nR, J = test_agent(agent, environment)\n\nprint(R, J)\n\nenvironment.train()\nagent.train()\nenvironment.print=False\n\n# run_experiment(agent, environment, n_epochs=50, n_steps=1000, run_id = \"test\", save_best=True, print_freq=1) # fit agent via run_experiment function\n\nenvironment.test()\nagent.eval()\n\nR, J = test_agent(agent, environment)\n\nprint(R, J)\n\n1.0\n(10000, 2) (10000, 1)\n\n\n/Users/magnus/miniforge3/envs/inventory_gym_2/lib/python3.11/site-packages/gymnasium/spaces/box.py:130: UserWarning: WARN: Box bound precision lowered by casting to float32\n  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\nINFO:root:Actor network:\n/Users/magnus/miniforge3/envs/inventory_gym_2/lib/python3.11/site-packages/torchinfo/torchinfo.py:462: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  action_fn=lambda data: sys.getsizeof(data.storage()),\n\n\nChecking tuple: (2,)\n==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nMLPActor                                 [1, 1]                    --\n├─Sequential: 1-1                        [1, 1]                    --\n│    └─Linear: 2-1                       [1, 64]                   192\n│    └─ReLU: 2-2                         [1, 64]                   --\n│    └─Dropout: 2-3                      [1, 64]                   --\n│    └─Linear: 2-4                       [1, 64]                   4,160\n│    └─ReLU: 2-5                         [1, 64]                   --\n│    └─Dropout: 2-6                      [1, 64]                   --\n│    └─Linear: 2-7                       [1, 1]                    65\n│    └─Identity: 2-8                     [1, 1]                    --\n==========================================================================================\nTotal params: 4,417\nTrainable params: 4,417\nNon-trainable params: 0\nTotal mult-adds (M): 0.00\n==========================================================================================\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.00\nParams size (MB): 0.02\nEstimated Total Size (MB): 0.02\n==========================================================================================\n\n\nINFO:root:Critic network:\n\n\nChecking tuple: (2,)\nChecking tuple: (1,)\n==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nMLPStateAction                           --                        --\n├─Sequential: 1-1                        [1, 1]                    --\n│    └─Linear: 2-1                       [1, 64]                   256\n│    └─ReLU: 2-2                         [1, 64]                   --\n│    └─Dropout: 2-3                      [1, 64]                   --\n│    └─Linear: 2-4                       [1, 64]                   4,160\n│    └─ReLU: 2-5                         [1, 64]                   --\n│    └─Dropout: 2-6                      [1, 64]                   --\n│    └─Linear: 2-7                       [1, 1]                    65\n│    └─Identity: 2-8                     [1, 1]                    --\n==========================================================================================\nTotal params: 4,481\nTrainable params: 4,481\nNon-trainable params: 0\nTotal mult-adds (M): 0.00\n==========================================================================================\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.00\nParams size (MB): 0.02\nEstimated Total Size (MB): 0.02\n==========================================================================================\n-779.2586167634846 -492.39378518242427\n-779.2586167634846 -492.39378518242427",
    "crumbs": [
      "Agents",
      "Reinforcement Learning agents",
      "TD3 agents"
    ]
  },
  {
    "objectID": "30_agents/51_RL_agents/mushroom_base_agent.html",
    "href": "30_agents/51_RL_agents/mushroom_base_agent.html",
    "title": "Mushroom base agent",
    "section": "",
    "text": "source",
    "crumbs": [
      "Agents",
      "Reinforcement Learning agents",
      "Mushroom base agent"
    ]
  },
  {
    "objectID": "30_agents/51_RL_agents/mushroom_base_agent.html#mushroombaseagent",
    "href": "30_agents/51_RL_agents/mushroom_base_agent.html#mushroombaseagent",
    "title": "Mushroom base agent",
    "section": "MushroomBaseAgent",
    "text": "MushroomBaseAgent\n\n MushroomBaseAgent (environment_info:ddopai.utils.MDPInfo,\n                    obsprocessors:Optional[List]=None, device:str='cpu',\n                    agent_name:str|None=None)\n\nBase class for Agents that integrate MushroomRL agents.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nenvironment_info\nMDPInfo\n\n\n\n\nobsprocessors\nOptional\nNone\ndefault: []\n\n\ndevice\nstr\ncpu\n“cuda” or “cpu”\n\n\nagent_name\nstr | None\nNone\n\n\n\n\n\nXXX\nXXX\nXXXs:\n\nXXX",
    "crumbs": [
      "Agents",
      "Reinforcement Learning agents",
      "Mushroom base agent"
    ]
  },
  {
    "objectID": "30_agents/40_base_agents/basic_agents.html",
    "href": "30_agents/40_base_agents/basic_agents.html",
    "title": "Basic agents",
    "section": "",
    "text": "source\n\nRandomAgent\n\n RandomAgent (environment_info:ddopai.utils.MDPInfo,\n              obsprocessors:list[object]|None=None,\n              agent_name:str='RandomAgent', *args, **kwargs)\n\nA random agent that samples actions from the environment’s action space. Useful for testing and as minimal baseline.",
    "crumbs": [
      "Agents",
      "Basic agents",
      "Basic agents"
    ]
  },
  {
    "objectID": "30_agents/60_approximators/critic_networks.html",
    "href": "30_agents/60_approximators/critic_networks.html",
    "title": "Critic Networks",
    "section": "",
    "text": "source\n\nRNNWrapper\n\n RNNWrapper (rnn_cell_class, *args, **kwargs)\n\n*Base class for all neural network modules.\nYour models should also subclass this class.\nModules can also contain other Modules, allowing to nest them in a tree structure. You can assign the submodules as regular attributes::\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Model(nn.Module):\n    def __init__(self) -&gt; None:\n        super().__init__()\n        self.conv1 = nn.Conv2d(1, 20, 5)\n        self.conv2 = nn.Conv2d(20, 20, 5)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        return F.relu(self.conv2(x))\nSubmodules assigned in this way will be registered, and will have their parameters converted too when you call :meth:to, etc.\n.. note:: As per the example above, an __init__() call to the parent class must be made before assignment on the child.\n:ivar training: Boolean represents whether this module is in training or evaluation mode. :vartype training: bool*\n\nsource\n\n\nBaseApproximator\n\n BaseApproximator ()\n\nSome basic functions for approximators\n\nsource\n\n\nBaseApproximatorMLP\n\n BaseApproximatorMLP ()\n\nSome basic functions for approximators\n\nsource\n\n\nRNNMLPHybrid\n\n RNNMLPHybrid (RNN_input_size:int, MLP_input_size:int|None,\n               output_size:int, num_hidden_units_RNN:int,\n               hidden_layers_RNN:int, hidden_layers_MLP:List[int],\n               hidden_layers_input_MLP:Optional[List[int]],\n               RNN_cell:torch.nn.modules.module.Module,\n               activation:torch.nn.modules.module.Module,\n               final_activation:torch.nn.modules.module.Module,\n               drop_prob:float, batch_norm:bool, init_method:str)\n\nA hybrid model combining an RNN and an MLP\n\nsource\n\n\nBaseApproximatorRNN\n\n BaseApproximatorRNN ()\n\nSome basic functions for approximators\n\nsource\n\n\nMLPStateAction\n\n MLPStateAction (input_shape:Union[Tuple,List[Tuple]], output_shape:Tuple,\n                 hidden_layers:list, activation:str='relu',\n                 drop_prob:float=0.0, batch_norm:bool=False,\n                 final_activation:str='identity',\n                 init_method:str='xavier_uniform', use_cuda:bool=False,\n                 dropout:bool=False)\n\nMultilayer perceptron model for critic networks that take both states and actions as inputs to output the q-value\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ninput_shape\nUnion\n\nnumber of features\n\n\noutput_shape\nTuple\n\nnumber of outputs/actions\n\n\nhidden_layers\nlist\n\nlist of number of neurons in each hidden layer\n\n\nactivation\nstr\nrelu\n\n\n\ndrop_prob\nfloat\n0.0\ndropout probability\n\n\nbatch_norm\nbool\nFalse\nwhether to apply batch normalization\n\n\nfinal_activation\nstr\nidentity\nwhether to apply ReLU activation to the output\n\n\ninit_method\nstr\nxavier_uniform\nParameter for initialization\n\n\nuse_cuda\nbool\nFalse\nhandled by mushroomRL, not used here\n\n\ndropout\nbool\nFalse\nlegacy parameter to ensure compatibility, use drop_prob instead\n\n\n\n\nsource\n\n\nMLPState\n\n MLPState (input_shape:Tuple, output_shape:Tuple, hidden_layers:list,\n           activation:str='relu', drop_prob:float=0.0,\n           batch_norm:bool=False, final_activation:str='identity',\n           init_method:str='xavier_uniform', use_cuda:bool=False,\n           dropout:bool=False)\n\nMultilayer perceptron model for critic networks that take both states and actions as inputs to output the q-value\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ninput_shape\nTuple\n\nnumber of features\n\n\noutput_shape\nTuple\n\nnumber of outputs/actions\n\n\nhidden_layers\nlist\n\nlist of number of neurons in each hidden layer\n\n\nactivation\nstr\nrelu\n\n\n\ndrop_prob\nfloat\n0.0\ndropout probability\n\n\nbatch_norm\nbool\nFalse\nwhether to apply batch normalization\n\n\nfinal_activation\nstr\nidentity\nwhether to apply ReLU activation to the output\n\n\ninit_method\nstr\nxavier_uniform\nParameter for initialization\n\n\nuse_cuda\nbool\nFalse\nhandled by mushroomRL, not used here\n\n\ndropout\nbool\nFalse\nlegacy parameter to ensure compatibility, use drop_prob instead\n\n\n\n\nsource\n\n\nMLPActor\n\n MLPActor (input_shape:Tuple, output_shape:Tuple, hidden_layers:list,\n           activation:str='relu', drop_prob:float=0.0,\n           batch_norm:bool=False, final_activation:str='identity',\n           init_method:str='xavier_uniform', use_cuda:bool=False,\n           dropout:bool=False, **kwargs)\n\nMultilayer perceptron model for critic networks that take both states and actions as inputs to output the q-value\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ninput_shape\nTuple\n\nnumber of features\n\n\noutput_shape\nTuple\n\nnumber of outputs/actions\n\n\nhidden_layers\nlist\n\nlist of number of neurons in each hidden layer\n\n\nactivation\nstr\nrelu\n\n\n\ndrop_prob\nfloat\n0.0\ndropout probability\n\n\nbatch_norm\nbool\nFalse\nwhether to apply batch normalization\n\n\nfinal_activation\nstr\nidentity\nwhether to apply ReLU activation to the output\n\n\ninit_method\nstr\nxavier_uniform\nParameter for initialization\n\n\nuse_cuda\nbool\nFalse\n\n\n\ndropout\nbool\nFalse\nlegacy parameter to ensure compatibility, use drop_prob instead\n\n\nkwargs\n\n\n\n\n\n\n\nsource\n\n\nRNNActor\n\n RNNActor (input_shape:List[Tuple], output_shape:Tuple,\n           hidden_layers_RNN:int, num_hidden_units_RNN:int,\n           hidden_layers_MLP:List,\n           hidden_layers_input_MLP:Optional[List]=None,\n           RNN_cell:str='GRU', activation:str='relu', drop_prob:float=0.0,\n           batch_norm:bool=False, final_activation:str='identity',\n           init_method:str='xavier_uniform', use_cuda:bool=False,\n           dropout:bool=False, input_shape_:List[Tuple]=None, **kwargs)\n\nMultilayer perceptron model for critic networks that take both states and actions as inputs to output the q-value\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ninput_shape\nList\n\ninput shape, must be exaclty as input shape into agent for mushroom_rl to work\n\n\noutput_shape\nTuple\n\nnumber of outputs/actions\n\n\nhidden_layers_RNN\nint\n\nnumber of initial hidden RNN layers\n\n\nnum_hidden_units_RNN\nint\n\nnumber of neurons in the RNN layers\n\n\nhidden_layers_MLP\nList\n\nlist of number of neurons in each hidden MLP layer, following the RNN layers\n\n\nhidden_layers_input_MLP\nOptional\nNone\nIf a separate MLP is used for (potential) MLP input\n\n\nRNN_cell\nstr\nGRU\nRNN cell type\n\n\nactivation\nstr\nrelu\n\n\n\ndrop_prob\nfloat\n0.0\ndropout probability\n\n\nbatch_norm\nbool\nFalse\nwhether to apply batch normalization\n\n\nfinal_activation\nstr\nidentity\nwhether to apply ReLU activation to the output\n\n\ninit_method\nstr\nxavier_uniform\nParameter for initialization\n\n\nuse_cuda\nbool\nFalse\n\n\n\ndropout\nbool\nFalse\nlegacy parameter to ensure compatibility, use drop_prob instead\n\n\ninput_shape_\nList\nNone\ninput shape for composite spaces\n\n\nkwargs\n\n\n\n\n\n\n\nsource\n\n\nRNNStateAction\n\n RNNStateAction (input_shape:List[Tuple], output_shape:Tuple,\n                 hidden_layers_RNN:int, num_hidden_units_RNN:int,\n                 hidden_layers_MLP:List,\n                 hidden_layers_input_MLP:Optional[List]=None,\n                 RNN_cell:str='GRU', activation:str='relu',\n                 drop_prob:float=0.0, batch_norm:bool=False,\n                 final_activation:str='identity',\n                 init_method:str='xavier_uniform', use_cuda:bool=False,\n                 dropout:bool=False, input_shape_:List[Tuple]=None,\n                 **kwargs)\n\nMultilayer perceptron model for critic networks that take both states and actions as inputs to output the q-value\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ninput_shape\nList\n\ninput shape, must be exaclty as input shape into agent for mushroom_rl to work\n\n\noutput_shape\nTuple\n\nOutput shape\n\n\nhidden_layers_RNN\nint\n\nnumber of initial hidden RNN layers\n\n\nnum_hidden_units_RNN\nint\n\nnumber of neurons in the RNN layers\n\n\nhidden_layers_MLP\nList\n\nlist of number of neurons in each hidden MLP layer, following the RNN layers\n\n\nhidden_layers_input_MLP\nOptional\nNone\nstructure of MLP to speratly process non-RNN input\n\n\nRNN_cell\nstr\nGRU\nRNN cell type\n\n\nactivation\nstr\nrelu\n\n\n\ndrop_prob\nfloat\n0.0\ndropout probability\n\n\nbatch_norm\nbool\nFalse\nwhether to apply batch normalization\n\n\nfinal_activation\nstr\nidentity\nwhether to apply ReLU activation to the output\n\n\ninit_method\nstr\nxavier_uniform\nParameter for initialization\n\n\nuse_cuda\nbool\nFalse\n\n\n\ndropout\nbool\nFalse\nlegacy parameter to ensure compatibility, use drop_prob instead\n\n\ninput_shape_\nList\nNone\ninput shape for composite spaces\n\n\nkwargs\n\n\n\n\n\n\n\nimport mushroom_rl\nmushroom_rl.__file__\n\n'/opt/hostedtoolcache/Python/3.10.15/x64/lib/python3.10/site-packages/mushroom_rl/__init__.py'",
    "crumbs": [
      "Agents",
      "Approximators",
      "Critic Networks"
    ]
  },
  {
    "objectID": "40_experiments/tracking.html",
    "href": "40_experiments/tracking.html",
    "title": "Tracking utils",
    "section": "",
    "text": "source",
    "crumbs": [
      "Experiment functions",
      "Tracking utils"
    ]
  },
  {
    "objectID": "40_experiments/tracking.html#get_git_hash",
    "href": "40_experiments/tracking.html#get_git_hash",
    "title": "Tracking utils",
    "section": "get_git_hash",
    "text": "get_git_hash\n\n get_git_hash (directory:str, tracking:bool=False,\n               tracking_tool:Literal['wandb']='wandb')\n\nGet the git hash and optionally track\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndirectory\nstr\n\nthe directory where the git repository is located\n\n\ntracking\nbool\nFalse\nwhether to directly track the git revision hash\n\n\ntracking_tool\nLiteral\nwandb\nCurrently only wandb is supported\n\n\nReturns\nstr\n\n\n\n\n\n\nsource",
    "crumbs": [
      "Experiment functions",
      "Tracking utils"
    ]
  },
  {
    "objectID": "40_experiments/tracking.html#get_library_version",
    "href": "40_experiments/tracking.html#get_library_version",
    "title": "Tracking utils",
    "section": "get_library_version",
    "text": "get_library_version\n\n get_library_version (library_name:str, tracking:bool=False,\n                      tracking_tool:Literal['wandb']='wandb')\n\nGet the version of a specified library and optionally track it\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nlibrary_name\nstr\n\n\n\n\ntracking\nbool\nFalse\nWhether to directly track the library version\n\n\ntracking_tool\nLiteral\nwandb\nCurrently only wandb is supported\n\n\nReturns\nstr\n\n\n\n\n\nExample usage for the check_parameter_types function.",
    "crumbs": [
      "Experiment functions",
      "Tracking utils"
    ]
  },
  {
    "objectID": "40_experiments/experiment_functions.html",
    "href": "40_experiments/experiment_functions.html",
    "title": "Experiment functions",
    "section": "",
    "text": "source",
    "crumbs": [
      "Experiment functions",
      "Experiment functions"
    ]
  },
  {
    "objectID": "40_experiments/experiment_functions.html#earlystoppinghandler",
    "href": "40_experiments/experiment_functions.html#earlystoppinghandler",
    "title": "Experiment functions",
    "section": "EarlyStoppingHandler",
    "text": "EarlyStoppingHandler\n\n EarlyStoppingHandler (patience:int=50, warmup:int=100, criteria:str='J',\n                       direction:str='max')\n\nClass to handle early stopping during experiments. The EarlyStoppingHandler handler calculates the average score over the last “patience” epochs and compares it to the average score over the previous “patience” epochs. Note that one epoch we define here as time in between evaluating on a validation set, for supervised learning typically one epoch is one pass through the training data. For reinforcement learning, in between each evaluation epoch there may be less than one, one, or many episodes played in the training environment.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\npatience\nint\n50\nNumber of epochs to evaluate for stopping\n\n\nwarmup\nint\n100\nHow many initial epochs to wait before evaluating\n\n\ncriteria\nstr\nJ\nWhether to use discounted rewards J or total rewards R as criteria\n\n\ndirection\nstr\nmax\nWhether reward shall be maximized or minimized\n\n\n\n\nsource\n\nEarlyStoppingHandler.add_result\n\n EarlyStoppingHandler.add_result (J:float, R:float)\n\nAdd the result of the last epoch to the history and check if the experiment should be stopped.\n\n\n\n\nType\nDetails\n\n\n\n\nJ\nfloat\nReturn (discounted rewards) of the last epoch\n\n\nR\nfloat\nTotal rewards of the last epoch\n\n\nReturns\nbool",
    "crumbs": [
      "Experiment functions",
      "Experiment functions"
    ]
  },
  {
    "objectID": "40_experiments/experiment_functions.html#helper-functions",
    "href": "40_experiments/experiment_functions.html#helper-functions",
    "title": "Experiment functions",
    "section": "Helper functions",
    "text": "Helper functions\n\nSome functions that are needed to run an experiment\n\n\nsource\n\nsave_agent\n\n save_agent (agent:ddopai.agents.base.BaseAgent, experiment_dir:str,\n             save_best:bool, R:float, J:float, best_R:float, best_J:float,\n             criteria:str='J', force_save=False)\n\nSave the agent if it has improved either R or J, depending on the criteria argument, vs. the previous epochs\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nagent\nBaseAgent\n\nAny agent inheriting from BaseAgent\n\n\nexperiment_dir\nstr\n\nDirectory to save the agent,\n\n\nsave_best\nbool\n\n\n\n\nR\nfloat\n\n\n\n\nJ\nfloat\n\n\n\n\nbest_R\nfloat\n\n\n\n\nbest_J\nfloat\n\n\n\n\ncriteria\nstr\nJ\n\n\n\nforce_save\nbool\nFalse\n\n\n\n\n\nsource\n\n\nupdate_best\n\n update_best (R:float, J:float, best_R:float, best_J:float)\n\nUpdate the best total rewards R and the best discounted rewards J.\n\n\n\n\nType\nDetails\n\n\n\n\nR\nfloat\n\n\n\nJ\nfloat\n\n\n\nbest_R\nfloat\n\n\n\nbest_J\nfloat\n\n\n\n\n\nsource\n\n\nlog_info\n\n log_info (R:float, J:float, n_epochs:int, tracking:Literal['wandb'],\n           mode:Literal['train','val','test'])\n\nLogs the same R, J information repeatedly for n_epoochs. E.g., to draw a straight line in wandb for algorithmes such as XGB, RF, etc. that can be comparared to the learning curves of supervised or reinforcement learning algorithms.\n\n\n\n\nType\nDetails\n\n\n\n\nR\nfloat\n\n\n\nJ\nfloat\n\n\n\nn_epochs\nint\n\n\n\ntracking\nLiteral\nonly wandb implemented so far\n\n\nmode\nLiteral\n\n\n\n\n\nsource\n\n\ncalculate_score\n\n calculate_score (dataset:List, env:ddopai.envs.base.BaseEnvironment)\n\nCalculate the total rewards R and the discounted rewards J of a dataset.\n\n\n\n\n\n\n\n\n\nType\nDetails\n\n\n\n\ndataset\nList\n\n\n\nenv\nBaseEnvironment\nAny environment inheriting from BaseEnvironment\n\n\nReturns\nTuple",
    "crumbs": [
      "Experiment functions",
      "Experiment functions"
    ]
  },
  {
    "objectID": "40_experiments/experiment_functions.html#experiment-functions",
    "href": "40_experiments/experiment_functions.html#experiment-functions",
    "title": "Experiment functions",
    "section": "Experiment functions",
    "text": "Experiment functions\n\nFunctions to run experiments\n\n\nsource\n\nrun_experiment\n\n run_experiment (agent:ddopai.agents.base.BaseAgent,\n                 env:ddopai.envs.base.BaseEnvironment, n_epochs:int,\n                 n_steps:int=None, early_stopping_handler:Optional[__main_\n                 _.EarlyStoppingHandler]=None, save_best:bool=True,\n                 performance_criterion:str='J',\n                 tracking:Optional[str]=None, results_dir:str='results',\n                 run_id:Optional[str]=None, print_freq:int=10,\n                 eval_step_info=False, return_score=False)\n\nRun an experiment with the given agent and environment for n_epochs. It automaticall dedects if the train mode of the agent is direct, epochs_fit or env_interaction and runs the experiment accordingly.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nagent\nBaseAgent\n\n\n\n\nenv\nBaseEnvironment\n\n\n\n\nn_epochs\nint\n\n\n\n\nn_steps\nint\nNone\nNumber of steps to interact with the environment per epoch. Will be ignored for direct_fit and epchos_fit agents\n\n\nearly_stopping_handler\nOptional\nNone\n\n\n\nsave_best\nbool\nTrue\n\n\n\nperformance_criterion\nstr\nJ\nother: “R”\n\n\ntracking\nOptional\nNone\nother: “wandb”\n\n\nresults_dir\nstr\nresults\n\n\n\nrun_id\nOptional\nNone\n\n\n\nprint_freq\nint\n10\n\n\n\neval_step_info\nbool\nFalse\n\n\n\nreturn_score\nbool\nFalse\n\n\n\n\n\n\nImportant notes on running experiments\nTraining mode:\n\nAgents have either a training mode direct_fit or epochs_fit or env_interaction. direct_fit means that agents are called with a single call to the fit method, providing the full X and Y dataset. epochs_fit means that agents are training iteratively via epochs. It is assumed that they then have access to the dataloader.\n\nTrain, val, test mode:\n\nThe function always sets the agent and environment to the approproate dataset mode (and thereofore indirectly the dataloader via then environment).\n\nEarly stopping:\n\nCan be optionally applied for epochs_fit and env_interaction agents.\n\nSave best agent:\n\nThe save_agent() functions, given the save_bestparam is True, will save the best agent based on the validation score.\nAt test time at a later point, one can then load the best agent and evaluate it on the test set (not done automatically by this function).\n\nLogging:\n\nBy setting logging to \"wandb\" the function will log J and R to wandb.\n\n\nsource\n\n\ntest_agent\n\n test_agent (agent:ddopai.agents.base.BaseAgent,\n             env:ddopai.envs.base.BaseEnvironment, return_dataset=False,\n             save_features=False, tracking=None, eval_step_info=False)\n\nTests the agent on the environment for a single episode\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nagent\nBaseAgent\n\n\n\n\nenv\nBaseEnvironment\n\n\n\n\nreturn_dataset\nbool\nFalse\n\n\n\nsave_features\nbool\nFalse\n\n\n\ntracking\nNoneType\nNone\nother: “wandb”,\n\n\neval_step_info\nbool\nFalse\n\n\n\n\n\nsource\n\n\nrun_test_episode\n\n run_test_episode (env:ddopai.envs.base.BaseEnvironment,\n                   agent:ddopai.agents.base.BaseAgent,\n                   eval_step_info:bool=False, save_features:bool=False)\n\nRuns an episode to test the agent’s performance. It assumes, that agent and environment are initialized, in test/val mode and have done reset.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nenv\nBaseEnvironment\n\nAny environment inheriting from BaseEnvironment\n\n\nagent\nBaseAgent\n\nAny agent inheriting from BaseAgent\n\n\neval_step_info\nbool\nFalse\nPrint step info during evaluation\n\n\nsave_features\nbool\nFalse\nSave features (observation) of the dataset. Can be turned off since they sometimes become very large with many lag information\n\n\n\nUsage example for test_agent():\n\nfrom ddopai.envs.inventory.single_period import NewsvendorEnv\nfrom ddopai.dataloaders.tabular import XYDataLoader\nfrom ddopai.agents.basic import RandomAgent\n\n\nval_index_start = 80 #90_000\ntest_index_start = 90 #100_000\n\nX = np.random.rand(100, 2)\nY = np.random.rand(100, 1)\n\ndataloader = XYDataLoader(X, Y, val_index_start, test_index_start)\n\nenvironment = NewsvendorEnv(\n    dataloader = dataloader,\n    underage_cost = 0.42857,\n    overage_cost = 1.0,\n    gamma = 0.999,\n    horizon_train = 365,\n)\n\nagent = RandomAgent(environment.mdp_info)\n\nenvironment.test()\n\nR, J = test_agent(agent, environment)\n\nprint(f\"R: {R}, J: {J}\")\n\nR: -7.269816766556392, J: -7.236762453375597",
    "crumbs": [
      "Experiment functions",
      "Experiment functions"
    ]
  },
  {
    "objectID": "90_datasets/meta_kaggle_m5.html",
    "href": "90_datasets/meta_kaggle_m5.html",
    "title": "Dataset Preparation for Kaggle M5 dataset for Meta-Learning",
    "section": "",
    "text": "source\n\nKaggleM5DatasetLoader\n\n KaggleM5DatasetLoader (data_path, overwrite=False,\n                        product_as_feature=False)\n\nClass to download the Kaggle M5 dataset and apply some preprocessing steps to prepare it for application in inventory management.\n\nrun_test = False\nif run_test:\n    data_path = \"/Users/magnus/Documents/02_PhD/03_Newsvendor_foundation_model/experiments/datasets/raw/kaggle_m5\"\n    if data_path is not None:\n        loader = KaggleM5DatasetLoader(data_path, overwrite=False, product_as_feature=False)\n        demand, SKU_features, time_features, time_SKU_features, mask = loader.load_dataset()\n\nINFO:root:Using existing data from disk\nINFO:root:Importing data\nINFO:root:Preprocessing data\nINFO:root:--Creating catogory mapping and features\nINFO:root:--Preparing sales time series data\nINFO:root:--Preparing calendric information\nINFO:root:--Preparing snap features\nINFO:root:--Preparing price information\nINFO:root:--Creating indicator table if products are available for purchase\nINFO:root:--Preparing final outputs and ensure consistency of time and feature dimensions\n\n\n      HOBBIES_1_001_CA_1  HOBBIES_1_002_CA_1  HOBBIES_1_003_CA_1  \\\n0                      0                   0                   0   \n1                      0                   0                   0   \n2                      0                   0                   0   \n3                      0                   0                   0   \n4                      0                   0                   0   \n...                  ...                 ...                 ...   \n1936                   0                   0                   0   \n1937                   3                   0                   2   \n1938                   3                   0                   3   \n1939                   0                   0                   0   \n1940                   1                   0                   1   \n\n      HOBBIES_1_004_CA_1  HOBBIES_1_005_CA_1  HOBBIES_1_006_CA_1  \\\n0                      0                   0                   0   \n1                      0                   0                   0   \n2                      0                   0                   0   \n3                      0                   0                   0   \n4                      0                   0                   0   \n...                  ...                 ...                 ...   \n1936                   1                   0                   0   \n1937                   3                   0                   0   \n1938                   0                   2                   5   \n1939                   2                   1                   2   \n1940                   6                   0                   0   \n\n      HOBBIES_1_007_CA_1  HOBBIES_1_008_CA_1  HOBBIES_1_009_CA_1  \\\n0                      0                  12                   2   \n1                      0                  15                   0   \n2                      0                   0                   7   \n3                      0                   0                   3   \n4                      0                   0                   0   \n...                  ...                 ...                 ...   \n1936                   1                   5                   0   \n1937                   0                   4                   0   \n1938                   1                   1                   0   \n1939                   1                  40                   1   \n1940                   0                  32                   0   \n\n      HOBBIES_1_010_CA_1  ...  FOODS_3_818_WI_3  FOODS_3_819_WI_3  \\\n0                      0  ...                 0                14   \n1                      0  ...                 0                11   \n2                      1  ...                 0                 5   \n3                      0  ...                 0                 6   \n4                      0  ...                 0                 5   \n...                  ...  ...               ...               ...   \n1936                   1  ...                 3                 6   \n1937                   1  ...                 1                 4   \n1938                   0  ...                 3                 4   \n1939                   0  ...                 0                 1   \n1940                   1  ...                 0                 1   \n\n      FOODS_3_820_WI_3  FOODS_3_821_WI_3  FOODS_3_822_WI_3  FOODS_3_823_WI_3  \\\n0                    1                 0                 4                 0   \n1                    1                 0                 4                 0   \n2                    1                 0                 2                 2   \n3                    1                 0                 5                 2   \n4                    1                 0                 2                 0   \n...                ...               ...               ...               ...   \n1936                 3                 0                 0                 1   \n1937                 3                 1                 2                 0   \n1938                 3                 1                 1                 0   \n1939                 0                 0                 3                 1   \n1940                 1                 4                 4                 1   \n\n      FOODS_3_824_WI_3  FOODS_3_825_WI_3  FOODS_3_826_WI_3  FOODS_3_827_WI_3  \n0                    0                 0                 0                 0  \n1                    0                 6                 0                 0  \n2                    0                 0                 0                 0  \n3                    0                 2                 0                 0  \n4                    0                 2                 0                 0  \n...                ...               ...               ...               ...  \n1936                 0                 1                 0                 0  \n1937                 1                 0                 1                 2  \n1938                 0                 1                 1                 2  \n1939                 1                 0                 1                 5  \n1940                 0                 2                 0                 1  \n\n[1941 rows x 30490 columns]",
    "crumbs": [
      "Datasets",
      "Dataset Preparation for Kaggle M5 dataset for Meta-Learning"
    ]
  },
  {
    "objectID": "90_datasets/meta_bakery.html",
    "href": "90_datasets/meta_bakery.html",
    "title": "Dataset Preparation for Bakery dataset for Meta-Learning",
    "section": "",
    "text": "source\n\nBakeryDatasetLoader\n\n BakeryDatasetLoader (data_path, overwrite=False,\n                      product_as_feature=False, store_as_features=False)\n\nClass to download the Kaggle M5 dataset and apply some preprocessing steps to prepare it for application in inventory management.\n\nrun_test = False\nif run_test:\n    data_path = \"/Users/magnus/Documents/02_PhD/03_Newsvendor_foundation_model/experiments/datasets/raw/bakery\" # For testing purposes, please specify the path to the data on your machine\n    if data_path is not None:\n        loader = BakeryDatasetLoader(data_path, overwrite=False, product_as_feature=False, store_as_features=False)\n        demand, SKU_features, time_features, time_SKU_features, mask = loader.load_dataset()\n\nINFO:root:Importing data\nINFO:root:Preprocessing data\nINFO:root:--Creating catogory mapping and features\nINFO:root:--Preparing calendric information\nINFO:root:--Preparing demand\nINFO:root:--Preparing SKU-specific features\nINFO:root:--Preparing SKU-time-specific features",
    "crumbs": [
      "Datasets",
      "Dataset Preparation for Bakery dataset for Meta-Learning"
    ]
  },
  {
    "objectID": "10_dataloaders/base_dataloader.html",
    "href": "10_dataloaders/base_dataloader.html",
    "title": "Base dataloader",
    "section": "",
    "text": "source",
    "crumbs": [
      "Dataloaders",
      "Base dataloader"
    ]
  },
  {
    "objectID": "10_dataloaders/base_dataloader.html#basedataloader",
    "href": "10_dataloaders/base_dataloader.html#basedataloader",
    "title": "Base dataloader",
    "section": "BaseDataLoader",
    "text": "BaseDataLoader\n\n BaseDataLoader ()\n\nBase class for data loaders. The idea of the data loader is to provide all external information to the environment (including lagged data, demand etc.). Internal data influenced by past decisions (like inventory levels) is to be added from within the environment\nTrain-Val-Test split:\n\nThe dataloader contains all data, including the training, validation and test sets.\nRetrieval of the dataset types is achieved by setting the internal state to train, validation or test using appropriate functions. Then the index will automatically be adjusted to the correct dataset (see below on data retrieval).\nDuring training, both the agent and experiment function may have to know the length of the dataset. Therefore, the functions len_train, len_val and len_test with decorator @property must be defined\n\nData retrieval:\n\nData retrieval is done with the ___getitem___ function. The function takes an index and returns the data at that index, typically as and X and Y pair.\nFor non-distribution-based dataloaders, the __init__ function must have arguments val_index_start and test_index_start from which the attributes val_index_start and test_index_start and train_index_endare set. The __getitem__ function must then check the index and return the correct data based on the internal state of the dataloader.\n\n\nsource\n\nBaseDataLoader.__len__\n\n BaseDataLoader.__len__ ()\n\nReturns the length of the dataset. For dataloaders based on distributions, this should return an error that the length is not defined, otherwise it should return the number of samples in the dataset.\n\nsource\n\n\nBaseDataLoader.__getitem__\n\n BaseDataLoader.__getitem__ (idx)\n\nReturns always a tuple of X and Y data. If no X data is available, return None.\n\nsource\n\n\nBaseDataLoader.X_shape\n\n BaseDataLoader.X_shape ()\n\nReturns the shape of the X data. It should follow the format (n_samples, n_features). If the data has a time dimension with a fixed length, the shape should be (n_samples, n_time_steps, n_features). If the data is generated from a distribtition, n_samples should be set to 1.\n\nsource\n\n\nBaseDataLoader.Y_shape\n\n BaseDataLoader.Y_shape ()\n\nReturns the shape of the Y data. It should follow the format (n_samples, n_SKUs). If the variable of interst is only a single SKU, the shape should be (n_samples, 1). If the data is generated from a distribtition, n_samples should be set to 1.\n\nsource\n\n\nBaseDataLoader.get_all_X\n\n BaseDataLoader.get_all_X (dataset_type:str='train')\n\nReturns the entire features dataset. If no X data is available, return None. Return either the train, val, test, or all data.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndataset_type\nstr\ntrain\ncan be ‘train’, ‘val’, ‘test’, ‘all’\n\n\n\n\nsource\n\n\nBaseDataLoader.get_all_Y\n\n BaseDataLoader.get_all_Y (dataset_type:str='train')\n\nReturns the entire target dataset. If no Y data is available, return None. Return either the train, val, test, or all data.\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndataset_type\nstr\ntrain\ncan be ‘train’, ‘val’, ‘test’, ‘all’\n\n\n\n\nsource\n\n\nBaseDataLoader.len_train\n\n BaseDataLoader.len_train ()\n\nReturns the length of the training set. For dataloaders based on distributions, this should return an error that the length is not defined, otherwise it should return the number of samples in the training set.\n\nsource\n\n\nBaseDataLoader.len_val\n\n BaseDataLoader.len_val ()\n\n*Returns the length of the validation set. For dataloaders based on distributions, this should return an error that the length is not defined, otherwise it should return the number of samples in the validation set.\nIf no valiation set is defined, raise an error.*\n\nsource\n\n\nBaseDataLoader.len_test\n\n BaseDataLoader.len_test ()\n\n*Returns the length of the test set. For dataloaders based on distributions, this should return an error that the length is not defined, otherwise it should return the number of samples in the test set.\nIf no test set is defined, raise an error.*\n\nsource\n\n\nBaseDataLoader.train\n\n BaseDataLoader.train ()\n\nSet the internal state of the dataloader to train\n\nsource\n\n\nBaseDataLoader.val\n\n BaseDataLoader.val ()\n\nSet the internal state of the dataloader to validation\n\nsource\n\n\nBaseDataLoader.test\n\n BaseDataLoader.test ()\n\nSet the internal state of the dataloader to test\n\nsource\n\n\nDummyDataLoader\n\n DummyDataLoader ()\n\nDummy class for data loaders that can be usef for environment that do not require any data.",
    "crumbs": [
      "Dataloaders",
      "Base dataloader"
    ]
  }
]