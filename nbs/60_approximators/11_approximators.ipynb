{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximators\n",
    "\n",
    "> Models that approximate a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp approximators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging_level = logging.DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Union\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class LinearModel(nn.Module):\n",
    "    \"\"\"Linear regression model\"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "            input_size: int, # number of features\n",
    "            output_size: int, # number of outputs/actions\n",
    "            relu_output: bool = False): # whether to apply ReLU activation to the output\n",
    "        super().__init__()\n",
    "        self.l1=nn.Linear(input_size, output_size)\n",
    "        if relu_output:\n",
    "            self.final_activation = nn.ReLU()\n",
    "        else:\n",
    "            self.final_activation = nn.Identity()\n",
    "            \n",
    "    def forward(self,x):\n",
    "        out=self.l1(x)\n",
    "        out=self.final_activation(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class MLP(nn.Module):\n",
    "\n",
    "    \"\"\" Multilayer perceptron model\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                    input_size: int, # number of features\n",
    "                    output_size: int, # number of outputs/actions\n",
    "                    hidden_layers: list, # list of number of neurons in each hidden layer\n",
    "                    drop_prob: float = 0.0, # dropout probability\n",
    "                    batch_norm: bool = False, # whether to apply batch normalization\n",
    "                    relu_output: bool = False): # whether to apply ReLU activation to the output\n",
    "        super().__init__()\n",
    "\n",
    "        # List of layers\n",
    "        layers = []\n",
    "\n",
    "        last_size = input_size\n",
    "        for num_neurons in hidden_layers:\n",
    "            layers.append(nn.Linear(last_size, num_neurons))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(p=drop_prob))\n",
    "            if batch_norm:\n",
    "                layers.append(nn.BatchNorm1d(num_neurons))\n",
    "            last_size = num_neurons\n",
    "\n",
    "        # Output layer\n",
    "        layers.append(nn.Linear(last_size, output_size))\n",
    "        if relu_output:\n",
    "            layers.append(nn.ReLU()) # output is non-negative\n",
    "        else:\n",
    "            layers.append(nn.Identity())\n",
    "\n",
    "        # Combine layers\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
