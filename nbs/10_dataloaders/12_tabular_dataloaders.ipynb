{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabular dataloaders\n",
    "\n",
    "> Dataloaders for tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp dataloaders.tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import numpy as np\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Union\n",
    "\n",
    "from ddopnew.dataloaders.base import BaseDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class XYDataLoader(BaseDataLoader):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    A class for datasets with the typicall X, Y structure. Both X\n",
    "    and Y are numpy arrays. X may be of shape (datapoints, features) or (datapoints, sequence_length, features) \n",
    "    if lag features are used. The prep_lag_features can be used to create those lag features. Y is of shape\n",
    "    (datapoints, units).\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "        X: np.ndarray,\n",
    "        Y: np.ndarray,\n",
    "        val_index_start: Union[int, None] = None, \n",
    "        test_index_start: Union[int, None] = None, \n",
    "        lag_window_params: Union[dict] = None # default: {'lag_window': 0, 'include_y': False, 'pre_calc-calc': False}\n",
    "    ):\n",
    "\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "        self.val_index_start = val_index_start\n",
    "        self.test_index_start = test_index_start\n",
    "\n",
    "        # train index ends either at the start of the validation set, the start of the test set or at the end of the dataset\n",
    "        if self.val_index_start is not None:\n",
    "            self.train_index_end = self.val_index_start-1\n",
    "        elif self.test_index_start is not None:\n",
    "            self.train_index_end = self.test_index_start-1\n",
    "        else:\n",
    "            self.train_index_end = len(Y)-1\n",
    "\n",
    "        self.dataset_type = \"train\"\n",
    "\n",
    "        lag_window_params = lag_window_params or {'lag_window': 0, 'include_y': False, 'pre_calc': False}\n",
    "\n",
    "        self.prep_lag_features(**lag_window_params)\n",
    "\n",
    "        # X must at least have datapoint and feature dimension\n",
    "        if len(X.shape) == 1:\n",
    "            self.X = X.reshape(-1, 1)\n",
    "        \n",
    "        # Y must have at least datapoint and unit dimension (even if only one unit is present)\n",
    "        if len(Y.shape) == 1:\n",
    "            self.Y = Y.reshape(-1, 1)\n",
    "\n",
    "        assert len(X) == len(Y), 'X and Y must have the same length'\n",
    "\n",
    "        self.num_units = Y.shape[1] # shape 0 is alsways time, shape 1 is the number of units (e.g., SKUs)\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "    def prep_lag_features(self,\n",
    "        lag_window: int = 0, # length of the lage window\n",
    "        include_y: bool = False, # if lag demand shall be included as feature\n",
    "        pre_calc: bool = False # if all lags are pre-calculated for the entire dataset\n",
    "        ):\n",
    "\n",
    "        \"\"\"\n",
    "        Create lag feature for the dataset. If \"inlcude_y\" is true, then a lag-1 of of the target variable is added as a feature.\n",
    "        If lag-window is > 0, the lag features are added as middle dimension to X. Note that this, e.g., means that with a lag\n",
    "        window of 1, the data will include 2 time steps, the current features including lag-1 demand and the lag-1 features\n",
    "        including lag-2 demand. If pre-calc is true, all these calculations are performed on the entire dataset reduce\n",
    "        computation time later on at the expense of increases memory usage. \n",
    "\n",
    "        \"\"\"\n",
    "        # to be discussed: Do we need option to only provide lag demand wihtout lag features?\n",
    "        self.lag_window = lag_window\n",
    "        self.include_y = include_y\n",
    "        self.pre_calc = pre_calc\n",
    "\n",
    "        if self.pre_calc:\n",
    "            if self.include_y:\n",
    "                # add additional column to X with demand shifted by 1\n",
    "                self.X = np.concatenate((self.X, np.roll(self.Y, 1, axis=0)), axis=1)\n",
    "                self.X = self.X[1:] # remove first row\n",
    "                self.Y = self.Y[1:] # remove first row\n",
    "                \n",
    "                self.val_index_start = self.val_index_start-1\n",
    "                self.test_index_start = self.test_index_start-1\n",
    "                self.train_index_end  = self.train_index_end-1\n",
    "        \n",
    "            if self.lag_window is not None and self.lag_window > 0:\n",
    "\n",
    "                # add lag features as dimention 2 to X (making it dimension (datapoints, sequence_length, features))\n",
    "                X_lag = np.zeros((self.X.shape[0], self.lag_window+1, self.X.shape[1]))\n",
    "                for i in range(self.lag_window+1):\n",
    "                    if i == 0:\n",
    "                        features = self.X\n",
    "                    else:    \n",
    "                        features = self.X[:-i, :]\n",
    "                    X_lag[i:, self.lag_window-i, :] = features\n",
    "                self.X = X_lag[self.lag_window:]\n",
    "                self.Y = self.Y[self.lag_window:]\n",
    "\n",
    "                self.val_index_start = self.val_index_start-self.lag_window\n",
    "                self.test_index_start = self.test_index_start-self.lag_window\n",
    "                self.train_index_end  = self.train_index_end-self.lag_window\n",
    "\n",
    "        else:\n",
    "            self.lag_window = None\n",
    "            self.include_y = False\n",
    "\n",
    "                # add time dimension to X\n",
    "    \n",
    "    def __getitem__(self, idx): \n",
    "\n",
    "        \"\"\" get item by index, depending on the dataset type (train, val, test)\"\"\"\n",
    "\n",
    "        if self.dataset_type == \"train\":\n",
    "            if idx > self.train_index_end:\n",
    "                raise IndexError(f'index{idx} out of range{self.train_index_end}')\n",
    "            idx = idx\n",
    "\n",
    "        elif self.dataset_type == \"val\":\n",
    "            idx = idx + self.val_index_start\n",
    "            \n",
    "            if idx >= self.test_index_start:\n",
    "                raise IndexError(f'index{idx} out of range{self.test_index_start}')\n",
    "            \n",
    "        elif self.dataset_type == \"test\":\n",
    "            idx = idx + self.test_index_start\n",
    "            \n",
    "            if idx >= len(self.X):\n",
    "                raise IndexError(f'index{idx} out of range{len(self.X)}')\n",
    "        \n",
    "        else:\n",
    "            raise ValueError('dataset_type not set')\n",
    "\n",
    "        return self.X[idx], self.Y[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    @property\n",
    "    def X_shape(self):\n",
    "        return self.X.shape\n",
    "    \n",
    "    @property\n",
    "    def Y_shape(self):\n",
    "        return self.Y.shape\n",
    "\n",
    "    @property\n",
    "    def len_train(self):\n",
    "        return self.train_index_end+1\n",
    "\n",
    "    @property\n",
    "    def len_val(self):\n",
    "        if self.val_index_start is None:\n",
    "            raise ValueError('no validation set defined')\n",
    "        return self.test_index_start-self.val_index_start\n",
    "\n",
    "    @property\n",
    "    def len_test(self):\n",
    "        if self.test_index_start is None:\n",
    "            raise ValueError('no test set defined')\n",
    "        return len(self.Y)-self.test_index_start\n",
    "\n",
    "    def get_all_X(self,\n",
    "                dataset_type: str = 'train' # can be 'train', 'val', 'test', 'all'\n",
    "                ): \n",
    "\n",
    "        \"\"\"\n",
    "        Returns the entire features dataset.\n",
    "        Return either the train, val, test, or all data.\n",
    "        \"\"\"\n",
    "\n",
    "        if dataset_type == 'train':\n",
    "            return self.X[:self.val_index_start].copy() if self.X is not None else None\n",
    "        elif dataset_type == 'val':\n",
    "            return self.X[self.val_index_start:self.test_index_start].copy() if self.X is not None else None\n",
    "        elif dataset_type == 'test':\n",
    "            return self.X[self.test_index_start:].copy() if self.X is not None else None\n",
    "        elif dataset_type == 'all':\n",
    "            return self.X.copy() if self.X is not None else None\n",
    "        else:\n",
    "            raise ValueError('dataset_type not recognized')\n",
    "\n",
    "    def get_all_Y(self,\n",
    "                dataset_type: str = 'train' # can be 'train', 'val', 'test', 'all'\n",
    "                ): \n",
    "\n",
    "        \"\"\"\n",
    "        Returns the entire target dataset.\n",
    "        Return either the train, val, test, or all data.\n",
    "        \"\"\"\n",
    "\n",
    "        if dataset_type == 'train':\n",
    "            return self.Y[:self.val_index_start].copy() if self.Y is not None else None\n",
    "        elif dataset_type == 'val':\n",
    "            return self.Y[self.val_index_start:self.test_index_start].copy() if self.Y is not None else None\n",
    "        elif dataset_type == 'test':\n",
    "            return self.Y[self.test_index_start:].copy() if self.Y is not None else None\n",
    "        elif dataset_type == 'all':\n",
    "            return self.Y.copy() if self.Y is not None else None\n",
    "        else:\n",
    "            raise ValueError('dataset_type not recognized')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/dataloaders/tabular.py#L14){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "## XYDataLoader\n",
       "\n",
       ">      XYDataLoader (X:numpy.ndarray, Y:numpy.ndarray,\n",
       ">                    val_index_start:Optional[int]=None,\n",
       ">                    test_index_start:Optional[int]=None,\n",
       ">                    lag_window_params:dict=None)\n",
       "\n",
       "*A class for datasets with the typicall X, Y structure. Both X\n",
       "and Y are numpy arrays. X may be of shape (datapoints, features) or (datapoints, sequence_length, features) \n",
       "if lag features are used. The prep_lag_features can be used to create those lag features. Y is of shape\n",
       "(datapoints, units).*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| X | ndarray |  |  |\n",
       "| Y | ndarray |  |  |\n",
       "| val_index_start | Optional | None |  |\n",
       "| test_index_start | Optional | None |  |\n",
       "| lag_window_params | dict | None | default: {'lag_window': 0, 'include_y': False, 'pre_calc-calc': False} |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/dataloaders/tabular.py#L14){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "## XYDataLoader\n",
       "\n",
       ">      XYDataLoader (X:numpy.ndarray, Y:numpy.ndarray,\n",
       ">                    val_index_start:Optional[int]=None,\n",
       ">                    test_index_start:Optional[int]=None,\n",
       ">                    lag_window_params:dict=None)\n",
       "\n",
       "*A class for datasets with the typicall X, Y structure. Both X\n",
       "and Y are numpy arrays. X may be of shape (datapoints, features) or (datapoints, sequence_length, features) \n",
       "if lag features are used. The prep_lag_features can be used to create those lag features. Y is of shape\n",
       "(datapoints, units).*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| X | ndarray |  |  |\n",
       "| Y | ndarray |  |  |\n",
       "| val_index_start | Optional | None |  |\n",
       "| test_index_start | Optional | None |  |\n",
       "| lag_window_params | dict | None | default: {'lag_window': 0, 'include_y': False, 'pre_calc-calc': False} |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(XYDataLoader, title_level=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/dataloaders/tabular.py#L58){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### XYDataLoader.prep_lag_features\n",
       "\n",
       ">      XYDataLoader.prep_lag_features (lag_window:int=0, include_y:bool=False,\n",
       ">                                      pre_calc:bool=False)\n",
       "\n",
       "*Create lag feature for the dataset. If \"inlcude_y\" is true, then a lag-1 of of the target variable is added as a feature.\n",
       "If lag-window is > 0, the lag features are added as middle dimension to X. Note that this, e.g., means that with a lag\n",
       "window of 1, the data will include 2 time steps, the current features including lag-1 demand and the lag-1 features\n",
       "including lag-2 demand. If pre-calc is true, all these calculations are performed on the entire dataset reduce\n",
       "computation time later on at the expense of increases memory usage.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| lag_window | int | 0 | length of the lage window |\n",
       "| include_y | bool | False | if lag demand shall be included as feature |\n",
       "| pre_calc | bool | False | if all lags are pre-calculated for the entire dataset |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/dataloaders/tabular.py#L58){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### XYDataLoader.prep_lag_features\n",
       "\n",
       ">      XYDataLoader.prep_lag_features (lag_window:int=0, include_y:bool=False,\n",
       ">                                      pre_calc:bool=False)\n",
       "\n",
       "*Create lag feature for the dataset. If \"inlcude_y\" is true, then a lag-1 of of the target variable is added as a feature.\n",
       "If lag-window is > 0, the lag features are added as middle dimension to X. Note that this, e.g., means that with a lag\n",
       "window of 1, the data will include 2 time steps, the current features including lag-1 demand and the lag-1 features\n",
       "including lag-2 demand. If pre-calc is true, all these calculations are performed on the entire dataset reduce\n",
       "computation time later on at the expense of increases memory usage.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| lag_window | int | 0 | length of the lage window |\n",
       "| include_y | bool | False | if lag demand shall be included as feature |\n",
       "| pre_calc | bool | False | if all lags are pre-calculated for the entire dataset |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(XYDataLoader.prep_lag_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/dataloaders/tabular.py#L99){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### XYDataLoader.__getitem__\n",
       "\n",
       ">      XYDataLoader.__getitem__ (idx)\n",
       "\n",
       "*get item by index, depending on the dataset type (train, val, test)*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/dataloaders/tabular.py#L99){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### XYDataLoader.__getitem__\n",
       "\n",
       ">      XYDataLoader.__getitem__ (idx)\n",
       "\n",
       "*get item by index, depending on the dataset type (train, val, test)*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(XYDataLoader.__getitem__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/dataloaders/tabular.py#L150){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### XYDataLoader.get_all_X\n",
       "\n",
       ">      XYDataLoader.get_all_X (dataset_type:str='train')\n",
       "\n",
       "*Returns the entire features dataset.\n",
       "Return either the train, val, test, or all data.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| dataset_type | str | train | can be 'train', 'val', 'test', 'all' |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/dataloaders/tabular.py#L150){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### XYDataLoader.get_all_X\n",
       "\n",
       ">      XYDataLoader.get_all_X (dataset_type:str='train')\n",
       "\n",
       "*Returns the entire features dataset.\n",
       "Return either the train, val, test, or all data.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| dataset_type | str | train | can be 'train', 'val', 'test', 'all' |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(XYDataLoader.get_all_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/dataloaders/tabular.py#L169){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### XYDataLoader.get_all_Y\n",
       "\n",
       ">      XYDataLoader.get_all_Y (dataset_type:str='train')\n",
       "\n",
       "*Returns the entire target dataset.\n",
       "Return either the train, val, test, or all data.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| dataset_type | str | train | can be 'train', 'val', 'test', 'all' |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/dataloaders/tabular.py#L169){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### XYDataLoader.get_all_Y\n",
       "\n",
       ">      XYDataLoader.get_all_Y (dataset_type:str='train')\n",
       "\n",
       "*Returns the entire target dataset.\n",
       "Return either the train, val, test, or all data.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| dataset_type | str | train | can be 'train', 'val', 'test', 'all' |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(XYDataLoader.get_all_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example usage of ```XYDataLoader``` for simple dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample: [0.92106972 0.70156946] [3.65913853]\n",
      "sample shape Y: (1,)\n",
      "length: 100\n"
     ]
    }
   ],
   "source": [
    "X = np.random.standard_normal((100, 2))\n",
    "Y = np.random.standard_normal((100, 1))\n",
    "Y += 2*X[:,0].reshape(-1, 1) + 3*X[:,1].reshape(-1, 1)\n",
    "\n",
    "dataloader = XYDataLoader(X = X, Y = Y)\n",
    "\n",
    "sample_X, sample_Y = dataloader[0]\n",
    "print(\"sample:\", sample_X, sample_Y)\n",
    "print(\"sample shape Y:\", sample_Y.shape)\n",
    "\n",
    "print(\"length:\", len(dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example usage of ```XYDataLoader``` on how to handle train, val, and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length train: 6 length val: 2 length test: 2\n",
      "\n",
      "### Data from train set ###\n",
      "idx: 0 data: [ 0.46617153 -1.5426306 ] [-3.42515345]\n",
      "idx: 1 data: [0.5959217  0.03931713] [1.02734347]\n",
      "idx: 2 data: [-0.28027772 -0.3641926 ] [-0.21429458]\n",
      "idx: 3 data: [-0.28347742 -1.60037267] [-4.4814403]\n",
      "idx: 4 data: [ 0.01677989 -0.84802836] [-2.56829448]\n",
      "idx: 5 data: [0.54772979 0.48605575] [1.9488545]\n",
      "\n",
      "### Data from val set ###\n",
      "idx: 0 data: [ 0.30611839 -1.38076852] [-2.76311498]\n",
      "idx: 1 data: [0.46367473 1.40884102] [4.47144858]\n",
      "\n",
      "### Data from test set ###\n",
      "idx: 0 data: [-0.30705721  0.42819263] [1.50589912]\n",
      "idx: 1 data: [ 0.76539705 -0.06903068] [2.19095387]\n",
      "\n",
      "### Data from train set again ###\n",
      "idx: 0 data: [ 0.46617153 -1.5426306 ] [-3.42515345]\n",
      "idx: 1 data: [0.5959217  0.03931713] [1.02734347]\n",
      "idx: 2 data: [-0.28027772 -0.3641926 ] [-0.21429458]\n",
      "idx: 3 data: [-0.28347742 -1.60037267] [-4.4814403]\n",
      "idx: 4 data: [ 0.01677989 -0.84802836] [-2.56829448]\n",
      "idx: 5 data: [0.54772979 0.48605575] [1.9488545]\n"
     ]
    }
   ],
   "source": [
    "X = np.random.standard_normal((10, 2))\n",
    "Y = np.random.standard_normal((10, 1))\n",
    "Y += 2*X[:,0].reshape(-1, 1) + 3*X[:,1].reshape(-1, 1)\n",
    "\n",
    "dataloader = XYDataLoader(X = X, Y = Y, val_index_start=6, test_index_start=8)\n",
    "\n",
    "sample_X, sample_Y = dataloader[0]\n",
    "\n",
    "print(\"length train:\", dataloader.len_train, \"length val:\", dataloader.len_val, \"length test:\", dataloader.len_test)\n",
    "\n",
    "print(\"\")\n",
    "print(\"### Data from train set ###\")\n",
    "for i in range(dataloader.len_train):\n",
    "    sample_X, sample_Y = dataloader[i]\n",
    "    print(\"idx:\", i, \"data:\", sample_X, sample_Y)\n",
    "\n",
    "dataloader.val()\n",
    "\n",
    "print(\"\")\n",
    "print(\"### Data from val set ###\")\n",
    "for i in range(dataloader.len_val):\n",
    "    sample_X, sample_Y = dataloader[i]\n",
    "    print(\"idx:\", i, \"data:\", sample_X, sample_Y)\n",
    "\n",
    "dataloader.test()\n",
    "\n",
    "print(\"\")\n",
    "print(\"### Data from test set ###\")\n",
    "for i in range(dataloader.len_test):\n",
    "    sample_X, sample_Y = dataloader[i]\n",
    "    print(\"idx:\", i, \"data:\", sample_X, sample_Y)\n",
    "\n",
    "dataloader.train()\n",
    "\n",
    "print(\"\")\n",
    "print(\"### Data from train set again ###\")\n",
    "for i in range(dataloader.len_train):\n",
    "    sample_X, sample_Y = dataloader[i]\n",
    "    print(\"idx:\", i, \"data:\", sample_X, sample_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.30705721,  0.42819263],\n",
       "       [ 0.76539705, -0.06903068]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | hide\n",
    "dataloader.get_all_X('all')\n",
    "dataloader.get_all_X('train')\n",
    "dataloader.get_all_X('val')\n",
    "dataloader.get_all_X('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.50589912],\n",
       "       [2.19095387]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | hide\n",
    "\n",
    "dataloader.get_all_Y('all')\n",
    "dataloader.get_all_Y('train')\n",
    "dataloader.get_all_Y('val')\n",
    "dataloader.get_all_Y('test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example usage of ```XYDataLoader``` on how to include lag features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length train: 4 length val: 2 length test: 2\n",
      "\n",
      "### Data from train set ###\n",
      "idx: 0 data: [[-0.02395273 -0.36204873 -3.2205055 ]\n",
      " [ 1.45525805 -1.11224179 -0.94619   ]] [0.2521341]\n",
      "idx: 1 data: [[ 1.45525805 -1.11224179 -0.94619   ]\n",
      " [ 0.23480631  1.18639722  0.2521341 ]] [3.53852786]\n",
      "idx: 2 data: [[0.23480631 1.18639722 0.2521341 ]\n",
      " [1.82872894 1.5804164  3.53852786]] [7.25937768]\n",
      "idx: 3 data: [[ 1.82872894  1.5804164   3.53852786]\n",
      " [ 0.31580198 -0.31130287  7.25937768]] [-1.96853374]\n",
      "\n",
      "### Data from val set ###\n",
      "idx: 0 data: [[ 0.31580198 -0.31130287  7.25937768]\n",
      " [ 0.72142481 -0.76287586 -1.96853374]] [-1.33508208]\n",
      "idx: 1 data: [[ 0.72142481 -0.76287586 -1.96853374]\n",
      " [ 0.27407661 -2.12056758 -1.33508208]] [-6.31542487]\n",
      "\n",
      "### Data from test set ###\n",
      "idx: 0 data: [[ 0.27407661 -2.12056758 -1.33508208]\n",
      " [ 0.20329526 -1.08744979 -6.31542487]] [-4.01934226]\n",
      "idx: 1 data: [[ 0.20329526 -1.08744979 -6.31542487]\n",
      " [ 1.89736436  0.80393495 -4.01934226]] [6.99178952]\n",
      "\n",
      "### Data from train set again ###\n",
      "idx: 0 data: [[-0.02395273 -0.36204873 -3.2205055 ]\n",
      " [ 1.45525805 -1.11224179 -0.94619   ]] [0.2521341]\n",
      "idx: 1 data: [[ 1.45525805 -1.11224179 -0.94619   ]\n",
      " [ 0.23480631  1.18639722  0.2521341 ]] [3.53852786]\n",
      "idx: 2 data: [[0.23480631 1.18639722 0.2521341 ]\n",
      " [1.82872894 1.5804164  3.53852786]] [7.25937768]\n",
      "idx: 3 data: [[ 1.82872894  1.5804164   3.53852786]\n",
      " [ 0.31580198 -0.31130287  7.25937768]] [-1.96853374]\n"
     ]
    }
   ],
   "source": [
    "X = np.random.standard_normal((10, 2))\n",
    "Y = np.random.standard_normal((10, 1))\n",
    "Y += 2*X[:,0].reshape(-1, 1) + 3*X[:,1].reshape(-1, 1)\n",
    "\n",
    "lag_window_params = {'lag_window': 1, 'include_y': True, 'pre_calc': True}\n",
    "\n",
    "dataloader = XYDataLoader(X = X, Y = Y, val_index_start=6, test_index_start=8, lag_window_params=lag_window_params)\n",
    "\n",
    "sample_X, sample_Y = dataloader[0]\n",
    "\n",
    "print(\"length train:\", dataloader.len_train, \"length val:\", dataloader.len_val, \"length test:\", dataloader.len_test)\n",
    "\n",
    "print(\"\")\n",
    "print(\"### Data from train set ###\")\n",
    "for i in range(dataloader.len_train):\n",
    "    sample_X, sample_Y = dataloader[i]\n",
    "    print(\"idx:\", i, \"data:\", sample_X, sample_Y)\n",
    "\n",
    "dataloader.val()\n",
    "\n",
    "print(\"\")\n",
    "print(\"### Data from val set ###\")\n",
    "for i in range(dataloader.len_val):\n",
    "    sample_X, sample_Y = dataloader[i]\n",
    "    print(\"idx:\", i, \"data:\", sample_X, sample_Y)\n",
    "\n",
    "dataloader.test()\n",
    "\n",
    "print(\"\")\n",
    "print(\"### Data from test set ###\")\n",
    "for i in range(dataloader.len_test):\n",
    "    sample_X, sample_Y = dataloader[i]\n",
    "    print(\"idx:\", i, \"data:\", sample_X, sample_Y)\n",
    "\n",
    "\n",
    "dataloader.train()\n",
    "\n",
    "print(\"\")\n",
    "print(\"### Data from train set again ###\")\n",
    "for i in range(dataloader.len_train):\n",
    "    sample_X, sample_Y = dataloader[i]\n",
    "    print(\"idx:\", i, \"data:\", sample_X, sample_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
