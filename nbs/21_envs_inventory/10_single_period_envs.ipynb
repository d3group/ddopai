{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Single period inventory environments\n",
    "\n",
    "> Static inventory environment where a decision only affects the next period (Newsvendor problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp envs.inventory.single_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Union, Tuple\n",
    "\n",
    "from ddopnew.envs.base import BaseEnvironment\n",
    "from ddopnew.utils import Parameter, MDPInfo\n",
    "from ddopnew.dataloaders.base import BaseDataLoader\n",
    "from ddopnew.loss_functions import pinball_loss\n",
    "from ddopnew.envs.inventory.base import BaseInventoryEnv\n",
    "\n",
    "import gymnasium as gym\n",
    "\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class NewsvendorEnv(BaseInventoryEnv, ABC):\n",
    "    \n",
    "    \"\"\"\n",
    "    Class implementing the Newsvendor problem, working for the single- and multi-item case. If underage_cost and overage_cost\n",
    "    are scalars and there are multiple SKUs, then the same cost is used for all SKUs. If underage_cost and overage_cost are arrays,\n",
    "    then they must have the same length as the number of SKUs. Num_SKUs can be set as parameter or inferred from the DataLoader.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "        underage_cost: Union[np.ndarray, Parameter, int, float] = 1, # underage cost per unit\n",
    "        overage_cost: Union[np.ndarray, Parameter, int, float] = 1, # overage cost per unit\n",
    "        q_bound_low: Union[np.ndarray, Parameter, int, float] = 0, # lower bound of the order quantity\n",
    "        q_bound_high: Union[np.ndarray, Parameter, int, float] = np.inf, # upper bound of the order quantity\n",
    "        dataloader: BaseDataLoader = None, # dataloader\n",
    "        num_SKUs: Union[int] = None, # if None it will be inferred from the DataLoader\n",
    "        gamma: float = 1, # discount factor\n",
    "        horizon_train: Union[str, int] = 100, # if \"use_all_data\" then horizon is inferred from the DataLoader\n",
    "        postprocessors: list[object] | None = None,  # default is empty list\n",
    "        mode: str = \"train\", # Initial mode (train, val, test) of the environment\n",
    "        return_truncation: str = True # whether to return a truncated condition in step function\n",
    "    ) -> None:\n",
    "\n",
    "        self.horizon_train = horizon_train\n",
    "        \n",
    "        self.dataloader = dataloader\n",
    "\n",
    "        num_SKUs = dataloader.num_units if num_SKUs is None else num_SKUs\n",
    "        if not isinstance(num_SKUs, int):\n",
    "            raise ValueError(\"num_SKUs must be an integer.\")\n",
    "        \n",
    "        self.set_param(\"num_SKUs\", num_SKUs, new=True)\n",
    "        \n",
    "        self.set_param(\"underage_cost\", underage_cost, shape=(num_SKUs,), new=True)\n",
    "        self.set_param(\"overage_cost\", overage_cost, shape=(num_SKUs,), new=True)\n",
    "        \n",
    "        self.set_param(\"q_bound_low\", q_bound_low, shape=(num_SKUs,), new=True)\n",
    "        self.set_param(\"q_bound_high\", q_bound_high, shape=(num_SKUs,), new=True)\n",
    "        \n",
    "        self.set_observation_space(dataloader.X_shape)\n",
    "\n",
    "        self.set_action_space(dataloader.Y_shape, low = self.q_bound_low, high = self.q_bound_high)\n",
    "\n",
    "        self.print=False\n",
    "\n",
    "        mdp_info = MDPInfo(self.observation_space, self.action_space, gamma=gamma, horizon=horizon_train)\n",
    "        \n",
    "        super().__init__(mdp_info=mdp_info, postprocessors = postprocessors,  mode=mode, return_truncation=return_truncation)\n",
    "\n",
    "    def step_(self, \n",
    "            action: np.ndarray # order quantity\n",
    "            ) -> Tuple[np.ndarray, float, bool, bool, dict]:\n",
    "\n",
    "        \"\"\"\n",
    "        Step function implementing the Newsvendor logic. Note that the dataloader will return an observation and a demad,\n",
    "        which will be relevant in the next period. The observation will be returned directly, while the demand will be \n",
    "        temporarily stored under self.demand and used in the next step.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # Most agent give by default a batch dimension which is not needed for a single period action.\n",
    "        # If action shape size is 2 and the first dimensiion is 1, then remove it\n",
    "        if action.ndim == 2 and action.shape[0] == 1:\n",
    "            action = np.squeeze(action, axis=0)  # Remove the first dimension\n",
    "\n",
    "        cost_per_SKU = pinball_loss(self.demand, action, self.underage_cost, self.overage_cost)\n",
    "        reward = -np.sum(cost_per_SKU) # negative because we want to minimize the cost\n",
    "\n",
    "        terminated = False # in this problem there is no termination condition\n",
    "        \n",
    "        info = dict(\n",
    "            demand=self.demand.copy(),\n",
    "            action=action.copy(),\n",
    "            cost_per_SKU=cost_per_SKU.copy()\n",
    "        )\n",
    "\n",
    "        # Set index will set the index and return True if the index is out of bounds\n",
    "        truncated = self.set_index()\n",
    "\n",
    "        if truncated:\n",
    "\n",
    "            observation = np.zeros_like(self.observation_space.sample()) if self.observation_space is not None else None\n",
    "            demand = np.zeros_like(self.action_space.sample())\n",
    "\n",
    "            return observation, reward, terminated, truncated, info\n",
    "        \n",
    "        else:\n",
    "\n",
    "            observation, self.demand = self.get_observation()\n",
    "\n",
    "            if self.print:\n",
    "                print(\"next_period:\", self.index+1)\n",
    "                print(\"next observation:\", observation)\n",
    "                print(\"next demand:\", self.demand)\n",
    "                time.sleep(3)\n",
    "\n",
    "            return observation, reward, terminated, truncated, info\n",
    "\n",
    "    def reset(self,\n",
    "        start_index: int | str = None, # index to start from\n",
    "        state: np.ndarray = None # initial state\n",
    "        ) -> Tuple[np.ndarray, bool]:\n",
    "\n",
    "        \"\"\"\n",
    "        Reset function for the Newsvendor problem. It will return the first observation and demand.\n",
    "        For val and test modes, it will by default reset to 0, while for the train mode it depends\n",
    "        on the paramter \"horizon_train\" whether a random point in the training data is selected or 0\n",
    "        \"\"\"\n",
    "\n",
    "        if start_index is None:\n",
    "            if self._mode == \"train\":\n",
    "                if self.horizon_train == \"use_all_data\":\n",
    "                    start_index = 0\n",
    "                elif hasattr(self.dataloader, \"is_distribution\") and self.dataloader.is_distribution:\n",
    "                    start_index = 0\n",
    "                else:\n",
    "                    start_index = \"random\"\n",
    "            elif self._mode == \"val\":\n",
    "                start_index = 0\n",
    "            elif self._mode == \"test\":\n",
    "                start_index = 0\n",
    "            else:\n",
    "                raise ValueError(\"Mode not recognized.\")\n",
    "\n",
    "        truncated = self.reset_index(start_index)\n",
    "\n",
    "        observation, self.demand = self.get_observation()\n",
    "        \n",
    "        return observation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/envs/inventory.py#L101){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "## NewsvendorEnv\n",
       "\n",
       ">      NewsvendorEnv\n",
       ">                     (underage_cost:Union[numpy.ndarray,ddopnew.utils.Parameter\n",
       ">                     ,int,float]=1, overage_cost:Union[numpy.ndarray,ddopnew.ut\n",
       ">                     ils.Parameter,int,float]=1, q_bound_low:Union[numpy.ndarra\n",
       ">                     y,ddopnew.utils.Parameter,int,float]=0, q_bound_high:Union\n",
       ">                     [numpy.ndarray,ddopnew.utils.Parameter,int,float]=inf,\n",
       ">                     dataloader:ddopnew.dataloaders.base.BaseDataLoader=None,\n",
       ">                     num_SKUs:int=None, gamma:float=1,\n",
       ">                     horizon_train:Union[str,int]=100,\n",
       ">                     postprocessors:list[object]|None=None, mode:str='train',\n",
       ">                     return_truncation:str=True)\n",
       "\n",
       "*Class implementing the Newsvendor problem, working for the single- and multi-item case. If underage_cost and overage_cost\n",
       "are scalars and there are multiple SKUs, then the same cost is used for all SKUs. If underage_cost and overage_cost are arrays,\n",
       "then they must have the same length as the number of SKUs. Num_SKUs can be set as parameter or inferred from the DataLoader.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| underage_cost | Union | 1 | underage cost per unit |\n",
       "| overage_cost | Union | 1 | overage cost per unit |\n",
       "| q_bound_low | Union | 0 | lower bound of the order quantity |\n",
       "| q_bound_high | Union | inf | upper bound of the order quantity |\n",
       "| dataloader | BaseDataLoader | None | dataloader |\n",
       "| num_SKUs | int | None | if None it will be inferred from the DataLoader |\n",
       "| gamma | float | 1 | discount factor |\n",
       "| horizon_train | Union | 100 | if \"use_all_data\" then horizon is inferred from the DataLoader |\n",
       "| postprocessors | list[object] \\| None | None | default is empty list |\n",
       "| mode | str | train | Initial mode (train, val, test) of the environment |\n",
       "| return_truncation | str | True | whether to return a truncated condition in step function |\n",
       "| **Returns** | **None** |  |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/envs/inventory.py#L101){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "## NewsvendorEnv\n",
       "\n",
       ">      NewsvendorEnv\n",
       ">                     (underage_cost:Union[numpy.ndarray,ddopnew.utils.Parameter\n",
       ">                     ,int,float]=1, overage_cost:Union[numpy.ndarray,ddopnew.ut\n",
       ">                     ils.Parameter,int,float]=1, q_bound_low:Union[numpy.ndarra\n",
       ">                     y,ddopnew.utils.Parameter,int,float]=0, q_bound_high:Union\n",
       ">                     [numpy.ndarray,ddopnew.utils.Parameter,int,float]=inf,\n",
       ">                     dataloader:ddopnew.dataloaders.base.BaseDataLoader=None,\n",
       ">                     num_SKUs:int=None, gamma:float=1,\n",
       ">                     horizon_train:Union[str,int]=100,\n",
       ">                     postprocessors:list[object]|None=None, mode:str='train',\n",
       ">                     return_truncation:str=True)\n",
       "\n",
       "*Class implementing the Newsvendor problem, working for the single- and multi-item case. If underage_cost and overage_cost\n",
       "are scalars and there are multiple SKUs, then the same cost is used for all SKUs. If underage_cost and overage_cost are arrays,\n",
       "then they must have the same length as the number of SKUs. Num_SKUs can be set as parameter or inferred from the DataLoader.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| underage_cost | Union | 1 | underage cost per unit |\n",
       "| overage_cost | Union | 1 | overage cost per unit |\n",
       "| q_bound_low | Union | 0 | lower bound of the order quantity |\n",
       "| q_bound_high | Union | inf | upper bound of the order quantity |\n",
       "| dataloader | BaseDataLoader | None | dataloader |\n",
       "| num_SKUs | int | None | if None it will be inferred from the DataLoader |\n",
       "| gamma | float | 1 | discount factor |\n",
       "| horizon_train | Union | 100 | if \"use_all_data\" then horizon is inferred from the DataLoader |\n",
       "| postprocessors | list[object] \\| None | None | default is empty list |\n",
       "| mode | str | train | Initial mode (train, val, test) of the environment |\n",
       "| return_truncation | str | True | whether to return a truncated condition in step function |\n",
       "| **Returns** | **None** |  |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(NewsvendorEnv, title_level=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/envs/base.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BaseEnvironment.step\n",
       "\n",
       ">      BaseEnvironment.step (action)\n",
       "\n",
       "*Step function of the environment. Do not overwrite this function. \n",
       "Instead, write the step_ function. Note that the postprocessor is applied here.*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/envs/base.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BaseEnvironment.step\n",
       "\n",
       ">      BaseEnvironment.step (action)\n",
       "\n",
       "*Step function of the environment. Do not overwrite this function. \n",
       "Instead, write the step_ function. Note that the postprocessor is applied here.*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(NewsvendorEnv.step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/envs/inventory.py#L218){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### NewsvendorEnv.reset\n",
       "\n",
       ">      NewsvendorEnv.reset (start_index:int|str=None, state:numpy.ndarray=None)\n",
       "\n",
       "*Reset function for the Newsvendor problem. It will return the first observation and demand.\n",
       "For val and test modes, it will by default reset to 0, while for the train mode it depends\n",
       "on the paramter \"horizon_train\" whether a random point in the training data is selected or 0*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| start_index | int \\| str | None | index to start from |\n",
       "| state | ndarray | None | initial state |\n",
       "| **Returns** | **Tuple** |  |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/envs/inventory.py#L218){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### NewsvendorEnv.reset\n",
       "\n",
       ">      NewsvendorEnv.reset (start_index:int|str=None, state:numpy.ndarray=None)\n",
       "\n",
       "*Reset function for the Newsvendor problem. It will return the first observation and demand.\n",
       "For val and test modes, it will by default reset to 0, while for the train mode it depends\n",
       "on the paramter \"horizon_train\" whether a random point in the training data is selected or 0*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| start_index | int \\| str | None | index to start from |\n",
       "| state | ndarray | None | initial state |\n",
       "| **Returns** | **Tuple** |  |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(NewsvendorEnv.reset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example usage of ```NewsvendorEnv``` with a distributional dataloader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NewsvendorEnv' object has no attribute 'max_index_episode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtruncated:\u001b[39m\u001b[38;5;124m\"\u001b[39m, truncated)\n\u001b[1;32m     14\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m NormalDistributionDataLoader(mean\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m3\u001b[39m], std\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m], num_units\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m test_env \u001b[38;5;241m=\u001b[39m \u001b[43mNewsvendorEnv\u001b[49m\u001b[43m(\u001b[49m\u001b[43munderage_cost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverage_cost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhorizon_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m obs \u001b[38;5;241m=\u001b[39m test_env\u001b[38;5;241m.\u001b[39mreset(start_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m##### RESET #####\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[22], line 48\u001b[0m, in \u001b[0;36mNewsvendorEnv.__init__\u001b[0;34m(self, underage_cost, overage_cost, q_bound_low, q_bound_high, dataloader, num_SKUs, gamma, horizon_train, postprocessors, mode, return_truncation)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     46\u001b[0m mdp_info \u001b[38;5;241m=\u001b[39m MDPInfo(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space, gamma\u001b[38;5;241m=\u001b[39mgamma, horizon\u001b[38;5;241m=\u001b[39mhorizon_train)\n\u001b[0;32m---> 48\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmdp_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmdp_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocessors\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpostprocessors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_truncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_truncation\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 15\u001b[0m, in \u001b[0;36mBaseInventoryEnv.__init__\u001b[0;34m(self, mdp_info, postprocessors, mode, return_truncation)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \n\u001b[1;32m      9\u001b[0m     mdp_info: MDPInfo, \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     postprocessors: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mobject\u001b[39m] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,  \u001b[38;5;66;03m# default is empty list\u001b[39;00m\n\u001b[1;32m     11\u001b[0m     mode: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;66;03m# Initial mode (train, val, test) of the environment\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     return_truncation: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;66;03m# whether to return a truncated condition in step function\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 15\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmdp_info\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmdp_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocessors\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpostprocessors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_truncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_truncation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/02_PhD/Other_python_projects/00_ddop_new/ddopnew/ddopnew/envs/base.py:42\u001b[0m, in \u001b[0;36mBaseEnvironment.__init__\u001b[0;34m(self, mdp_info, postprocessors, mode, return_truncation)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mdp_info \u001b[38;5;241m=\u001b[39m mdp_info\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m: \n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval()\n",
      "File \u001b[0;32m~/Documents/02_PhD/Other_python_projects/00_ddop_new/ddopnew/ddopnew/envs/base.py:292\u001b[0m, in \u001b[0;36mBaseEnvironment.train\u001b[0;34m(self, update_mdp_info)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m update_mdp_info:\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_mdp_info(gamma\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmdp_info\u001b[38;5;241m.\u001b[39mgamma, horizon\u001b[38;5;241m=\u001b[39mhorizon)\n\u001b[0;32m--> 292\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[22], line 145\u001b[0m, in \u001b[0;36mNewsvendorEnv.reset\u001b[0;34m(self, start_index, state)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMode not recognized.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 145\u001b[0m truncated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m observation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdemand \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_observation()\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m observation\n",
      "File \u001b[0;32m~/Documents/02_PhD/Other_python_projects/00_ddop_new/ddopnew/ddopnew/envs/base.py:246\u001b[0m, in \u001b[0;36mBaseEnvironment.reset_index\u001b[0;34m(self, start_index)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(start_index, \u001b[38;5;28mint\u001b[39m):\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstart_index \u001b[38;5;241m=\u001b[39m start_index\n\u001b[0;32m--> 246\u001b[0m     truncated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_index must be an integer or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/02_PhD/Other_python_projects/00_ddop_new/ddopnew/ddopnew/envs/base.py:220\u001b[0m, in \u001b[0;36mBaseEnvironment.set_index\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 220\u001b[0m truncated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_index_episode\u001b[49m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m truncated\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NewsvendorEnv' object has no attribute 'max_index_episode'"
     ]
    }
   ],
   "source": [
    "from ddopnew.dataloaders.distribution import NormalDistributionDataLoader\n",
    "\n",
    "def run_test_loop(env):\n",
    "    truncated = False\n",
    "    while not truncated:\n",
    "        action = env.action_space.sample()\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        print(\"##### STEP: \", env.index, \"#####\")\n",
    "        print(\"reward:\", reward)\n",
    "        print(\"info:\", info)\n",
    "        print(\"next observation:\", obs)\n",
    "        print(\"truncated:\", truncated)\n",
    "\n",
    "dataloader = NormalDistributionDataLoader(mean=[4, 3], std=[1, 2], num_units=2)\n",
    "\n",
    "test_env = NewsvendorEnv(underage_cost=1, overage_cost=2, dataloader=dataloader, horizon_train=3)\n",
    "\n",
    "obs = test_env.reset(start_index=0)\n",
    "print(\"##### RESET #####\")\n",
    "\n",
    "run_test_loop(test_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example usage of ```NewsvendorEnv``` using a fixed dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################### RESET ####################\n",
      "#################### RUN IN TRAIN MODE ####################\n",
      "##### STEP:  1 #####\n",
      "reward: -0.6789389739421594\n",
      "info: {'demand': array([0.41801109, 0.41814421]), 'action': array([0.04, 1.02], dtype=float32), 'cost_per_SKU': array([0.37801109, 0.30092789])}\n",
      "next observation: [0.51654708 0.67238019]\n",
      "truncated: False\n",
      "##### STEP:  2 #####\n",
      "reward: -0.31011557616595586\n",
      "info: {'demand': array([0.61617324, 0.52211535]), 'action': array([0.35, 0.61], dtype=float32), 'cost_per_SKU': array([0.26617325, 0.04394233])}\n",
      "next observation: [0.71467365 0.37996181]\n",
      "truncated: False\n",
      "##### STEP:  3 #####\n",
      "reward: -0.8341675952170908\n",
      "info: {'demand': array([0.45242345, 0.60924132]), 'action': array([0.67, 2.06], dtype=float32), 'cost_per_SKU': array([0.10878828, 0.72537931])}\n",
      "next observation: [0.78011439 1.        ]\n",
      "truncated: False\n",
      "##### STEP:  4 #####\n",
      "reward: -1.1401562849186946\n",
      "info: {'demand': array([1.        , 0.88968748]), 'action': array([0.08, 1.33], dtype=float32), 'cost_per_SKU': array([0.92      , 0.22015628])}\n",
      "next observation: [0. 0.]\n",
      "truncated: True\n",
      "#################### RUN IN VAL MODE ####################\n",
      "##### STEP:  1 #####\n",
      "reward: -1.2861999413627203\n",
      "info: {'demand': array([0.        , 0.16760013]), 'action': array([1.84, 0.9 ], dtype=float32), 'cost_per_SKU': array([0.92000002, 0.36619992])}\n",
      "next observation: [0.         0.59527916]\n",
      "truncated: False\n",
      "##### STEP:  2 #####\n",
      "reward: -0.812252234691077\n",
      "info: {'demand': array([0.33549548, 0.        ]), 'action': array([1.54, 0.42], dtype=float32), 'cost_per_SKU': array([0.60225224, 0.20999999])}\n",
      "next observation: [0. 0.]\n",
      "truncated: True\n",
      "#################### RUN IN TEST MODE ####################\n",
      "##### STEP:  1 #####\n",
      "reward: -0.2898165142767727\n",
      "info: {'demand': array([0.3316407 , 0.33063685]), 'action': array([0.67, 0.21], dtype=float32), 'cost_per_SKU': array([0.16917966, 0.12063685])}\n",
      "next observation: [1.         0.71807281]\n",
      "truncated: False\n",
      "##### STEP:  2 #####\n",
      "reward: -1.4154925147993378\n",
      "info: {'demand': array([0.8554925, 1.       ]), 'action': array([0.39, 0.05], dtype=float32), 'cost_per_SKU': array([0.46549252, 0.95      ])}\n",
      "next observation: [0. 0.]\n",
      "truncated: True\n",
      "#################### RUN IN TRAIN MODE AGAIN ####################\n",
      "##### STEP:  1 #####\n",
      "reward: -0.4661552922333969\n",
      "info: {'demand': array([0.41801109, 0.41814421]), 'action': array([0.23, 0.14], dtype=float32), 'cost_per_SKU': array([0.18801108, 0.27814421])}\n",
      "next observation: [0.51654708 0.67238019]\n",
      "truncated: False\n",
      "##### STEP:  2 #####\n",
      "reward: -3.455855798770788\n",
      "info: {'demand': array([0.61617324, 0.52211535]), 'action': array([6.59, 1.46], dtype=float32), 'cost_per_SKU': array([2.98691346, 0.46894234])}\n",
      "next observation: [0.71467365 0.37996181]\n",
      "truncated: False\n",
      "##### STEP:  3 #####\n",
      "reward: -1.3930296136285667\n",
      "info: {'demand': array([0.45242345, 0.60924132]), 'action': array([2.46, 0.22], dtype=float32), 'cost_per_SKU': array([1.00378829, 0.38924132])}\n",
      "next observation: [0.78011439 1.        ]\n",
      "truncated: False\n",
      "##### STEP:  4 #####\n",
      "reward: -2.204687474270048\n",
      "info: {'demand': array([1.        , 0.88968748]), 'action': array([4.27, 0.32], dtype=float32), 'cost_per_SKU': array([1.63499999, 0.56968748])}\n",
      "next observation: [0. 0.]\n",
      "truncated: True\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from ddopnew.dataloaders.tabular import XYDataLoader\n",
    "\n",
    "# create a simple dataset bounded between 0 and 1.\n",
    "# We just scale all the data, pretending that it is the demand.\n",
    "# When using real data, one should only fit the scaler on the training data\n",
    "X, Y = make_regression(n_samples=8, n_features=2, n_targets=2, noise=0.1, random_state=42)\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "Y = scaler.fit_transform(Y)\n",
    "\n",
    "dataloader = XYDataLoader(X, Y, val_index_start = 4, test_index_start = 6)\n",
    "test_env = NewsvendorEnv(underage_cost=Parameter(np.array([1,1]), shape = (2,)), overage_cost=Parameter(np.array([0.5,0.5]), shape = (2,)), dataloader=dataloader, horizon_train=\"use_all_data\")\n",
    "\n",
    "obs = test_env.reset(start_index=0)\n",
    "print(\"#################### RESET ####################\")\n",
    "\n",
    "print(\"#################### RUN IN TRAIN MODE ####################\")\n",
    "run_test_loop(test_env)\n",
    "\n",
    "print(\"#################### RUN IN VAL MODE ####################\")\n",
    "test_env.val()\n",
    "run_test_loop(test_env)\n",
    "\n",
    "print(\"#################### RUN IN TEST MODE ####################\")\n",
    "test_env.test()\n",
    "run_test_loop(test_env)\n",
    "\n",
    "print(\"#################### RUN IN TRAIN MODE AGAIN ####################\")\n",
    "test_env.train()\n",
    "run_test_loop(test_env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #| export\n",
    "# class NewsvendorVariableSLEnv(NewsvendorEnv, ABC):\n",
    "#     \"\"\"\n",
    "\n",
    "#     \"\"\"\n",
    "#     def __init__(self,\n",
    "#         underage_cost: Union[np.ndarray, Parameter] = np.array([1]),\n",
    "#         overage_cost: Union[np.ndarray, Parameter] = np.array([1]),\n",
    "#         q_bound_low: Union[np.ndarray, Parameter] = np.array([0]),\n",
    "#         q_bound_high: Union[np.ndarray, Parameter] = np.array([np.inf]),\n",
    "#         dataloader: BaseDataLoader = None,\n",
    "#         gamma: float = 1,\n",
    "#         horizon: int = 100,\n",
    "\n",
    "#         low_sl: np.ndarray = np.array([0.1]),\n",
    "#         high_sl: np.ndarray = np.array([0.9]),\n",
    "\n",
    "#     ) -> None:\n",
    "    \n",
    "#         super().__init__( \n",
    "#             underage_cost=underage_cost,\n",
    "#             overage_cost=overage_cost,\n",
    "#             q_bound_low=q_bound_low,\n",
    "#             q_bound_high=q_bound_high,\n",
    "#             dataloader=dataloader,\n",
    "#             gamma=gamma,\n",
    "#             horizon=horizon,\n",
    "#         )\n",
    "\n",
    "#         self.low_sl = set_env_parameter(low_sl, self.num_SKUs)\n",
    "#         self.high_sl = set_env_parameter(high_sl, self.num_SKUs)\n",
    "    \n",
    "#     def set_observation_space(self,\n",
    "#                             shape: tuple,\n",
    "#                             low: Union[np.ndarray, float] = -np.inf,\n",
    "#                             high: Union[np.ndarray, float] = np.inf) -> None:\n",
    "        \n",
    "#         '''\n",
    "#         Set the observation space of the environment.\n",
    "#         '''\n",
    "\n",
    "#         ### THIS MAKES NO SENSE:\n",
    "\n",
    "#         # if shape is not None:\n",
    "#         #     if not isinstance(shape, tuple):\n",
    "#         #         raise ValueError(\"Shape must be a tuple.\")\n",
    "            \n",
    "#         #     shape = shape[1:]\n",
    "        \n",
    "#         #     self.observation_space = gym.spaces.Dict({\n",
    "#         #         'X': gym.spaces.Box(low=low, high=high, shape=shape, dtype=np.float32),\n",
    "#         #         'sl': gym.spaces.Box(low=0, high=1, shape=(self.num_SKUs,), dtype=np.float32)\n",
    "#         #     })\n",
    "#         # else:\n",
    "#         #     self.observation_space = gym.spaces.Dict({\n",
    "#         #         'sl': gym.spaces.Box(low=0, high=1, shape=(self.num_SKUs,), dtype=np.float32)\n",
    "#         #     })\n",
    "\n",
    "#     def get_observation(self):\n",
    "#         \"\"\"\n",
    "#         Return the current observation.\n",
    "#         \"\"\"\n",
    "        \n",
    "#         X_item, Y_item = self.dataloader[self.index]\n",
    "\n",
    "#         underage_cost, overage_cost, sl = self.draw_service_level()\n",
    "\n",
    "#         self.underage_cost.set_value(underage_cost, (self.num_SKUs,))\n",
    "#         self.overage_cost.set_value(overage_cost, (self.num_SKUs,))\n",
    "\n",
    "#         if X_item is not None:\n",
    "#             obs = {'X': X_item, 'sl': sl}\n",
    "#         else:\n",
    "#             obs = {'sl': sl}\n",
    "\n",
    "#         return obs, Y_item\n",
    "    \n",
    "#     def draw_service_level(self):\n",
    "        \n",
    "#         sl = np.random.uniform(self.low_sl, self.high_sl, self.num_SKUs)\n",
    "\n",
    "#         overage_cost = np.ones_like(sl)\n",
    "#         underage_cost = np.ones_like(sl)\n",
    "\n",
    "#         # # Calculate underage_cost where sl >= 0.5\n",
    "#         underage_cost = np.where(sl < 0.5, sl / (1 - sl), underage_cost)\n",
    "        \n",
    "#         # Calculate overage_cost where sl < 0.5\n",
    "#         overage_cost = np.where(sl >= 0.5, 1 / sl -1, overage_cost)\n",
    "        \n",
    "#         return underage_cost, overage_cost, sl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_env = NewsvendorVariableSLEnv(underage_cost=Parameter(np.array([1,1]), shape = (2,)), overage_cost=Parameter(np.array([0.5,0.5]), shape = (2,)), dataloader=dataloader, horizon=3)\n",
    "\n",
    "# print(test_env.observation_space)\n",
    "# print(test_env.observation_space.sample())\n",
    "\n",
    "# obs = test_env.reset(start_index=0)\n",
    "# print(\"##### RESET #####\")\n",
    "# print(\"obs:\", obs)\n",
    "\n",
    "# truncated = False\n",
    "# while not truncated:\n",
    "#     action = test_env.action_space.sample()\n",
    "#     obs, reward, terminated, truncated, info = test_env.step(action)\n",
    "#     print(\"##### STEP: \", test_env.index, \"#####\")\n",
    "#     print(\"reward:\", reward)\n",
    "#     print(\"info:\", info)\n",
    "#     print(\"obs:\", obs)\n",
    "#     print(\"truncated:\", truncated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Example with synthetic data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import make_regression\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# from ddopnew.dataloaders.tabular import XYDataLoader\n",
    "\n",
    "# # create a simple dataset bounded between 0 and 1\n",
    "# X, Y = make_regression(n_samples=100, n_features=2, n_targets=2, noise=0.1)\n",
    "# scaler = MinMaxScaler()\n",
    "# X = scaler.fit_transform(X)\n",
    "# Y = scaler.fit_transform(Y)\n",
    "\n",
    "# dataloader = XYDataLoader(X, Y)\n",
    "# test_env = NewsvendorVariableSLEnv(underage_cost=Parameter(np.array([1,1]), shape = (2,)), overage_cost=Parameter(np.array([0.5,0.5]), shape = (2,)), dataloader=dataloader, horizon=len(dataloader))\n",
    "\n",
    "# print(test_env.observation_space)\n",
    "# print(test_env.observation_space.sample())\n",
    "\n",
    "# obs = test_env.reset(start_index=0)\n",
    "# print(\"##### RESET #####\")\n",
    "# print(\"obs:\", obs)\n",
    "\n",
    "# truncated = False\n",
    "# while not truncated:\n",
    "#     action = test_env.action_space.sample()\n",
    "#     obs, reward, terminated, truncated, info = test_env.step(action)\n",
    "#     print(\"##### STEP: \", test_env.index, \"#####\")\n",
    "#     print(\"reward:\", reward)\n",
    "#     print(\"info:\", info)\n",
    "#     print(\"obs:\", obs)\n",
    "#     print(\"truncated:\", truncated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
