{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tabular dataloaders\n",
    "\n",
    "> To be written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp dataloaders.tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import numpy as np\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Union\n",
    "\n",
    "from ddopnew.dataloaders.base import BaseDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class XYDataLoader(BaseDataLoader):\n",
    "    \n",
    "    def __init__(self,\n",
    "        X: np.ndarray,\n",
    "        Y: np.ndarray,\n",
    "        val_index_start: Union[int, None] = None, # give list\n",
    "        test_index_start: Union[int, None] = None, # give list\n",
    "        lag_window_params: Union[dict] = None # default: {'lag_window': None, 'include_y': False, 'pre-calc': False}\n",
    "    ):\n",
    "\n",
    "\n",
    "\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "        self.val_index_start = val_index_start\n",
    "        self.test_index_start = test_index_start\n",
    "\n",
    "        if self.val_index_start is not None:\n",
    "            self.train_index_end = self.val_index_start-1\n",
    "        elif self.test_index_start is not None:\n",
    "            self.train_index_end = self.test_index_start-1\n",
    "        else:\n",
    "            self.train_index_end = len(Y)-1\n",
    "\n",
    "        self.dataset_type = \"train\"\n",
    "\n",
    "        lag_window_params = lag_window_params or {'lag_window': None, 'include_y': False, 'pre-calc': False}\n",
    "\n",
    "        self.prep_lag_features(lag_window_params)\n",
    "\n",
    "  \n",
    "        if len(X.shape) == 1:\n",
    "            self.X = X.reshape(-1, 1)\n",
    "        \n",
    "        if len(Y.shape) == 1:\n",
    "            self.Y = Y.reshape(-1, 1)\n",
    "\n",
    "        assert len(X) == len(Y), 'X and Y must have the same length'\n",
    "\n",
    "        self.num_units = Y.shape[1] # shape 0 is alsways time, shape 1 is the number of units (e.g., SKUs)\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "    def prep_lag_features(self, lag_window_params: dict):\n",
    "        # handle lag window for data\n",
    "        # to be discussed: Do we need option to only provide lag demand wihtout lag features?\n",
    "        self.lag_window = lag_window_params['lag_window']\n",
    "        self.include_y = lag_window_params['include_y']\n",
    "        self.pre_calc = lag_window_params['pre-calc']\n",
    "\n",
    "        if self.pre_calc:\n",
    "            if self.include_y:\n",
    "                # add additional column to X with demand shifted by 1\n",
    "                self.X = np.concatenate((self.X, np.roll(self.Y, 1, axis=0)), axis=1)\n",
    "                self.X = self.X[1:] # remove first row\n",
    "                self.Y = self.Y[1:] # remove first row\n",
    "                \n",
    "                self.val_index_start = self.val_index_start-1\n",
    "                self.test_index_start = self.test_index_start-1\n",
    "                self.train_index_end  = self.train_index_end-1\n",
    "        \n",
    "            if self.lag_window is not None and self.lag_window > 0:\n",
    "\n",
    "                # add lag features as dimention 2 to X (making it dimension (datapoints, sequence_length, features))\n",
    "                X_lag = np.zeros((self.X.shape[0], self.lag_window+1, self.X.shape[1]))\n",
    "                for i in range(self.lag_window+1):\n",
    "                    if i == 0:\n",
    "                        features = self.X\n",
    "                    else:    \n",
    "                        features = self.X[:-i, :]\n",
    "                    X_lag[i:, self.lag_window-i, :] = features\n",
    "                self.X = X_lag[self.lag_window:]\n",
    "                self.Y = self.Y[self.lag_window:]\n",
    "\n",
    "                self.val_index_start = self.val_index_start-self.lag_window\n",
    "                self.test_index_start = self.test_index_start-self.lag_window\n",
    "                self.train_index_end  = self.train_index_end-self.lag_window\n",
    "\n",
    "        else:\n",
    "            self.lag_window = None\n",
    "            self.include_y = False\n",
    "\n",
    "                # add time dimension to X\n",
    "    \n",
    "    def __getitem__(self, idx): \n",
    "\n",
    "        if self.dataset_type == \"train\":\n",
    "            if idx > self.train_index_end:\n",
    "                raise IndexError(f'index{idx} out of range{self.train_index_end}')\n",
    "            idx = idx\n",
    "\n",
    "        elif self.dataset_type == \"val\":\n",
    "            idx = idx + self.val_index_start\n",
    "            \n",
    "            if idx >= self.test_index_start:\n",
    "                raise IndexError(f'index{idx} out of range{self.test_index_start}')\n",
    "            \n",
    "        elif self.dataset_type == \"test\":\n",
    "            idx = idx + self.test_index_start\n",
    "            \n",
    "            if idx >= len(self.X):\n",
    "                raise IndexError(f'index{idx} out of range{len(self.X)}')\n",
    "        \n",
    "        else:\n",
    "            raise ValueError('dataset_type not set')\n",
    "\n",
    "        return self.X[idx], self.Y[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    @property\n",
    "    def X_shape(self):\n",
    "        return self.X.shape\n",
    "    \n",
    "    @property\n",
    "    def Y_shape(self):\n",
    "        return self.Y.shape\n",
    "\n",
    "    @property\n",
    "    def len_train(self):\n",
    "        return self.train_index_end+1\n",
    "\n",
    "    @property\n",
    "    def len_val(self):\n",
    "        if self.val_index_start is None:\n",
    "            raise ValueError('no validation set defined')\n",
    "        return self.test_index_start-self.val_index_start\n",
    "\n",
    "    @property\n",
    "    def len_test(self):\n",
    "        if self.test_index_start is None:\n",
    "            raise ValueError('no test set defined')\n",
    "        return len(self.Y)-self.test_index_start\n",
    "\n",
    "    def get_all_X(self,\n",
    "                dataset_type: str = 'train' # can be 'train', 'val', 'test', 'all'\n",
    "                ): \n",
    "\n",
    "        \"\"\"\n",
    "        Returns the entire features dataset. If no X data is available, return None.\n",
    "        \"\"\"\n",
    "\n",
    "        if dataset_type == 'train':\n",
    "            return self.X[:self.val_index_start].copy() if self.X is not None else None\n",
    "        elif dataset_type == 'val':\n",
    "            return self.X[self.val_index_start:self.test_index_start].copy() if self.X is not None else None\n",
    "        elif dataset_type == 'test':\n",
    "            return self.X[self.test_index_start:].copy() if self.X is not None else None\n",
    "        elif dataset_type == 'all':\n",
    "            return self.X.copy() if self.X is not None else None\n",
    "        else:\n",
    "            raise ValueError('dataset_type not recognized')\n",
    "\n",
    "    def get_all_Y(self,\n",
    "                dataset_type: str = 'train' # can be 'train', 'val', 'test', 'all'\n",
    "                ): \n",
    "\n",
    "        \"\"\"\n",
    "        Returns the entire target dataset. If no Y data is available, return None.\n",
    "        \"\"\"\n",
    "\n",
    "        if dataset_type == 'train':\n",
    "            return self.Y[:self.val_index_start].copy() if self.Y is not None else None\n",
    "        elif dataset_type == 'val':\n",
    "            return self.Y[self.val_index_start:self.test_index_start].copy() if self.Y is not None else None\n",
    "        elif dataset_type == 'test':\n",
    "            return self.Y[self.test_index_start:].copy() if self.Y is not None else None\n",
    "        elif dataset_type == 'all':\n",
    "            return self.Y.copy() if self.Y is not None else None\n",
    "        else:\n",
    "            raise ValueError('dataset_type not recognized')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample: [ 0.33274707 -0.24641805] [-0.45527037]\n",
      "sample shape Y: (1,)\n",
      "length: 100\n"
     ]
    }
   ],
   "source": [
    "X = np.random.standard_normal((100, 2))\n",
    "Y = np.random.standard_normal((100, 1))\n",
    "Y += 2*X[:,0].reshape(-1, 1) + 3*X[:,1].reshape(-1, 1)\n",
    "\n",
    "dataloader = XYDataLoader(X = X, Y = Y)\n",
    "\n",
    "sample_X, sample_Y = dataloader[0]\n",
    "print(\"sample:\", sample_X, sample_Y)\n",
    "print(\"sample shape Y:\", sample_Y.shape)\n",
    "\n",
    "print(\"length:\", len(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length train: 6 length val: 2 length test: 2\n",
      "\n",
      "### Data from train set ###\n",
      "idx: 0 data: [-0.4714739  -0.05026454] [1.33354208]\n",
      "idx: 1 data: [-0.56958581 -0.01464409] [-0.71487067]\n",
      "idx: 2 data: [ 1.01129044 -0.12002934] [3.42328914]\n",
      "idx: 3 data: [ 0.58626323 -0.93649442] [-1.8266753]\n",
      "idx: 4 data: [-0.15120646  0.76788591] [1.65753042]\n",
      "idx: 5 data: [0.20478926 1.0917585 ] [3.33542422]\n",
      "\n",
      "### Data from val set ###\n",
      "idx: 0 data: [ 0.40259561 -1.82746553] [-4.51104439]\n",
      "idx: 1 data: [ 1.14951959 -0.03224172] [2.86059253]\n",
      "\n",
      "### Data from test set ###\n",
      "idx: 0 data: [-1.97081197  0.97850784] [0.39491233]\n",
      "idx: 1 data: [-2.01072747 -0.04217872] [-3.66736877]\n",
      "\n",
      "### Data from train set again ###\n",
      "idx: 0 data: [-0.4714739  -0.05026454] [1.33354208]\n",
      "idx: 1 data: [-0.56958581 -0.01464409] [-0.71487067]\n",
      "idx: 2 data: [ 1.01129044 -0.12002934] [3.42328914]\n",
      "idx: 3 data: [ 0.58626323 -0.93649442] [-1.8266753]\n",
      "idx: 4 data: [-0.15120646  0.76788591] [1.65753042]\n",
      "idx: 5 data: [0.20478926 1.0917585 ] [3.33542422]\n"
     ]
    }
   ],
   "source": [
    "X = np.random.standard_normal((10, 2))\n",
    "Y = np.random.standard_normal((10, 1))\n",
    "Y += 2*X[:,0].reshape(-1, 1) + 3*X[:,1].reshape(-1, 1)\n",
    "\n",
    "dataloader = XYDataLoader(X = X, Y = Y, val_index_start=6, test_index_start=8)\n",
    "\n",
    "sample_X, sample_Y = dataloader[0]\n",
    "\n",
    "print(\"length train:\", dataloader.len_train, \"length val:\", dataloader.len_val, \"length test:\", dataloader.len_test)\n",
    "\n",
    "print(\"\")\n",
    "print(\"### Data from train set ###\")\n",
    "for i in range(dataloader.len_train):\n",
    "    sample_X, sample_Y = dataloader[i]\n",
    "    print(\"idx:\", i, \"data:\", sample_X, sample_Y)\n",
    "\n",
    "dataloader.val()\n",
    "\n",
    "print(\"\")\n",
    "print(\"### Data from val set ###\")\n",
    "for i in range(dataloader.len_val):\n",
    "    sample_X, sample_Y = dataloader[i]\n",
    "    print(\"idx:\", i, \"data:\", sample_X, sample_Y)\n",
    "\n",
    "dataloader.test()\n",
    "\n",
    "print(\"\")\n",
    "print(\"### Data from test set ###\")\n",
    "for i in range(dataloader.len_test):\n",
    "    sample_X, sample_Y = dataloader[i]\n",
    "    print(\"idx:\", i, \"data:\", sample_X, sample_Y)\n",
    "\n",
    "dataloader.train()\n",
    "\n",
    "print(\"\")\n",
    "print(\"### Data from train set again ###\")\n",
    "for i in range(dataloader.len_train):\n",
    "    sample_X, sample_Y = dataloader[i]\n",
    "    print(\"idx:\", i, \"data:\", sample_X, sample_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.97081197,  0.97850784],\n",
       "       [-2.01072747, -0.04217872]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader.get_all_X('all')\n",
    "dataloader.get_all_X('train')\n",
    "dataloader.get_all_X('val')\n",
    "dataloader.get_all_X('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.33354208],\n",
       "       [-0.71487067],\n",
       "       [ 3.42328914],\n",
       "       [-1.8266753 ],\n",
       "       [ 1.65753042],\n",
       "       [ 3.33542422]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader.get_all_Y('all')\n",
    "dataloader.get_all_Y('train')\n",
    "dataloader.get_all_Y('val')\n",
    "dataloader.get_all_Y('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length train: 4 length val: 2 length test: 2\n",
      "\n",
      "### Data from train set ###\n",
      "idx: 0 data: [[-1.40876254 -0.14268124 -3.32373933]\n",
      " [ 1.3568839   0.19228266 -3.47869167]] [2.83952595]\n",
      "idx: 1 data: [[ 1.3568839   0.19228266 -3.47869167]\n",
      " [ 0.57655503 -0.20559243  2.83952595]] [-1.03795912]\n",
      "idx: 2 data: [[ 0.57655503 -0.20559243  2.83952595]\n",
      " [ 0.64965388 -1.22862093 -1.03795912]] [-2.51057617]\n",
      "idx: 3 data: [[ 0.64965388 -1.22862093 -1.03795912]\n",
      " [-0.29481134  2.06600286 -2.51057617]] [4.69638231]\n",
      "\n",
      "### Data from val set ###\n",
      "idx: 0 data: [[-0.29481134  2.06600286 -2.51057617]\n",
      " [ 0.4712446  -0.19227017  4.69638231]] [-0.89261003]\n",
      "idx: 1 data: [[ 0.4712446  -0.19227017  4.69638231]\n",
      " [ 0.10975213 -0.01414033 -0.89261003]] [0.32833319]\n",
      "\n",
      "### Data from test set ###\n",
      "idx: 0 data: [[ 0.10975213 -0.01414033 -0.89261003]\n",
      " [ 0.44967256  0.13099119  0.32833319]] [-0.88167709]\n",
      "idx: 1 data: [[ 0.44967256  0.13099119  0.32833319]\n",
      " [ 0.29672722 -0.4092795  -0.88167709]] [-0.30977552]\n",
      "\n",
      "### Data from train set again ###\n",
      "idx: 0 data: [[-1.40876254 -0.14268124 -3.32373933]\n",
      " [ 1.3568839   0.19228266 -3.47869167]] [2.83952595]\n",
      "idx: 1 data: [[ 1.3568839   0.19228266 -3.47869167]\n",
      " [ 0.57655503 -0.20559243  2.83952595]] [-1.03795912]\n",
      "idx: 2 data: [[ 0.57655503 -0.20559243  2.83952595]\n",
      " [ 0.64965388 -1.22862093 -1.03795912]] [-2.51057617]\n",
      "idx: 3 data: [[ 0.64965388 -1.22862093 -1.03795912]\n",
      " [-0.29481134  2.06600286 -2.51057617]] [4.69638231]\n"
     ]
    }
   ],
   "source": [
    "X = np.random.standard_normal((10, 2))\n",
    "Y = np.random.standard_normal((10, 1))\n",
    "Y += 2*X[:,0].reshape(-1, 1) + 3*X[:,1].reshape(-1, 1)\n",
    "\n",
    "lag_window_params = {'lag_window': 1, 'include_y': True, 'pre-calc': True}\n",
    "\n",
    "dataloader = XYDataLoader(X = X, Y = Y, val_index_start=6, test_index_start=8, lag_window_params=lag_window_params)\n",
    "\n",
    "sample_X, sample_Y = dataloader[0]\n",
    "\n",
    "print(\"length train:\", dataloader.len_train, \"length val:\", dataloader.len_val, \"length test:\", dataloader.len_test)\n",
    "\n",
    "print(\"\")\n",
    "print(\"### Data from train set ###\")\n",
    "for i in range(dataloader.len_train):\n",
    "    sample_X, sample_Y = dataloader[i]\n",
    "    print(\"idx:\", i, \"data:\", sample_X, sample_Y)\n",
    "\n",
    "dataloader.val()\n",
    "\n",
    "print(\"\")\n",
    "print(\"### Data from val set ###\")\n",
    "for i in range(dataloader.len_val):\n",
    "    sample_X, sample_Y = dataloader[i]\n",
    "    print(\"idx:\", i, \"data:\", sample_X, sample_Y)\n",
    "\n",
    "dataloader.test()\n",
    "\n",
    "print(\"\")\n",
    "print(\"### Data from test set ###\")\n",
    "for i in range(dataloader.len_test):\n",
    "    sample_X, sample_Y = dataloader[i]\n",
    "    print(\"idx:\", i, \"data:\", sample_X, sample_Y)\n",
    "\n",
    "\n",
    "dataloader.train()\n",
    "\n",
    "print(\"\")\n",
    "print(\"### Data from train set again ###\")\n",
    "for i in range(dataloader.len_train):\n",
    "    sample_X, sample_Y = dataloader[i]\n",
    "    print(\"idx:\", i, \"data:\", sample_X, sample_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
