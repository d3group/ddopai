{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta experiment functions\n",
    "\n",
    "> Very high-level functions to run experiments with minimal code, directly from terminal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp meta_experiment_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:numexpr.utils:Note: NumExpr detected 10 cores but \"NUMEXPR_MAX_THREADS\" not set, so enforcing safe limit of 8.\n",
      "INFO:numexpr.utils:NumExpr defaulting to 8 threads.\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Union, List, Tuple, Dict, Literal\n",
    "import logging\n",
    "from datetime import datetime  \n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import yaml\n",
    "import pickle\n",
    "import warnings\n",
    "import torch\n",
    "\n",
    "from ddopai.tracking import get_git_hash, get_library_version\n",
    "from ddopai.agents.class_names import AGENT_CLASSES\n",
    "from ddopai.dataloaders.tabular import XYDataLoader\n",
    "from ddopai.datasets.default_datasets import DatasetLoader\n",
    "from ddopai.experiment_functions import EarlyStoppingHandler, test_agent\n",
    "\n",
    "import wandb\n",
    "\n",
    "import gc\n",
    "\n",
    "import importlib\n",
    "\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "# Think about how to handle mushroom integration.\n",
    "from mushroom_rl.core import Core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warnings\n",
    "\n",
    "> Some warnings are irrelevant for this library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def set_warnings (logging_level):\n",
    "\n",
    "    \"\"\" Set warnings to be ignored for the given logging level or higher.\"\"\"\n",
    "\n",
    "    if logging.getLogger().isEnabledFor(logging_level):\n",
    "        warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*Box bound precision lowered by casting to float32.*\")\n",
    "        warnings.filterwarnings(\"ignore\", category=UserWarning, message=\".*TypedStorage is deprecated.*\")\n",
    "        warnings.filterwarnings(\"ignore\", category=FutureWarning, message=\".*You are using `torch.load` with `weights_only=False`.*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load files and set-up tracking\n",
    "\n",
    "> Fist part of experiment: Log into wandb and load config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def prep_experiment(\n",
    "    project_name: str,\n",
    "    libraries_to_track: List[str] = [\"ddopai\"],\n",
    "    config_train_name: str = \"config_train\",\n",
    "    config_agent_name: str = \"config_agent\",\n",
    "    config_env_name: str = \"config_env\",\n",
    "):\n",
    "    \"\"\" First stpes to always execute when starting an experiment (using wandb for tracking)\"\"\"\n",
    "\n",
    "    init_wandb(project_name)\n",
    "    track_libraries_and_git(libraries_to_track)\n",
    "\n",
    "    config_train = import_config(config_train_name)\n",
    "    config_agent = import_config(config_agent_name) # General config file containing all agent parameters\n",
    "    config_env = import_config(config_env_name)\n",
    "\n",
    "    AgentClass = select_agent(config_train[\"agent\"]) # Select agent class and import dynamically\n",
    "    agent_name = config_train[\"agent\"]\n",
    "    config_agent = config_agent[config_train[\"agent\"]] # Get parameters for specific agent\n",
    "    \n",
    "    transfer_lag_window_to_env(config_env, config_agent) \n",
    "\n",
    "    wandb.config.update(config_train)\n",
    "    wandb.config.update(config_agent)\n",
    "    wandb.config.update(config_env)\n",
    "\n",
    "    return config_train, config_agent, config_env, AgentClass, agent_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def init_wandb(project_name: str): #\n",
    "\n",
    "    \"\"\" init wandb \"\"\"\n",
    "\n",
    "    wandb.init(\n",
    "        project=project_name,\n",
    "        name = f\"{project_name}_{datetime.now().strftime('%Y-%m-%d_%H-%M-%S')}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def track_libraries_and_git(    libraries_to_track: List[str],\n",
    "                                tracking: bool = True,\n",
    "                                tracking_tool = \"wandb\", # Currenty only wandb is supported\n",
    "                                ) -> None:\n",
    "    \n",
    "    \"\"\"\n",
    "    Track the versions of the libraries and the git hash of the repository.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    for lib in libraries_to_track:\n",
    "        version = get_library_version(lib, tracking=tracking, tracking_tool=tracking_tool)\n",
    "        logging.info(f\"{lib}: {version}\")\n",
    "    git_hash = get_git_hash(\".\", tracking=tracking, tracking_tool=tracking_tool)\n",
    "    logging.info(f\"Git hash: {git_hash}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def import_config(  filename: str, # Name of the file, must be a yaml file\n",
    "                    path: str = None # Optional path to the file if it is not in the current directory\n",
    "                    ) -> Dict:\n",
    "    \n",
    "    \"\"\"\n",
    "    Import a config file in YAML format\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Check if filename has an extension\n",
    "    if '.' in filename:\n",
    "        extension = filename.split(\".\")[-1]\n",
    "    else:\n",
    "        extension = ''\n",
    "\n",
    "    if not extension:\n",
    "        filename += \".yaml\"\n",
    "    elif extension not in [\"yaml\", \"yml\"]:\n",
    "        raise ValueError(\"The configuration file must have a .yaml or .yml extension.\")\n",
    "\n",
    "\n",
    "    if path is not None:\n",
    "        full_path = os.path.join(path, filename)\n",
    "    else:\n",
    "        full_path = filename\n",
    "    \n",
    "\n",
    "    # Check if the file exists\n",
    "    if not os.path.exists(full_path):\n",
    "        raise FileNotFoundError(f\"The configuration file '{full_path}' does not exist.\")\n",
    "\n",
    "    with open(full_path, \"r\") as stream:\n",
    "        try:\n",
    "            config = yaml.safe_load(stream)\n",
    "        except yaml.YAMLError as exc:\n",
    "            raise yaml.YAMLError(f\"Error parsing YAML file '{full_path}': {exc}\")\n",
    "    \n",
    "    logging.info(f\"Configuration file '{filename}' successfully loaded.\")\n",
    "    logging.debug(f\"Configuration: {config}\")\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def transfer_lag_window_to_env(config_env: Dict, #\n",
    "                                config_agent: Dict\n",
    "                                ) -> None:\n",
    "    \n",
    "    \"\"\"\n",
    "    Transfer the lag window from the agent configuration to the environment configuration\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    if \"lag_window\" in config_agent.keys():\n",
    "        if isinstance(config_agent[\"lag_window\"], int):\n",
    "            config_env[\"lag_window_params\"][\"lag_window\"] = config_agent[\"lag_window\"]\n",
    "        else:\n",
    "            raise ValueError(\"The lag window must be an integer.\")\n",
    "        del config_agent[\"lag_window\"]\n",
    "    else:\n",
    "        logging.warning(\"No lag window specified in the agent configuration. Keeping value from env config\")\n",
    "\n",
    "#| export\n",
    "def transfer_additional_target_to_env(config_env: Dict, #\n",
    "                                config_agent: Dict\n",
    "                                ) -> None:\n",
    "    \n",
    "    \"\"\"\n",
    "    Transfer the lag window from the agent configuration to the environment configuration\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    if \"provide_additional_target\" in config_agent.keys():\n",
    "        if isinstance(config_agent[\"provide_additional_target\"], bool):\n",
    "            config_env[\"provide_additional_target\"] = config_agent[\"provide_additional_target\"]\n",
    "        else:\n",
    "            raise ValueError(f\"Expected boolean value for provide_additional_target, got {config_agent['provide_additional_target']}\")\n",
    "        del config_agent[\"provide_additional_target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data\n",
    "\n",
    "> Import data from the ddop package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def get_ddop_data(\n",
    "    config_env: Dict,\n",
    "    overwrite: bool = False\n",
    "    ) -> Tuple:\n",
    "\n",
    "    \"\"\" Standard function to load data provided by the ddop package \"\"\"\n",
    "    \n",
    "    data = download_data(config_env, overwrite)\n",
    "\n",
    "    val_index_start, test_index_start = set_indices(config_env, data[0])\n",
    "\n",
    "    return data, val_index_start, test_index_start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def download_data(  config_env: Dict,\n",
    "                    overwrite: bool = False #\n",
    "                    ) -> Tuple:\n",
    "\n",
    "    \"\"\" Download standard dataset from ddop repository using the DatasetLoader class \"\"\"\n",
    "\n",
    "    datasetloader = DatasetLoader()\n",
    "\n",
    "    data = datasetloader.load_dataset(\n",
    "        dataset_type = config_env[\"dataset_type\"],\n",
    "        dataset_number = config_env[\"dataset_number\"],\n",
    "        overwrite=False)\n",
    "\n",
    "    data_tuple = data[\"data_raw_features\"], data[\"data_raw_target\"]\n",
    "\n",
    "    return data_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def set_indices(config_env: Dict, #\n",
    "                X: np.ndarray \n",
    ") -> Tuple:\n",
    "\n",
    "    \"\"\" Set the indices for the validation and test set \"\"\"\n",
    "\n",
    "    val_index_start = len(X) - config_env[\"size_val\"] - config_env[\"size_test\"]\n",
    "    test_index_start = len(X) - config_env[\"size_test\"]\n",
    "\n",
    "    return val_index_start, test_index_start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up environment\n",
    "\n",
    "> Some functions to set-up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def set_up_env(\n",
    "    env_class,\n",
    "    raw_data: Tuple, #\n",
    "    val_index_start: int,\n",
    "    test_index_start: int,\n",
    "    config_env: Dict,\n",
    "    postprocessors: List,\n",
    ") -> object:\n",
    "    \n",
    "    \"\"\" Set up the environment \"\"\"\n",
    "\n",
    "    dataloader = XYDataLoader(  X = raw_data[0],\n",
    "                                Y = raw_data[1],\n",
    "                                val_index_start = val_index_start,\n",
    "                                test_index_start = test_index_start,\n",
    "                                lag_window_params = config_env[\"lag_window_params\"],\n",
    "                                normalize_features = {'normalize': config_env[\"normalize_features\"], 'ignore_one_hot': True})\n",
    "\n",
    "    environment = env_class(\n",
    "        dataloader = dataloader,\n",
    "        postprocessors = postprocessors,\n",
    "        **config_env[\"env_kwargs\"]\n",
    "    )\n",
    "\n",
    "    return environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up training\n",
    "\n",
    "> Some functions to set-up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def set_up_earlystoppinghandler(config_train: Dict) -> object: #\n",
    "\n",
    "    \"\"\" Set up the early stopping handler \"\"\"\n",
    "\n",
    "    # check if config_train has either early_stopping_patience or early_stopping_warmup\n",
    "    if \"early_stopping_patience\" in config_train or \"early_stopping_warmup\" in config_train:\n",
    "        warmup = config_train[\"early_stopping_warmup\"] if \"early_stopping_warmup\" in config_train else 0\n",
    "        patience = config_train[\"early_stopping_patience\"] if \"early_stopping_patience\" in config_train else 0\n",
    "\n",
    "        earlystoppinghandler = EarlyStoppingHandler(warmup=warmup, patience=patience)\n",
    "    else:\n",
    "        earlystoppinghandler = None\n",
    "\n",
    "    return earlystoppinghandler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "> Some functions to test the final model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def prep_and_run_test(\n",
    "    agent,\n",
    "    environment,\n",
    "    agent_dir: str = None,\n",
    "    save_dataset: bool = True,\n",
    "    save_features: bool = False,\n",
    "    dataset_dir: str = None,\n",
    "    eval_step_info = False,\n",
    "    tracking = \"wandb\"):\n",
    "    \n",
    "    \"\"\"\n",
    "    Test the agent in the environment.\n",
    "    \"\"\"\n",
    "\n",
    "    if save_dataset:\n",
    "        if dataset_dir is None:\n",
    "            raise ValueError(\"If save_dataset is True, dataset_dir must be specified.\")\n",
    "\n",
    "    # load parameters of agent\n",
    "\n",
    "    if agent_dir is not None:\n",
    "        agent.load(agent_dir)\n",
    "\n",
    "    # Set agent and environment to test mode\n",
    "    agent.eval()\n",
    "    environment.test()\n",
    "\n",
    "    # Run test episode\n",
    "    output = test_agent(\n",
    "        agent,\n",
    "        environment,\n",
    "        return_dataset=save_dataset,\n",
    "        save_features=save_features,\n",
    "        tracking=tracking,\n",
    "        eval_step_info=eval_step_info,\n",
    "    )\n",
    "\n",
    "    # Save dataset\n",
    "    if save_dataset:\n",
    "\n",
    "        R, J, dataset = output\n",
    "\n",
    "        if not os.path.exists(dataset_dir):\n",
    "            os.mkdir(dataset_dir)\n",
    "        else:\n",
    "            raise ValueError(\"Path to save dataset already exists\") # it should never exist since run_id is usually part or path and unique\n",
    "        \n",
    "        dir = os.path.join(dataset_dir, \"dataset_test.pkl\")\n",
    "\n",
    "        with open (os.path.join(dir), \"wb\") as f:\n",
    "            pickle.dump(dataset, f)\n",
    "\n",
    "        artifact = wandb.Artifact(\"transition_test_set\", type=\"dataset\")\n",
    "\n",
    "        artifact.add_file(os.path.join(dir))\n",
    "\n",
    "        wandb.run.log_artifact(artifact)\n",
    "    \n",
    "    else:\n",
    "\n",
    "        R, J = output\n",
    "\n",
    "    logging.info(f\"final evaluation on test set: R = {np.round(R, 10)} J = {np.round(J, 10)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean-up\n",
    "\n",
    "> Function to clean-up the experiment script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def clean_up(agent, environment):\n",
    "\n",
    "    \"\"\" Clean up agent and environment to free up GPU memory \"\"\"\n",
    "    \n",
    "    # Delete agent and environment to free up GPU memory\n",
    "    del agent\n",
    "    del environment\n",
    "\n",
    "    # Force garbage collection\n",
    "    gc.collect()\n",
    "\n",
    "    # Clear GPU cache\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    wandb.finish()\n",
    "\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions\n",
    "\n",
    "> Some functions that are needed to run an experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def select_agent(agent_name: str) -> type: #\n",
    "    \"\"\" Select an agent class from a list of agent names and return the class\"\"\"\n",
    "    if agent_name in AGENT_CLASSES:\n",
    "        module_path, class_name = AGENT_CLASSES[agent_name].rsplit(\".\", 1)\n",
    "        module = importlib.import_module(module_path)\n",
    "        return getattr(module, class_name)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown agent name: {agent_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def merge_with_namespace(target_dict, source_dict, target_dict_name):\n",
    "    \n",
    "    \"\"\"\n",
    "    Merge source_dict into target_dict, using the keys as namespaces.\n",
    "    For example, if target_dict_name is \"agent\", the key \"agent-epsilon\" in source_dict will be merged into target_dict[\"epsilon\"].\n",
    "    The function is to merge hyperparameters from a config file with the default hyperparameters from the yaml files\n",
    "\n",
    "    Args:\n",
    "        target_dict (dict): Target dictionary\n",
    "        source_dict (dict): Source dictionary\n",
    "        target_dict_name (str): Name of the target dictionary\n",
    "\n",
    "    Returns:\n",
    "        dict: Merged dictionary\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    for namespaced_key, value in source_dict.items():\n",
    "        keys = namespaced_key.split('-')\n",
    "\n",
    "        if keys[0] != target_dict_name:\n",
    "            continue\n",
    "\n",
    "        keys = keys[1:]\n",
    "\n",
    "        d = target_dict\n",
    "    \n",
    "        # Check if keys already exist in target_dict\n",
    "        exists = True\n",
    "        for key in keys:\n",
    "            if key not in d:\n",
    "                exists = False\n",
    "                break\n",
    "            if isinstance(d[key], dict):\n",
    "                d = d[key]\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        # If all keys are present, overwrite the value\n",
    "        if exists:\n",
    "            prev = d[key]\n",
    "            d[key] = value\n",
    "            print(f\"Overwriting in key {namespaced_key} value {prev} with value {value}\")\n",
    "        else:\n",
    "            # exception if key is not present in target_dict\n",
    "            print(f\"Key {namespaced_key} not found in {target_dict_name}.\")\n",
    "            raise ValueError(f\"Key {namespaced_key} not found in {target_dict_name}.\")\n",
    "\n",
    "    return target_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
