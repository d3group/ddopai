{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General utils\n",
    "\n",
    "> Some general utility functions that are used throughout the package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from typing import Union, List, Tuple, Literal\n",
    "from gymnasium.spaces import Space\n",
    "from ddopai.dataloaders.base import BaseDataLoader\n",
    "\n",
    "import logging\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def check_parameter_types(\n",
    "                            *args,                      # any number of parameters to be checked\n",
    "                            parameter_type=np.ndarray   # the expected type for each parameter\n",
    "):\n",
    "    \n",
    "    \"\"\"\n",
    "    Checks if each argument in args is of the specified type, defaulting to np.ndarray.\n",
    "    \"\"\"\n",
    "    \n",
    "    for index, arg in enumerate(args):\n",
    "        if not isinstance(arg, parameter_type):\n",
    "            raise TypeError(f\"Argument {index+1} of {len(args)} is of type {type(arg).__name__}, expected {parameter_type.__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example usage for the `check_parameter_types` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Argument 2 of 2 is of type list, expected ndarray\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "b = [1, 2, 3]\n",
    "\n",
    "try:\n",
    "    check_parameter_types(a, b)\n",
    "except TypeError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Parameter():\n",
    "\n",
    "    \"\"\"\n",
    "    Legacy, not used in the current implementation.\n",
    "    \"\"\"\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class MDPInfo():\n",
    "    \"\"\"\n",
    "    This class is used to store the information of the environment.\n",
    "    It is based on MushroomRL (https://github.com/MushroomRL). It can be accessed by \n",
    "    agents that need the information of the environment, such as the state and action spaces.\n",
    "    \n",
    "    Key difference with MushroomRL is that the state and action spaces are gymnasium spaces.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                observation_space: Space,\n",
    "                action_space: Space,  \n",
    "                gamma: float,\n",
    "                horizon: int,\n",
    "                dt: float = 1e-1,\n",
    "                backend: Literal['numpy'] = 'numpy'  # Currently only numpy is supported\n",
    "            ) -> None: \n",
    "\n",
    "        self.observation_space = observation_space\n",
    "        self.action_space = action_space\n",
    "        self.gamma = gamma\n",
    "        self.horizon = horizon\n",
    "        self.dt = dt\n",
    "        self.backend = backend\n",
    "\n",
    "    @property\n",
    "    def size(self):\n",
    "        \"\"\"\n",
    "        Returns: The sum of the number of discrete states and discrete actions. Only works for discrete spaces.\n",
    "\n",
    "        \"\"\"\n",
    "        return self.observation_space.size + self.action_space.size\n",
    "\n",
    "    @property\n",
    "    def shape(self):\n",
    "        \"\"\"\n",
    "        Returns: The concatenation of the shape tuple of the state and action spaces.\n",
    "\n",
    "        \"\"\"\n",
    "        return self.observation_space.shape + self.action_space.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/utils.py#L118){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "## MDPInfo\n",
       "\n",
       ">      MDPInfo (observation_space:gymnasium.spaces.space.Space,\n",
       ">               action_space:gymnasium.spaces.space.Space, gamma:float,\n",
       ">               horizon:int, dt:float=0.1, backend:Literal['numpy']='numpy')\n",
       "\n",
       "*This class is used to store the information of the environment.\n",
       "It is based on MushroomRL (https://github.com/MushroomRL). It can be accessed by \n",
       "agents that need the information of the environment, such as the state and action spaces.\n",
       "\n",
       "Key difference with MushroomRL is that the state and action spaces are gymnasium spaces.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| observation_space | Space |  |  |\n",
       "| action_space | Space |  |  |\n",
       "| gamma | float |  |  |\n",
       "| horizon | int |  |  |\n",
       "| dt | float | 0.1 |  |\n",
       "| backend | Literal | numpy | Currently only numpy is supported |\n",
       "| **Returns** | **None** |  |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/utils.py#L118){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "## MDPInfo\n",
       "\n",
       ">      MDPInfo (observation_space:gymnasium.spaces.space.Space,\n",
       ">               action_space:gymnasium.spaces.space.Space, gamma:float,\n",
       ">               horizon:int, dt:float=0.1, backend:Literal['numpy']='numpy')\n",
       "\n",
       "*This class is used to store the information of the environment.\n",
       "It is based on MushroomRL (https://github.com/MushroomRL). It can be accessed by \n",
       "agents that need the information of the environment, such as the state and action spaces.\n",
       "\n",
       "Key difference with MushroomRL is that the state and action spaces are gymnasium spaces.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| observation_space | Space |  |  |\n",
       "| action_space | Space |  |  |\n",
       "| gamma | float |  |  |\n",
       "| horizon | int |  |  |\n",
       "| dt | float | 0.1 |  |\n",
       "| backend | Literal | numpy | Currently only numpy is supported |\n",
       "| **Returns** | **None** |  |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(MDPInfo, title_level=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/utils.py#L144){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MDPInfo.size\n",
       "\n",
       ">      MDPInfo.size ()\n",
       "\n",
       "*Returns: The sum of the number of discrete states and discrete actions. Only works for discrete spaces.*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/utils.py#L144){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MDPInfo.size\n",
       "\n",
       ">      MDPInfo.size ()\n",
       "\n",
       "*Returns: The sum of the number of discrete states and discrete actions. Only works for discrete spaces.*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(MDPInfo.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/utils.py#L152){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MDPInfo.shape\n",
       "\n",
       ">      MDPInfo.shape ()\n",
       "\n",
       "*Returns: The concatenation of the shape tuple of the state and action spaces.*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/utils.py#L152){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### MDPInfo.shape\n",
       "\n",
       ">      MDPInfo.shape ()\n",
       "\n",
       "*Returns: The concatenation of the shape tuple of the state and action spaces.*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(MDPInfo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class DatasetWrapper(Dataset):\n",
    "    \"\"\"\n",
    "    This class is used to wrap a Pytorch Dataset around the ddopai dataloader\n",
    "    to enable the usage of the Pytorch Dataloader during training. This way,\n",
    "    agents that are trained using Pytorch without interacting with the environment\n",
    "    can directly train on the data generated by the dataloader.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "            dataloader: BaseDataLoader, # Any dataloader that inherits from BaseDataLoader\n",
    "            obsprocessors: List = None # processors (to mimic the environment processors)\n",
    "            ):\n",
    "        self.dataloader = dataloader\n",
    "        self.obsprocessors = obsprocessors or []\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Get the item at the provided idx.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # create tuple of items\n",
    "\n",
    "        output = self.dataloader[idx]\n",
    "\n",
    "        X = output[0]\n",
    "\n",
    "        X = np.expand_dims(X, axis=0) # single datapoints are always returned without batch dimension, need to add for obsprocessors\n",
    "\n",
    "        for obsprocessor in self.obsprocessors:\n",
    "            X = obsprocessor(X)\n",
    "        \n",
    "        X = np.squeeze(X, axis=0) # remove batch dimension\n",
    "\n",
    "        output = (X, *output[1:])\n",
    "        \n",
    "        return output\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        Returns the length of the dataset. Depends on the state of\n",
    "        the dataloader (train, val, test).\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.dataloader.dataset_type == 'train':\n",
    "            return self.dataloader.len_train\n",
    "        elif self.dataloader.dataset_type == 'val':\n",
    "            return self.dataloader.len_val\n",
    "        elif self.dataloader.dataset_type == 'test':\n",
    "            return self.dataloader.len_test\n",
    "        else:\n",
    "            raise ValueError(\"Dataset type must be either 'train', 'val' or 'test'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/utils.py#L160){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "## DatasetWrapper\n",
       "\n",
       ">      DatasetWrapper (dataloader:ddopai.dataloaders.base.BaseDataLoader,\n",
       ">                      obsprocessors:List=None)\n",
       "\n",
       "*This class is used to wrap a Pytorch Dataset around the ddopai dataloader\n",
       "to enable the usage of the Pytorch Dataloader during training. This way,\n",
       "agents that are trained using Pytorch without interacting with the environment\n",
       "can directly train on the data generated by the dataloader.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| dataloader | BaseDataLoader |  | Any dataloader that inherits from BaseDataLoader |\n",
       "| obsprocessors | List | None | processors (to mimic the environment processors) |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/utils.py#L160){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "## DatasetWrapper\n",
       "\n",
       ">      DatasetWrapper (dataloader:ddopai.dataloaders.base.BaseDataLoader,\n",
       ">                      obsprocessors:List=None)\n",
       "\n",
       "*This class is used to wrap a Pytorch Dataset around the ddopai dataloader\n",
       "to enable the usage of the Pytorch Dataloader during training. This way,\n",
       "agents that are trained using Pytorch without interacting with the environment\n",
       "can directly train on the data generated by the dataloader.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| dataloader | BaseDataLoader |  | Any dataloader that inherits from BaseDataLoader |\n",
       "| obsprocessors | List | None | processors (to mimic the environment processors) |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(DatasetWrapper, title_level=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/utils.py#L176){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DatasetWrapper.__getitem__\n",
       "\n",
       ">      DatasetWrapper.__getitem__ (idx)\n",
       "\n",
       "*Get the item at the provided idx.*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/utils.py#L176){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DatasetWrapper.__getitem__\n",
       "\n",
       ">      DatasetWrapper.__getitem__ (idx)\n",
       "\n",
       "*Get the item at the provided idx.*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(DatasetWrapper.__getitem__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/utils.py#L200){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DatasetWrapper.__len__\n",
       "\n",
       ">      DatasetWrapper.__len__ ()\n",
       "\n",
       "*Returns the length of the dataset. Depends on the state of\n",
       "the dataloader (train, val, test).*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/utils.py#L200){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### DatasetWrapper.__len__\n",
       "\n",
       ">      DatasetWrapper.__len__ ()\n",
       "\n",
       "*Returns the length of the dataset. Depends on the state of\n",
       "the dataloader (train, val, test).*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(DatasetWrapper.__len__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class DatasetWrapperMeta(DatasetWrapper):\n",
    "    \"\"\"\n",
    "    This class is used to wrap a Pytorch Dataset around the ddopai dataloader\n",
    "    to enable the usage of the Pytorch Dataloader during training. This way,\n",
    "    agents that are trained using Pytorch without interacting with the environment\n",
    "    can directly train on the data generated by the dataloader.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "            dataloader: BaseDataLoader, # Any dataloader that inherits from BaseDataLoader\n",
    "            draw_parameter_function: callable = None, # function to draw parameters from distribution\n",
    "            distribution: Literal[\"fixed\", \"uniform\"] | List = \"fixed\", # distribution for params during training, can be List for multiple parameters\n",
    "            parameter_names: List[str] = None, # names of the parameters\n",
    "            bounds_low: Union[int, float] | List = 0, # lower bound for params during training, can be List for multiple parameters\n",
    "            bounds_high: Union[int, float] | List = 1, # upper bound for params during training, can be List for multiple parameters\n",
    "            obsprocessors: List = None # processors (to mimic the environment processors)\n",
    "            ):\n",
    "\n",
    "        if isinstance(distribution, list) or isinstance(bounds_low, list) or isinstance(bounds_high, list):\n",
    "            raise NotImplementedError(\"Multiple parameters not yet implemented\")\n",
    "        if obsprocessors is None:\n",
    "            raise ValueError(\"Obsprocessors must be provided\")\n",
    "        \n",
    "        self.distribution = [distribution]\n",
    "        self.bounds_low = [bounds_low]\n",
    "        self.bounds_high = [bounds_high]\n",
    "        \n",
    "        self.dataloader = dataloader\n",
    "\n",
    "        self.draw_parameter = draw_parameter_function\n",
    "        self.obsprocessors = obsprocessors\n",
    "\n",
    "        self.parameter_names = parameter_names\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Get the item at the provided idx.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        features, demand = self.dataloader[idx] \n",
    "\n",
    "        features = np.expand_dims(features, axis=0) # add batch dimension as meta environments also return a batch dimension (needed for obsprocessor)\n",
    "\n",
    "        params = {}\n",
    "        for i in range(len(self.distribution)):\n",
    "            param = self.draw_parameter(self.distribution[0], self.bounds_low[0], self.bounds_high[0], samples=1) # idx always gets a single sample\n",
    "            params[self.parameter_names[i]] = param\n",
    "        \n",
    "        obs = params.copy()\n",
    "        obs[\"features\"] = features\n",
    "\n",
    "        for obsprocessor in self.obsprocessors:\n",
    "            obs = obsprocessor(obs)\n",
    "\n",
    "        obs = np.squeeze(obs, axis=0) # remove batch dimension after observation has been processed as the pytorch dataloader adds the batch dimension\n",
    "\n",
    "        return obs, demand, params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def merge_dictionaries(dict1, dict2):\n",
    "    \"\"\" Merge two dictionaries. If a key is found in both dictionaries, raise a KeyError. \"\"\"\n",
    "    for key in dict2:\n",
    "        if key in dict1:\n",
    "            raise KeyError(f\"Duplicate key found: {key}\")\n",
    "    \n",
    "    # If no duplicates are found, merge the dictionaries\n",
    "    merged_dict = {**dict1, **dict2}\n",
    "    return merged_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/utils.py#L280){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "## merge_dictionaries\n",
       "\n",
       ">      merge_dictionaries (dict1, dict2)\n",
       "\n",
       "*Merge two dictionaries. If a key is found in both dictionaries, raise a KeyError.*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/utils.py#L280){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "## merge_dictionaries\n",
       "\n",
       ">      merge_dictionaries (dict1, dict2)\n",
       "\n",
       "*Merge two dictionaries. If a key is found in both dictionaries, raise a KeyError.*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(merge_dictionaries, title_level=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def set_param(obj,\n",
    "                name: str, # name of the parameter (will become the attribute name)\n",
    "                input: Parameter | int | float | np.ndarray | List | None , # input value of the parameter\n",
    "                shape: tuple = (1,), # shape of the parameter\n",
    "                new: bool = False, # whether to create a new parameter or update an existing one\n",
    "                ): \n",
    "    \"\"\"\n",
    "        Set a parameter for the class. It converts scalar values to numpy arrays and ensures that\n",
    "        environment parameters are either of the Parameter class of Numpy arrays. If new is set to True, \n",
    "        the function will create a new parameter or update an existing one otherwise. If new is set to\n",
    "        False, the function will raise an error if the parameter does not exist.\n",
    "    \"\"\"\n",
    "\n",
    "    if input is None:\n",
    "        param = None\n",
    "\n",
    "    elif isinstance(input, Parameter):\n",
    "        if input.shape != shape:\n",
    "            raise ValueError(\"Parameter shape must be equal to the shape specified for this environment parameter\")\n",
    "        param = input\n",
    "    \n",
    "    elif isinstance(input, (int, float, np.integer, np.floating)):\n",
    "        param = np.full(shape, input)\n",
    "\n",
    "    elif isinstance(input, list):\n",
    "        input = np.array(input)\n",
    "        if input.shape == shape:\n",
    "            param = input\n",
    "        elif input.size == 1:  # Handle single-element arrays correctly\n",
    "            param = np.full(shape, input.item())\n",
    "        else:\n",
    "            raise ValueError(\"Error in setting parameter. Input array must match the specified shape or be a single-element array\")\n",
    "\n",
    "    elif isinstance(input, np.ndarray):\n",
    "        if input.shape == shape:\n",
    "            param = input\n",
    "        elif input.size == 1:  # Handle single-element arrays correctly\n",
    "            param = np.full(shape, input.item())\n",
    "        else:\n",
    "            raise ValueError(\"Error in setting parameter. Input array must match the specified shape or be a single-element array\")\n",
    "    else:\n",
    "        raise TypeError(f\"Input must be a Parameter, scalar, or numpy array, got {type(input).__name__} with value {input}\")\n",
    "\n",
    "    # set the parameter\n",
    "    if new:\n",
    "        if hasattr(obj, name):\n",
    "            logging.warning(f\"Parameter {name} already exists. Overwriting it.\")\n",
    "        setattr(obj, name, param)\n",
    "    else:\n",
    "        if not hasattr(obj, name):\n",
    "            raise AttributeError(f\"Parameter {name} does not exist\")\n",
    "        else:\n",
    "            setattr(obj, name, param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/utils.py#L291){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "## set_param\n",
       "\n",
       ">      set_param (obj, name:str,\n",
       ">                 input:Union[__main__.Parameter,int,float,numpy.ndarray,List,No\n",
       ">                 neType], shape:tuple=(1,), new:bool=False)\n",
       "\n",
       "*Set a parameter for the class. It converts scalar values to numpy arrays and ensures that\n",
       "environment parameters are either of the Parameter class of Numpy arrays. If new is set to True, \n",
       "the function will create a new parameter or update an existing one otherwise. If new is set to\n",
       "False, the function will raise an error if the parameter does not exist.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| obj |  |  |  |\n",
       "| name | str |  | name of the parameter (will become the attribute name) |\n",
       "| input | Union |  | input value of the parameter |\n",
       "| shape | tuple | (1,) | shape of the parameter |\n",
       "| new | bool | False | whether to create a new parameter or update an existing one |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/utils.py#L291){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "## set_param\n",
       "\n",
       ">      set_param (obj, name:str,\n",
       ">                 input:Union[__main__.Parameter,int,float,numpy.ndarray,List,No\n",
       ">                 neType], shape:tuple=(1,), new:bool=False)\n",
       "\n",
       "*Set a parameter for the class. It converts scalar values to numpy arrays and ensures that\n",
       "environment parameters are either of the Parameter class of Numpy arrays. If new is set to True, \n",
       "the function will create a new parameter or update an existing one otherwise. If new is set to\n",
       "False, the function will raise an error if the parameter does not exist.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| obj |  |  |  |\n",
       "| name | str |  | name of the parameter (will become the attribute name) |\n",
       "| input | Union |  | input value of the parameter |\n",
       "| shape | tuple | (1,) | shape of the parameter |\n",
       "| new | bool | False | whether to create a new parameter or update an existing one |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(set_param, title_level=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
