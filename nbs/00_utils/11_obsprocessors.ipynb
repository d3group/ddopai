{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obsprocessors\n",
    "\n",
    "> Processors for observations can be used to process the input for an agent before it is being passed to the agent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp obsprocessors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from typing import Union, Optional, List, Tuple, Dict\n",
    "\n",
    "import numpy as np\n",
    "from ddopnew.utils import Parameter, check_parameter_types\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class FlattenTimeDimNumpy():\n",
    "\n",
    "    \"\"\"\n",
    "    Preprocessor to flatten the time and feature dimension of the input.\n",
    "    Used, e.g., to convert time-series data for models that cannot process\n",
    "    a time dimension such as MLPs or Regression models.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "        allow_2d: Optional[bool] = False, #\n",
    "        batch_dim_included: Optional[bool] = True\n",
    "        ):\n",
    "        self.allow_2d = allow_2d\n",
    "        self.batch_dim_included = batch_dim_included\n",
    "\n",
    "    def check_input(self,\n",
    "            input: np.ndarray #\n",
    "            ):\n",
    "        \"\"\"\n",
    "        Check that the input is a PyTorch tensor with the correct shape.\n",
    "        \"\"\"\n",
    "        # Check if the input is a PyTorch tensor\n",
    "        if not isinstance(input, np.ndarray):\n",
    "            raise TypeError(f\"Expected input to be a numpy array, but got {type(input)} instead.\")\n",
    "\n",
    "        # Determine expected dimensions based on batch_dim_included\n",
    "        expected_ndim = 3 if self.batch_dim_included else 2\n",
    "        allow_ndim = 2 if self.batch_dim_included else 1\n",
    "\n",
    "        # Check if the input array has the correct dimensions\n",
    "        if input.ndim == expected_ndim:\n",
    "            # If the input is 3D, it is valid regardless of allow_2d\n",
    "            return\n",
    "        elif input.ndim == allow_ndim:\n",
    "            # If the input has fewer dimensions, check if the reduced dimension is allowed\n",
    "            if not self.allow_2d:\n",
    "                raise ValueError(\n",
    "                    f\"Expected input to have {expected_ndim} dimensions with shape \"\n",
    "                    f\"{'(batch_size, timesteps, features)' if self.batch_dim_included else '(timesteps, features)'}, \"\n",
    "                    f\"but got shape {input.shape} instead. \"\n",
    "                    f\"{allow_ndim}D inputs are not allowed when allow_2d is False.\"\n",
    "                )\n",
    "        else:\n",
    "            # If the input has an unexpected number of dimensions\n",
    "            expected_shape_msg = (\n",
    "                f\"Expected input to have {expected_ndim} dimensions with shape \"\n",
    "                f\"{'(batch_size, timesteps, features)' if self.batch_dim_included else '(timesteps, features)'}\"\n",
    "                if not self.allow_2d\n",
    "                else f\"Expected input to have {expected_ndim} dimensions with shape \"\n",
    "                     f\"{'(batch_size, timesteps, features)' if self.batch_dim_included else '(timesteps, features)'} \"\n",
    "                     f\"or {allow_ndim} dimensions with shape \"\n",
    "                     f\"{'(batch_size, features)' if self.batch_dim_included else '(features)'}\"\n",
    "            )\n",
    "            raise ValueError(f\"{expected_shape_msg}, but got shape {input.shape} instead.\")\n",
    "            \n",
    "    def __call__(self,\n",
    "                input: np.ndarray\n",
    "                ) -> np.ndarray:\n",
    "                \n",
    "        \"\"\"\n",
    "        Process the input array by keeping the batch dimension and flattening\n",
    "        the time and feature dimensions.\n",
    "        \"\"\"\n",
    "\n",
    "        # Validate the input tensor\n",
    "        self.check_input(input)\n",
    "\n",
    "        if self.batch_dim_included:\n",
    "            # If batch dimension is included\n",
    "            if input.ndim == 2:\n",
    "                output = input\n",
    "            else:\n",
    "                # Keep the batch dimension, flatten time and feature dimensions\n",
    "                batch_size, timesteps, features = input.shape\n",
    "                output = input.reshape(batch_size, -1)\n",
    "        else:\n",
    "            # If batch dimension is not included\n",
    "            if input.ndim == 1:\n",
    "                output = input\n",
    "            else:\n",
    "                # Flatten time and feature dimensions\n",
    "                timesteps, features = input.shape\n",
    "                output = input.reshape(-1)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/obsprocessors.py#L17){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "## FlattenTimeDimNumpy\n",
       "\n",
       ">      FlattenTimeDimNumpy (allow_2d:Optional[bool]=False,\n",
       ">                           batch_dim_included:Optional[bool]=True)\n",
       "\n",
       "*Preprocessor to flatten the time and feature dimension of the input.\n",
       "Used, e.g., to convert time-series data for models that cannot process\n",
       "a time dimension such as MLPs or Regression models.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| allow_2d | Optional | False |  |\n",
       "| batch_dim_included | Optional | True |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/obsprocessors.py#L17){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "## FlattenTimeDimNumpy\n",
       "\n",
       ">      FlattenTimeDimNumpy (allow_2d:Optional[bool]=False,\n",
       ">                           batch_dim_included:Optional[bool]=True)\n",
       "\n",
       "*Preprocessor to flatten the time and feature dimension of the input.\n",
       "Used, e.g., to convert time-series data for models that cannot process\n",
       "a time dimension such as MLPs or Regression models.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| allow_2d | Optional | False |  |\n",
       "| batch_dim_included | Optional | True |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(FlattenTimeDimNumpy, title_level=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/obsprocessors.py#L32){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### FlattenTimeDimNumpy.check_input\n",
       "\n",
       ">      FlattenTimeDimNumpy.check_input (input:numpy.ndarray)\n",
       "\n",
       "*Check that the input is a PyTorch tensor with the correct shape.*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| input | ndarray |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/obsprocessors.py#L32){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### FlattenTimeDimNumpy.check_input\n",
       "\n",
       ">      FlattenTimeDimNumpy.check_input (input:numpy.ndarray)\n",
       "\n",
       "*Check that the input is a PyTorch tensor with the correct shape.*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| input | ndarray |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(FlattenTimeDimNumpy.check_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/obsprocessors.py#L72){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### FlattenTimeDimNumpy.__call__\n",
       "\n",
       ">      FlattenTimeDimNumpy.__call__ (input:numpy.ndarray)\n",
       "\n",
       "*Process the input array by keeping the batch dimension and flattening\n",
       "the time and feature dimensions.*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/obsprocessors.py#L72){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### FlattenTimeDimNumpy.__call__\n",
       "\n",
       ">      FlattenTimeDimNumpy.__call__ (input:numpy.ndarray)\n",
       "\n",
       "*Process the input array by keeping the batch dimension and flattening\n",
       "the time and feature dimensions.*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(FlattenTimeDimNumpy.__call__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class ConvertDictSpace():\n",
    "\n",
    "    \"\"\"  \n",
    "\n",
    "    A utility class to process a dictionary of numpy arrays, with options to preserve or flatten the time dimension.\n",
    "\n",
    "    Note, this class is only used to preprocess output from the environment without batch dimension.\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "        keep_time_dim: Optional[bool] = False, #If time timension should be flattened as well.\n",
    "        hybrid_space_params: Optional[Dict] = None, # dict with keys \"time\" that is a list of observation keys that should keep the time dimension.\n",
    "        ):\n",
    "        self.keep_time_dim = keep_time_dim\n",
    "        self.hybrid_space_params = hybrid_space_params\n",
    "\n",
    "        if not keep_time_dim and hybrid_space_params is not None:\n",
    "            raise ValueError(\"If keep_time_dim is False, hybrid_space_params must be None.\")\n",
    "        if hybrid_space_params is not None and not isinstance(hybrid_space_params, dict):\n",
    "            raise ValueError(\"hybrid_space_params must be a dictionary if provided.\")\n",
    "\n",
    "\n",
    "    def __call__(self, \n",
    "                input: Dict, # Observation as dict of with numpy arrays\n",
    "                flatten: bool = True, # whether to flatten composite spaces (non-composite spaces will depend on self.keep_time_dim)\n",
    "                ) -> List[np.ndarray] | np.ndarray: \n",
    "\n",
    "        \"\"\"\n",
    "        Process the input dictionary by converting it to a numpy array.\n",
    "        \"\"\"\n",
    "\n",
    "        if self.hybrid_space_params is not None:\n",
    "            obs_2d = [] # time X features\n",
    "            obs_1d = [] # features\n",
    "        else:\n",
    "            obs = [] # features or time X features\n",
    "\n",
    "        for counter, (key, value) in enumerate(input.items()):\n",
    "            if not isinstance(value, np.ndarray):\n",
    "                raise TypeError(f\"Expected input to be a dictionary of numpy arrays, but got {type(value)} instead.\")\n",
    "\n",
    "            if self.hybrid_space_params is not None:\n",
    "                if key in self.hybrid_space_params[\"time_series_input\"]:\n",
    "                    obs_2d.append(value)\n",
    "                    if counter != 0:\n",
    "                        assert obs_2d[counter].shape[0] == obs_2d[counter-1].shape[0], \"All time dimensions must be the same.\"\n",
    "                else:\n",
    "                    obs_1d.append(value.flatten())\n",
    "            else:\n",
    "                if self.keep_time_dim:\n",
    "                    obs.append(value)\n",
    "                    if counter != 0:\n",
    "                        assert obs[counter].shape[0] == obs[counter-1].shape[0], \"All time dimensions must be the same.\"\n",
    "                else:\n",
    "                    obs.append(value.flatten())\n",
    "\n",
    "        if self.hybrid_space_params is not None:\n",
    "            obs_2d = np.concatenate(obs_2d, axis=0)\n",
    "            obs_1d = np.concatenate(obs_1d, axis=0)\n",
    "            if flatten:\n",
    "                # create a single one dimnensional vector\n",
    "                # print(obs_2d.shape, obs_1d.shape)\n",
    "                # print(np.concatenate([obs_2d.flatten(), obs_1d], axis=0).shape)\n",
    "                return np.concatenate([obs_2d.flatten(), obs_1d], axis=0)\n",
    "            else:\n",
    "                return [obs_2d, obs_1d]\n",
    "        else:\n",
    "            if obs[0].ndim == 1:\n",
    "                return np.concatenate(obs, axis=0)\n",
    "            else:\n",
    "                return np.concatenate(obs, axis=1)\n",
    "\n",
    "            return np.concatenate(obs, axis=0)\n",
    "\n",
    "    def determine_output_shape(self,\n",
    "        sample_input: Dict, #\n",
    "        flat: bool = False # if the flattend output shape should be returned\n",
    "        ) -> Tuple | List:\n",
    "\n",
    "        \"\"\"\n",
    "        Determine the output shape based on the input dictionary.\n",
    "        \"\"\"\n",
    "\n",
    "        if flat:\n",
    "            output = self.__call__(sample_input, flatten=True)\n",
    "        else:\n",
    "            output = self.__call__(sample_input, flatten=False)\n",
    "        if isinstance(output, list):\n",
    "            return [output[0].shape, output[1].shape]\n",
    "        else:\n",
    "            return output.shape\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
