{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAC agents\n",
    "\n",
    "> Soft Actor Critic based agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp agents.rl.sac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import logging\n",
    "\n",
    "# set logging level to INFO\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Union, Optional, List, Tuple, Callable, Any\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from ddopnew.envs.base import BaseEnvironment\n",
    "from ddopnew.agents.rl.mushroom_rl import MushroomBaseAgent\n",
    "from ddopnew.utils import MDPInfo, Parameter, merge_dictionaries\n",
    "from ddopnew.obsprocessors import FlattenTimeDimNumpy\n",
    "from ddopnew.RL_approximators import MLPStateAction, MLPActor, RNNStateAction, RNNActor\n",
    "from ddopnew.postprocessors import ClipAction\n",
    "\n",
    "from ddopnew.dataloaders.base import BaseDataLoader\n",
    "\n",
    "from mushroom_rl.algorithms.actor_critic.deep_actor_critic import SAC\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class SACBaseAgent(MushroomBaseAgent):\n",
    "\n",
    "    \"\"\"\n",
    "    Base agent for the Soft Actor-Critic (SAC) algorithm. \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                environment_info: MDPInfo,\n",
    "\n",
    "                # Not input regarding network architecture --> to be set in subclass\n",
    "\n",
    "                learning_rate_actor: float = 3e-4,\n",
    "                learning_rate_critic: float | None = None, # If none, then it is set to learning_rate_actor\n",
    "                initial_replay_size: int = 64,\n",
    "                max_replay_size: int = 50000,\n",
    "                batch_size: int = 64,\n",
    "                warmup_transitions: int = 100,\n",
    "                lr_alpha: float = 3e-4,\n",
    "                tau: float = 0.005,\n",
    "                log_std_min: float = -20.0,\n",
    "                log_std_max: float = 2.0,\n",
    "                use_log_alpha_loss=False,\n",
    "                target_entropy: float | None = None,\n",
    "                \n",
    "                drop_prob: float = 0.0,\n",
    "                batch_norm: bool = False,\n",
    "                init_method: str = \"xavier_uniform\", # \"xavier_uniform\", \"xavier_normal\", \"he_normal\", \"he_uniform\", \"normal\", \"uniform\"\n",
    "\n",
    "                optimizer: str = \"Adam\", # \"Adam\" or \"SGD\" or \"RMSprop\"  \n",
    "                loss: str = \"MSE\", # currently only MSE is supported     \n",
    "                obsprocessors: list | None = None,      # default: []\n",
    "                device: str = \"cpu\", # \"cuda\" or \"cpu\"\n",
    "                agent_name: str | None = \"SAC\",\n",
    "\n",
    "                network_actor_mu_params: dict = None,\n",
    "                network_actor_sigma_params: dict = None,\n",
    "                network_critic_params: dict = None,\n",
    "\n",
    "                ):\n",
    "\n",
    "        #### To set in the subclass:\n",
    "        # potential pre-processor\n",
    "        # input shapes for actor and critic, output shape for actor\n",
    "        # actor and critic network classes\n",
    "        # actor and critic network parameters\n",
    "\n",
    "        use_cuda = self.set_device(device)\n",
    "\n",
    "        self.warmup_training_steps = initial_replay_size\n",
    "\n",
    "        OptimizerClass=self.get_optimizer_class(optimizer)\n",
    "        learning_rate_critic = learning_rate_critic or learning_rate_actor\n",
    "        lossfunction = self.get_loss_function(loss)\n",
    "\n",
    "        actor_mu_params = dict(\n",
    "                                    drop_prob=drop_prob,\n",
    "                                    batch_norm=batch_norm,\n",
    "                                    init_method=init_method,\n",
    "\n",
    "                                    use_cuda=use_cuda,\n",
    "                                    dropout=self.dropout\n",
    "        )\n",
    "\n",
    "        actor_sigma_params = dict(\n",
    "                                    drop_prob=drop_prob,\n",
    "                                    batch_norm=batch_norm,\n",
    "                                    init_method=init_method,\n",
    "\n",
    "                                    use_cuda=use_cuda,\n",
    "                                    dropout=self.dropout\n",
    "        )\n",
    "\n",
    "        actor_mu_params = merge_dictionaries(actor_mu_params, network_actor_mu_params)\n",
    "        actor_sigma_params = merge_dictionaries(actor_sigma_params, network_actor_sigma_params)\n",
    "\n",
    "        actor_optimizer = {'class': OptimizerClass,\n",
    "            'params': {'lr': learning_rate_actor}} \n",
    "\n",
    "        critic_optimizer = {'class': OptimizerClass,\n",
    "            'params': {'lr': learning_rate_critic}}\n",
    "\n",
    "        critic_params = dict(\n",
    "                                optimizer = critic_optimizer,\n",
    "                                loss=lossfunction,\n",
    "                                drop_prob=drop_prob,\n",
    "                                batch_norm=batch_norm,\n",
    "                                init_method=init_method,\n",
    "\n",
    "                                use_cuda=use_cuda,\n",
    "                                dropout=self.dropout,)\n",
    "                            \n",
    "        critic_params = merge_dictionaries(critic_params, network_critic_params)\n",
    "\n",
    "        self.agent = SAC(\n",
    "            mdp_info=environment_info,\n",
    "            actor_mu_params=actor_mu_params,\n",
    "            actor_sigma_params=actor_sigma_params,\n",
    "            actor_optimizer=actor_optimizer,\n",
    "            critic_params=critic_params,\n",
    "            batch_size=batch_size,\n",
    "            initial_replay_size=initial_replay_size,\n",
    "            max_replay_size=max_replay_size,\n",
    "            warmup_transitions=warmup_transitions,\n",
    "            tau=tau,\n",
    "            lr_alpha=lr_alpha,\n",
    "            use_log_alpha_loss=use_log_alpha_loss,\n",
    "            log_std_min=log_std_min,\n",
    "            log_std_max=log_std_max,\n",
    "            target_entropy=target_entropy,\n",
    "            critic_fit_params=None\n",
    "        )\n",
    "\n",
    "        super().__init__(\n",
    "            environment_info=environment_info,\n",
    "            obsprocessors=obsprocessors,\n",
    "            device=device,\n",
    "            agent_name=agent_name\n",
    "        )\n",
    "\n",
    "        batch_dim = 1\n",
    "        logging.info(\"Actor network (mu network):\")\n",
    "        if logging.getLogger().isEnabledFor(logging.INFO):\n",
    "            input_size = self.add_batch_dimension_for_shape(actor_mu_params[\"input_shape\"], batch_dim=batch_dim)\n",
    "            input_size = self.convert_recursively_to_int(input_size)\n",
    "            if isinstance(input_size, list):\n",
    "                input_tensor = torch.randn(1, *actor_mu_params[\"input_shape\"][0]).to(self.device).view(batch_dim, -1)\n",
    "                if len(input_size) == 2:\n",
    "                    mlp_features = torch.randn(batch_dim, *actor_mu_params[\"input_shape\"][1]).to(self.device)\n",
    "                    input_tensor = torch.cat((input_tensor, mlp_features), dim=1)\n",
    "            else:\n",
    "                input_tensor = torch.randn(batch_dim, *actor_mu_params[\"input_shape\"]).to(self.device)\n",
    "            input_tuple = (input_tensor,)\n",
    "            print(summary(self.actor, input_data=input_tuple, device=self.device))\n",
    "            time.sleep(0.2)\n",
    "\n",
    "        logging.info(\"################################################################################\")\n",
    "        logging.info(\"Critic network:\")\n",
    "        if logging.getLogger().isEnabledFor(logging.INFO):\n",
    "            input_size = self.add_batch_dimension_for_shape(critic_params[\"input_shape\"])\n",
    "            input_size = self.convert_recursively_to_int(input_size)\n",
    "            action_sample = torch.randn(batch_dim, *critic_params[\"input_shape\"][1]).to(self.device)\n",
    "            if isinstance(input_size[0], tuple):\n",
    "                state_sample = torch.randn(batch_dim, *critic_params[\"input_shape\"][0]).to(self.device)\n",
    "            else:\n",
    "                state_sample = torch.randn(batch_dim, *critic_params[\"input_shape\"][0][0]).to(self.device).view(batch_dim, -1)\n",
    "                if len(input_size[0]) == 2:\n",
    "                    state_mlp_sample = torch.randn(batch_dim, *critic_params[\"input_shape\"][0][1]).to(self.device)\n",
    "                    state_sample = torch.cat((state_sample, state_mlp_sample), dim=1)\n",
    "            input_tuple = (state_sample, action_sample)\n",
    "            print(summary(self.critic, input_data=input_tuple, device=self.device))\n",
    "\n",
    "    def get_network_list(self, set_actor_critic_attributes: bool = True):\n",
    "        \"\"\" Get the list of networks in the agent for the save and load functions\n",
    "        Get the actor for the predict function in eval mode \"\"\"\n",
    "\n",
    "        networks = []\n",
    "        ensemble_critic = self.agent._critic_approximator._impl.model\n",
    "        for i, model in enumerate(ensemble_critic):\n",
    "            networks.append(model.network)\n",
    "        networks.append(self.agent.policy._mu_approximator._impl.model.network)\n",
    "        networks.append(self.agent.policy._sigma_approximator._impl.model.network)\n",
    "\n",
    "        actor = self.agent.policy._mu_approximator._impl.model.network\n",
    "        critic = ensemble_critic[0].network\n",
    "\n",
    "        if set_actor_critic_attributes:\n",
    "            return networks, actor, critic\n",
    "        else:\n",
    "            return networks\n",
    "\n",
    "    def predict_(self, observation: np.ndarray) -> np.ndarray: #\n",
    "        \"\"\" Do one forward pass of the model directly and return the prediction.\n",
    "        Apply tanh as implemented for the SAC actor in mushroom_rl\"\"\"\n",
    "\n",
    "        # make observation torch tensor\n",
    "        device = next(self.actor.parameters()).device\n",
    "        observation = torch.tensor(observation, dtype=torch.float32).to(device)\n",
    "\n",
    "        action = self.actor.forward(observation)\n",
    "        action = torch.tanh(action)\n",
    "        action = action * self.agent.policy._delta_a + self.agent.policy._central_a\n",
    "        action = action.cpu().detach().numpy()\n",
    "\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class SACAgent(SACBaseAgent):\n",
    "\n",
    "    \"\"\"\n",
    "    XXX\n",
    "    \"\"\"\n",
    "\n",
    "    dropout = True # always keep in True for mushroom_RL, dropout is not desired set drop_prob=0.0\n",
    "\n",
    "    def __init__(self, \n",
    "                environment_info: MDPInfo,\n",
    "\n",
    "                hidden_layers: List = None, # if None, then default is [64, 64]\n",
    "                activation: str = \"relu\", # \"relu\", \"sigmoid\", \"tanh\", \"leakyrelu\", \"elu\"\n",
    "\n",
    "                learning_rate_actor: float = 3e-4,\n",
    "                learning_rate_critic: float | None = None, # If none, then it is set to learning_rate_actor\n",
    "                initial_replay_size: int = 64,\n",
    "                max_replay_size: int = 50000,\n",
    "                batch_size: int = 64,\n",
    "                warmup_transitions: int = 100,\n",
    "                lr_alpha: float = 3e-4,\n",
    "                tau: float = 0.005,\n",
    "                log_std_min: float = -20.0,\n",
    "                log_std_max: float = 2.0,\n",
    "                use_log_alpha_loss=False,\n",
    "                target_entropy: float | None = None,\n",
    "\n",
    "                drop_prob: float = 0.0,\n",
    "                batch_norm: bool = False,\n",
    "                init_method: str = \"xavier_uniform\", # \"xavier_uniform\", \"xavier_normal\", \"he_normal\", \"he_uniform\", \"normal\", \"uniform\"\n",
    "\n",
    "                optimizer: str = \"Adam\", # \"Adam\" or \"SGD\" or \"RMSprop\"  \n",
    "                loss: str = \"MSE\", # currently only MSE is supported     \n",
    "                obsprocessors: list | None = None,      # default: []\n",
    "                device: str = \"cpu\", # \"cuda\" or \"cpu\"\n",
    "                agent_name: str | None = \"SAC\",\n",
    "                observation_space_shape = None, # optional when it cannot be inferred from environment_info (e.g. for dict spaces)\n",
    "                action_space_shape = None, # optional when it cannot be inferred from environment_info (e.g. for dict spaces)\n",
    "                ):\n",
    "\n",
    "        # The standard SAC agent needs a 2D input, so we need to flatten the time dimension\n",
    "        flatten_time_dim_processor = FlattenTimeDimNumpy(allow_2d=True, batch_dim_included=False)\n",
    "        obsprocessors = (obsprocessors or []) + [flatten_time_dim_processor]\n",
    "\n",
    "        # determine observation and action shapes\n",
    "        obs_space_shape = observation_space_shape or self.get_input_shape(environment_info.observation_space)\n",
    "        act_space_shape = action_space_shape or environment_info.action_space.shape\n",
    "\n",
    "        obs_space_shape = self.convert_recursively_to_int(obs_space_shape)\n",
    "        act_space_shape = self.convert_recursively_to_int(act_space_shape)\n",
    "\n",
    "        actor_input_shape = obs_space_shape # Note: This can be a list or tuple \n",
    "        actor_output_shape = act_space_shape # Note: This can be a list or tuple\n",
    "        critic_input_shape = [obs_space_shape, act_space_shape,] # Note: This can be a list or tuple\n",
    "\n",
    "        # Set networks (use classes, not instances)\n",
    "        actor_mu_network = MLPActor\n",
    "        actor_sigma_network = MLPActor\n",
    "        critic_network = MLPStateAction\n",
    "\n",
    "        # Set default for network architecture\n",
    "        hidden_layers = hidden_layers or [64, 64]\n",
    "\n",
    "        # Set network parameters\n",
    "        network_actor_mu_params = dict(\n",
    "                                    network = MLPActor,\n",
    "                                    input_shape=actor_input_shape,\n",
    "                                    output_shape=actor_output_shape,\n",
    "                                    hidden_layers=hidden_layers,\n",
    "                                    activation=activation,\n",
    "        )\n",
    "\n",
    "        network_actor_sigma_params = dict(\n",
    "                                    network = MLPActor,\n",
    "                                    input_shape=actor_input_shape,\n",
    "                                    output_shape=actor_output_shape,\n",
    "                                    hidden_layers=hidden_layers,\n",
    "                                    activation=activation,\n",
    "        )\n",
    "\n",
    "        network_critic_params = dict(\n",
    "                                    network = MLPStateAction,\n",
    "                                    input_shape=critic_input_shape,\n",
    "                                    output_shape=(1,),\n",
    "                                    hidden_layers=hidden_layers,\n",
    "                                    activation=activation,\n",
    "        )\n",
    "\n",
    "        super().__init__(\n",
    "            environment_info=environment_info,\n",
    "\n",
    "            learning_rate_actor=learning_rate_actor,\n",
    "            learning_rate_critic=learning_rate_critic,\n",
    "            initial_replay_size=initial_replay_size,\n",
    "            max_replay_size=max_replay_size,\n",
    "            batch_size=batch_size,\n",
    "            warmup_transitions=warmup_transitions,\n",
    "            lr_alpha=lr_alpha,\n",
    "            tau=tau,\n",
    "            log_std_min=log_std_min,\n",
    "            log_std_max=log_std_max,\n",
    "            use_log_alpha_loss=use_log_alpha_loss,\n",
    "            target_entropy=target_entropy,\n",
    "\n",
    "            drop_prob=drop_prob,\n",
    "            batch_norm=batch_norm,\n",
    "            init_method=init_method,\n",
    "\n",
    "            optimizer=optimizer,\n",
    "            loss=loss,\n",
    "            obsprocessors=obsprocessors,\n",
    "            device=device,\n",
    "            agent_name=agent_name,\n",
    "\n",
    "            network_actor_mu_params=network_actor_mu_params,\n",
    "            network_actor_sigma_params=network_actor_sigma_params,\n",
    "            network_critic_params=network_critic_params,\n",
    "        ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/magnus/miniforge3/envs/inventory_gym_2/lib/python3.11/site-packages/gymnasium/spaces/box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "INFO:root:Actor network (mu network):\n",
      "/Users/magnus/miniforge3/envs/inventory_gym_2/lib/python3.11/site-packages/torchinfo/torchinfo.py:462: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  action_fn=lambda data: sys.getsizeof(data.storage()),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "MLPActor                                 [1, 1]                    --\n",
      "├─Sequential: 1-1                        [1, 1]                    --\n",
      "│    └─Linear: 2-1                       [1, 64]                   192\n",
      "│    └─ReLU: 2-2                         [1, 64]                   --\n",
      "│    └─Dropout: 2-3                      [1, 64]                   --\n",
      "│    └─Linear: 2-4                       [1, 64]                   4,160\n",
      "│    └─ReLU: 2-5                         [1, 64]                   --\n",
      "│    └─Dropout: 2-6                      [1, 64]                   --\n",
      "│    └─Linear: 2-7                       [1, 1]                    65\n",
      "│    └─Identity: 2-8                     [1, 1]                    --\n",
      "==========================================================================================\n",
      "Total params: 4,417\n",
      "Trainable params: 4,417\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.00\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.02\n",
      "Estimated Total Size (MB): 0.02\n",
      "==========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:################################################################################\n",
      "INFO:root:Critic network:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "MLPStateAction                           --                        --\n",
      "├─Sequential: 1-1                        [1, 1]                    --\n",
      "│    └─Linear: 2-1                       [1, 64]                   256\n",
      "│    └─ReLU: 2-2                         [1, 64]                   --\n",
      "│    └─Dropout: 2-3                      [1, 64]                   --\n",
      "│    └─Linear: 2-4                       [1, 64]                   4,160\n",
      "│    └─ReLU: 2-5                         [1, 64]                   --\n",
      "│    └─Dropout: 2-6                      [1, 64]                   --\n",
      "│    └─Linear: 2-7                       [1, 1]                    65\n",
      "│    └─Identity: 2-8                     [1, 1]                    --\n",
      "==========================================================================================\n",
      "Total params: 4,481\n",
      "Trainable params: 4,481\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.00\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.02\n",
      "Estimated Total Size (MB): 0.02\n",
      "==========================================================================================\n",
      "-254.0208357996548 -159.8911204707865\n",
      "-254.0208357996548 -159.8911204707865\n"
     ]
    }
   ],
   "source": [
    "from ddopnew.envs.inventory.single_period import NewsvendorEnv\n",
    "from ddopnew.dataloaders.tabular import XYDataLoader\n",
    "from ddopnew.experiment_functions import run_experiment, test_agent\n",
    "\n",
    "val_index_start = 8000 #90_000\n",
    "test_index_start = 9000 #100_000\n",
    "\n",
    "X = np.random.standard_normal((10000, 2))\n",
    "Y = np.random.standard_normal((10000, 1))\n",
    "Y += 2*X[:,0].reshape(-1, 1) + 3*X[:,1].reshape(-1, 1)\n",
    "Y = X[:,0].reshape(-1, 1)\n",
    "# truncate Y at 0:\n",
    "Y = np.maximum(Y, 0)\n",
    "# normalize Y max to 1\n",
    "Y = Y/np.max(Y)\n",
    "\n",
    "# print(np.max(Y))\n",
    "# print(X.shape, Y.shape)\n",
    "\n",
    "clip_action = ClipAction(0., 1.)\n",
    "\n",
    "dataloader = XYDataLoader(X, Y, val_index_start, test_index_start, lag_window_params =  {'lag_window': 0, 'include_y': False, 'pre_calc': True})\n",
    "\n",
    "environment = NewsvendorEnv(\n",
    "    dataloader = dataloader,\n",
    "    underage_cost = 0.42857,\n",
    "    overage_cost = 1.0,\n",
    "    gamma = 0.999,\n",
    "    horizon_train = 365,\n",
    "    q_bound_high = 1.0,\n",
    "    q_bound_low = -0.1,\n",
    "    postprocessors = [clip_action],\n",
    ")\n",
    "\n",
    "agent = SACAgent(environment.mdp_info,\n",
    "                obsprocessors = None,      # default: []\n",
    "                device=\"cpu\", # \"cuda\" or \"cpu\"\n",
    ")\n",
    "\n",
    "environment.test()\n",
    "agent.eval()\n",
    "\n",
    "R, J = test_agent(agent, environment)\n",
    "\n",
    "print(R, J)\n",
    "\n",
    "environment.train()\n",
    "agent.train()\n",
    "environment.print=False\n",
    "\n",
    "# run_experiment(agent, environment, n_epochs=50, n_steps=1000, run_id = \"test\", save_best=True, print_freq=1) # fit agent via run_experiment function\n",
    "\n",
    "environment.test()\n",
    "agent.eval()\n",
    "\n",
    "R, J = test_agent(agent, environment)\n",
    "\n",
    "print(R, J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class SACRNNAgent(SACBaseAgent):\n",
    "\n",
    "    \"\"\"\n",
    "    XXX\n",
    "    \"\"\"\n",
    "\n",
    "    dropout = True # always keep in True for mushroom_RL, dropout is not desired set drop_prob=0.0\n",
    "\n",
    "    def __init__(self, \n",
    "                environment_info: MDPInfo,\n",
    "\n",
    "                hidden_layers_RNN: int = 1, # Initial RNN layers\n",
    "                num_hidden_units_RNN: int = 64, # Initial number of hidden units in RNN layers\n",
    "                RNN_cell: str = \"GRU\", # \"LSTM\", \"GRU\", \"RNN\"\n",
    "                hidden_layers_MLP: List = None, # MLP layers behind RNN: if None, then default is [64, 64]\n",
    "                hidden_layers_input_MLP: List = None, # MLP layers for  non-time features. Default is None\n",
    "                activation: str = \"relu\", # \"relu\", \"sigmoid\", \"tanh\", \"leakyrelu\", \"elu\"\n",
    "\n",
    "                learning_rate_actor: float = 3e-4,\n",
    "                learning_rate_critic: float | None = None, # If none, then it is set to learning_rate_actor\n",
    "                initial_replay_size: int = 64,\n",
    "                max_replay_size: int = 50000,\n",
    "                batch_size: int = 64,\n",
    "                warmup_transitions: int = 100,\n",
    "                lr_alpha: float = 3e-4,\n",
    "                tau: float = 0.005,\n",
    "                log_std_min: float = -20.0,\n",
    "                log_std_max: float = 2.0,\n",
    "                use_log_alpha_loss=False,\n",
    "                target_entropy: float | None = None,\n",
    "\n",
    "                drop_prob: float = 0.0,\n",
    "                batch_norm: bool = False,\n",
    "                init_method: str = \"xavier_uniform\", # \"xavier_uniform\", \"xavier_normal\", \"he_normal\", \"he_uniform\", \"normal\", \"uniform\"\n",
    "\n",
    "                optimizer: str = \"Adam\", # \"Adam\" or \"SGD\" or \"RMSprop\"  \n",
    "                loss: str = \"MSE\", # currently only MSE is supported     \n",
    "                obsprocessors: list | None = None,      # default: []\n",
    "                device: str = \"cpu\", # \"cuda\" or \"cpu\"\n",
    "                agent_name: str | None = \"SAC\",\n",
    "                observation_space_shape = None, # optional when it cannot be inferred from environment_info (e.g. for dict spaces)\n",
    "                action_space_shape = None, # optional when it cannot be inferred from environment_info (e.g. for dict spaces)\n",
    "                ):\n",
    "\n",
    "        # # The standard SAC agent needs a 2D input, so we need to flatten the time dimension\n",
    "        # flatten_time_dim_processor = FlattenTimeDimNumpy(allow_2d=True, batch_dim_included=False)\n",
    "        # obsprocessors = (obsprocessors or []) + [flatten_time_dim_processor]\n",
    "\n",
    "        # determine observation and action shapes\n",
    "        obs_space_shape = observation_space_shape or self.get_input_shape(environment_info.observation_space, flatten_time_dim=False)\n",
    "        act_space_shape = action_space_shape or environment_info.action_space.shape\n",
    "    \n",
    "        obs_space_shape = self.convert_recursively_to_int(obs_space_shape)\n",
    "        act_space_shape = self.convert_recursively_to_int(act_space_shape)\n",
    "\n",
    "        if isinstance(obs_space_shape, list) and len(obs_space_shape[0]) == 1 or len(obs_space_shape) == 1:\n",
    "            raise ValueError(\"The RNN-based SAC needs at least one 2D input (time x features)\")\n",
    "\n",
    "\n",
    "        # determine shapes\n",
    "        actor_input_shape = obs_space_shape # Note: This can be a list or tuple\n",
    "        actor_output_shape = act_space_shape # Note: This can be a list or tuple\n",
    "        \n",
    "        critic_input_shape = [obs_space_shape, act_space_shape]\n",
    "\n",
    "        # Determine raw input shape for mushroom to work:\n",
    "        if isinstance(actor_input_shape, list):\n",
    "            actor_input_shape_mushroom = actor_input_shape[0][0]*actor_input_shape[0][1] + actor_input_shape[1][0], # if composite space, then flattend vector\n",
    "            critic_input_shape_mushroom = [actor_input_shape_mushroom, act_space_shape]\n",
    "        else:\n",
    "            actor_input_shape_mushroom = actor_input_shape # if only time dimension, then keep 2d input\n",
    "            critic_input_shape_mushroom = critic_input_shape\n",
    "\n",
    "        # Set networks (use classes, not instances)\n",
    "        actor_mu_network = RNNActor\n",
    "        actor_sigma_network = RNNActor\n",
    "        critic_network = RNNStateAction\n",
    "\n",
    "        # Set default for network architecture\n",
    "        hidden_layers_MLP = hidden_layers_MLP or [64, 64]\n",
    "\n",
    "        # Set network parameters\n",
    "        network_actor_mu_params = dict(\n",
    "                                    network = RNNActor,\n",
    "                                    input_shape=actor_input_shape_mushroom,\n",
    "                                    input_shape_=actor_input_shape,\n",
    "                                    output_shape=actor_output_shape,\n",
    "                                    hidden_layers_RNN=hidden_layers_RNN,\n",
    "                                    num_hidden_units_RNN=num_hidden_units_RNN,\n",
    "                                    hidden_layers_MLP=hidden_layers_MLP,\n",
    "                                    hidden_layers_input_MLP=hidden_layers_input_MLP,\n",
    "                                    RNN_cell=RNN_cell,\n",
    "                                    activation=activation,\n",
    "        )\n",
    "\n",
    "        network_actor_sigma_params = dict(\n",
    "                                    network = RNNActor,\n",
    "                                    input_shape=actor_input_shape_mushroom,\n",
    "                                    input_shape_=actor_input_shape,\n",
    "                                    output_shape=actor_output_shape,\n",
    "                                    hidden_layers_RNN=hidden_layers_RNN,\n",
    "                                    num_hidden_units_RNN=num_hidden_units_RNN,\n",
    "                                    hidden_layers_MLP=hidden_layers_MLP,\n",
    "                                    hidden_layers_input_MLP=hidden_layers_input_MLP,\n",
    "                                    RNN_cell=RNN_cell,\n",
    "                                    activation=activation,\n",
    "        )\n",
    "\n",
    "        network_critic_params = dict(\n",
    "                                    network = RNNStateAction,\n",
    "                                    input_shape=critic_input_shape_mushroom,\n",
    "                                    input_shape_=critic_input_shape,\n",
    "                                    output_shape=(1,),\n",
    "                                    hidden_layers_RNN=hidden_layers_RNN,\n",
    "                                    num_hidden_units_RNN=num_hidden_units_RNN,\n",
    "                                    hidden_layers_MLP=hidden_layers_MLP,\n",
    "                                    hidden_layers_input_MLP=hidden_layers_input_MLP,\n",
    "                                    RNN_cell=RNN_cell,\n",
    "                                    activation=activation,\n",
    "        )\n",
    "\n",
    "        super().__init__(\n",
    "            environment_info=environment_info,\n",
    "\n",
    "            learning_rate_actor=learning_rate_actor,\n",
    "            learning_rate_critic=learning_rate_critic,\n",
    "            initial_replay_size=initial_replay_size,\n",
    "            max_replay_size=max_replay_size,\n",
    "            batch_size=batch_size,\n",
    "            warmup_transitions=warmup_transitions,\n",
    "            lr_alpha=lr_alpha,\n",
    "            tau=tau,\n",
    "            log_std_min=log_std_min,\n",
    "            log_std_max=log_std_max,\n",
    "            use_log_alpha_loss=use_log_alpha_loss,\n",
    "            target_entropy=target_entropy,\n",
    "\n",
    "            drop_prob=drop_prob,\n",
    "            batch_norm=batch_norm,\n",
    "            init_method=init_method,\n",
    "\n",
    "            optimizer=optimizer,\n",
    "            loss=loss,\n",
    "            obsprocessors=obsprocessors,\n",
    "            device=device,\n",
    "            agent_name=agent_name,\n",
    "\n",
    "            network_actor_mu_params=network_actor_mu_params,\n",
    "            network_actor_sigma_params=network_actor_sigma_params,\n",
    "            network_critic_params=network_critic_params,\n",
    "        ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/magnus/miniforge3/envs/inventory_gym_2/lib/python3.11/site-packages/gymnasium/spaces/box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "INFO:root:Actor network (mu network):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "RNNActor                                 [1, 1]                    --\n",
      "├─RNNMLPHybrid: 1-1                      [1, 1]                    --\n",
      "│    └─Sequential: 2-1                   [1, 6, 64]                --\n",
      "│    │    └─SpecificRNNWrapper: 3-1      [1, 6, 64]                13,248\n",
      "│    │    └─ReLU: 3-2                    [1, 6, 64]                --\n",
      "│    └─Sequential: 2-2                   [1, 1]                    --\n",
      "│    │    └─Linear: 3-3                  [1, 64]                   4,160\n",
      "│    │    └─ReLU: 3-4                    [1, 64]                   --\n",
      "│    │    └─Dropout: 3-5                 [1, 64]                   --\n",
      "│    │    └─Linear: 3-6                  [1, 64]                   4,160\n",
      "│    │    └─ReLU: 3-7                    [1, 64]                   --\n",
      "│    │    └─Dropout: 3-8                 [1, 64]                   --\n",
      "│    │    └─Linear: 3-9                  [1, 1]                    65\n",
      "==========================================================================================\n",
      "Total params: 21,633\n",
      "Trainable params: 21,633\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.09\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.09\n",
      "Estimated Total Size (MB): 0.09\n",
      "==========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:################################################################################\n",
      "INFO:root:Critic network:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "RNNStateAction                           --                        --\n",
      "├─RNNMLPHybrid: 1-1                      [1, 1]                    --\n",
      "│    └─Sequential: 2-1                   [1, 6, 64]                --\n",
      "│    │    └─SpecificRNNWrapper: 3-1      [1, 6, 64]                13,248\n",
      "│    │    └─ReLU: 3-2                    [1, 6, 64]                --\n",
      "│    └─Sequential: 2-2                   [1, 1]                    --\n",
      "│    │    └─Linear: 3-3                  [1, 64]                   4,224\n",
      "│    │    └─ReLU: 3-4                    [1, 64]                   --\n",
      "│    │    └─Dropout: 3-5                 [1, 64]                   --\n",
      "│    │    └─Linear: 3-6                  [1, 64]                   4,160\n",
      "│    │    └─ReLU: 3-7                    [1, 64]                   --\n",
      "│    │    └─Dropout: 3-8                 [1, 64]                   --\n",
      "│    │    └─Linear: 3-9                  [1, 1]                    65\n",
      "==========================================================================================\n",
      "Total params: 21,697\n",
      "Trainable params: 21,697\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.09\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.09\n",
      "Estimated Total Size (MB): 0.09\n",
      "==========================================================================================\n",
      "-420.9567259533292 -266.3596900995244\n",
      "-420.9567259533292 -266.3596900995244\n"
     ]
    }
   ],
   "source": [
    "from ddopnew.envs.inventory.single_period import NewsvendorEnv\n",
    "from ddopnew.dataloaders.tabular import XYDataLoader\n",
    "from ddopnew.experiment_functions import run_experiment, test_agent\n",
    "\n",
    "val_index_start = 8000 #90_000\n",
    "test_index_start = 9000 #100_000\n",
    "\n",
    "X = np.random.standard_normal((10000, 2))\n",
    "Y = np.random.standard_normal((10000, 1))\n",
    "Y += 2*X[:,0].reshape(-1, 1) + 3*X[:,1].reshape(-1, 1)\n",
    "Y = X[:,0].reshape(-1, 1)\n",
    "# truncate Y at 0:\n",
    "Y = np.maximum(Y, 0)\n",
    "# normalize Y max to 1\n",
    "Y = Y/np.max(Y)\n",
    "\n",
    "clip_action = ClipAction(0., 1.)\n",
    "\n",
    "dataloader = XYDataLoader(X, Y, val_index_start, test_index_start, lag_window_params =  {'lag_window': 5, 'include_y': True, 'pre_calc': True})\n",
    "\n",
    "environment = NewsvendorEnv(\n",
    "    dataloader = dataloader,\n",
    "    underage_cost = 0.42857,\n",
    "    overage_cost = 1.0,\n",
    "    gamma = 0.999,\n",
    "    horizon_train = 365,\n",
    "    q_bound_high = 1.0,\n",
    "    q_bound_low = -0.1,\n",
    "    postprocessors = [clip_action],\n",
    ")\n",
    "\n",
    "agent = SACRNNAgent(environment.mdp_info,\n",
    "                obsprocessors = None,      # default: []\n",
    "                device=\"cpu\", # \"cuda\" or \"cpu\"\n",
    ")\n",
    "\n",
    "environment.test()\n",
    "agent.eval()\n",
    "\n",
    "R, J = test_agent(agent, environment)\n",
    "\n",
    "print(R, J)\n",
    "\n",
    "environment.train()\n",
    "agent.train()\n",
    "environment.print=False\n",
    "\n",
    "# run_experiment(agent, environment, n_epochs=50, n_steps=1000, run_id = \"test\", save_best=True, print_freq=1) # fit agent via run_experiment function\n",
    "\n",
    "environment.test()\n",
    "agent.eval()\n",
    "\n",
    "R, J = test_agent(agent, environment)\n",
    "\n",
    "print(R, J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
