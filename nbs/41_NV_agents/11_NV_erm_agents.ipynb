{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERM agents\n",
    "\n",
    "> Newsvendor agents based on Empirical Risk Minimization (ERM) principles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp agents.newsvendor.erm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import logging\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Union, Optional, List, Tuple\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "\n",
    "from ddopnew.envs.base import BaseEnvironment\n",
    "from ddopnew.agents.base import BaseAgent\n",
    "from ddopnew.utils import MDPInfo, Parameter, DatasetWrapper\n",
    "from ddopnew.torch_utils.loss_functions import TorchQuantileLoss\n",
    "from ddopnew.torch_utils.preprocessors import FlattenTimeDim\n",
    "\n",
    "from ddopnew.dataloaders.base import BaseDataLoader\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class SGDBaseAgent(BaseAgent):\n",
    "\n",
    "    \"\"\"\n",
    "    Base class for Agents that are trained using Stochastic Gradient Descent (SGD) on PyTorch models.\n",
    "    \"\"\"\n",
    "\n",
    "    train_mode = \"epochs_fit\"\n",
    "    \n",
    "    def __init__(self, \n",
    "            environment_info: MDPInfo,\n",
    "            dataloader: BaseDataLoader,\n",
    "            input_shape: int,\n",
    "            output_shape: int,\n",
    "            optimizer_params: Optional[dict] = None,  # default: {\"optimizer\": \"Adam\", \"lr\": 0.01, \"weight_decay\": 0.0}\n",
    "            learning_rate_scheduler = None,  # TODO: add base class for learning rate scheduler for typing\n",
    "            dataloader_params: Optional[dict] = None, # default: {\"batch_size\": 32, \"shuffle\": True}\n",
    "            preprocessors: Optional[List] = None,     # default: []\n",
    "            postprocessors: Optional[List] = None,     # default: []\n",
    "            torch_preprocessors: Optional[List] = None,     # default: []\n",
    "            device: str = \"cpu\", # \"cuda\" or \"cpu\"\n",
    "            agent_name: str | None = None\n",
    "            ):\n",
    "\n",
    "        # Initialize default values for mutable arguments\n",
    "        optimizer_params = optimizer_params or {\"optimizer\": \"Adam\", \"lr\": 0.01, \"weight_decay\": 0.0}\n",
    "        dataloader_params = dataloader_params or {\"batch_size\": 32, \"shuffle\": True}\n",
    "        self.torch_preprocessors = torch_preprocessors or []\n",
    "\n",
    "        self.device = device\n",
    "        \n",
    "        self.set_dataloader(dataloader, dataloader_params)\n",
    "        self.set_model(input_shape, output_shape)\n",
    "        self.set_loss_function()\n",
    "        self.set_optimizer(optimizer_params)\n",
    "        self.set_learning_rate_scheduler(learning_rate_scheduler)\n",
    "\n",
    "        super().__init__(environment_info, preprocessors, postprocessors, agent_name)\n",
    "\n",
    "    def set_dataloader(self,\n",
    "                        dataloader: BaseDataLoader,\n",
    "                        dataloader_params: dict, # dict with keys: batch_size, shuffle\n",
    "                        ) -> None: \n",
    "\n",
    "        \"\"\"\n",
    "        Set the dataloader for the agent by wrapping it into a Torch Dataset\n",
    "        \n",
    "        \"\"\"\n",
    "        dataset = DatasetWrapper(dataloader)\n",
    "        self.dataloader = torch.utils.data.DataLoader(dataset, **dataloader_params)\n",
    "\n",
    "    @abstractmethod\n",
    "    def set_loss_function(self):\n",
    "        \"\"\" Set loss function for the model \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def set_model(self, input_shape: Tuple, output_shape: Tuple):\n",
    "        \"\"\" Set the model for the agent \"\"\"\n",
    "        pass\n",
    "\n",
    "    def set_optimizer(self, optimizer_params: dict): # dict with keys: optimizer, lr, weight_decay\n",
    "        \n",
    "        \"\"\" Set the optimizer for the model \"\"\"\n",
    "        optimizer = optimizer_params[\"optimizer\"]\n",
    "        optimizer_params_copy = optimizer_params.copy()\n",
    "        del optimizer_params_copy[\"optimizer\"]\n",
    "\n",
    "        if optimizer == \"Adam\":\n",
    "            self.optimizer = torch.optim.Adam(self.model.parameters(), **optimizer_params_copy)\n",
    "        elif optimizer == \"SGD\":\n",
    "            self.optimizer = torch.optim.SGD(self.model.parameters(), **optimizer_params_copy)\n",
    "        elif optimizer == \"RMSprop\":\n",
    "            self.optimizer = torch.optim.RMSprop(self.model.parameters(), **optimizer_params_copy)\n",
    "        else:\n",
    "            raise ValueError(f\"Optimizer {optimizer} not supported\")\n",
    "        \n",
    "    def set_learning_rate_scheduler(self, learning_rate_scheduler: None = None): #\n",
    "        \"\"\" Set learning rate scheudler (can be None) \"\"\"\n",
    "        if learning_rate_scheduler is not None:\n",
    "            raise NotImplementedError(\"Learning rate scheduler not implemented yet\")\n",
    "        else:\n",
    "            self.learning_rate_scheduler = None\n",
    "\n",
    "    def fit_epoch(self):\n",
    "\n",
    "        \"\"\" Fit the model for one epoch using the dataloader \"\"\"\n",
    "\n",
    "        device = next(self.model.parameters()).device\n",
    "        self.model.train()\n",
    "        total_loss=0\n",
    "\n",
    "        for i, output in enumerate(self.dataloader):\n",
    "            \n",
    "            X, y = output\n",
    "\n",
    "            # convert X and y to float32\n",
    "            X = X.type(torch.float32)\n",
    "            y = y.type(torch.float32)\n",
    "\n",
    "            for torch_preprocessor in self.torch_preprocessors:\n",
    "                X = torch_preprocessor(X)\n",
    "            \n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            y_pred = self.model(X)\n",
    "\n",
    "            if self.loss_function_params==None:\n",
    "                loss = self.loss_function(y_pred, y)\n",
    "            else:\n",
    "                loss = self.loss_function(y_pred, y, **self.loss_function_params) # TODO: add reduction param when defining loss function\n",
    "\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        self.model.eval()\n",
    "        \n",
    "        return total_loss\n",
    "\n",
    "    def draw_action_(self, observation: np.ndarray) -> np.ndarray: #\n",
    "        \n",
    "        \"\"\" \n",
    "        Draw an action based on the fitted model (see predict method)\n",
    "        \"\"\"\n",
    "        \n",
    "        action = self.predict(observation)\n",
    "        \n",
    "        return action\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray: #\n",
    "        \"\"\" Do one forward pass of the model and return the prediction \"\"\"\n",
    "\n",
    "        # TODO handle if X is larger than some size, then split into batches\n",
    "\n",
    "        device = next(self.model.parameters()).device\n",
    "        self.model.eval()\n",
    "\n",
    "        X = torch.tensor(X, dtype=torch.float32)\n",
    "        for torch_preprocessor in self.torch_preprocessors:\n",
    "            X = torch_preprocessor(X)\n",
    "        X = X.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            y_pred = self.model(X)\n",
    "\n",
    "\n",
    "        y_pred = y_pred.cpu().numpy()\n",
    "\n",
    "        return y_pred\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"set the internal state of the agent and its model to train\"\"\"\n",
    "        self.mode = \"train\"\n",
    "        self.model.train()\n",
    "\n",
    "    def eval(self):\n",
    "        \"\"\"set the internal state of the agent and its model to eval\"\"\"\n",
    "        self.mode = \"eval\"\n",
    "        self.model.eval()\n",
    "\n",
    "    def to(self, device: str): #\n",
    "        \"\"\"Move the model to the specified device\"\"\"\n",
    "        self.model.to(device)\n",
    "\n",
    "    def save(self,\n",
    "                path: str, # The directory where the file will be saved.\n",
    "                overwrite: bool=True): # Allow overwriting; if False, a FileExistsError will be raised if the file exists.\n",
    "        \n",
    "        \"\"\"\n",
    "        Save the PyTorch model to a file in the specified directory.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        if not hasattr(self, 'model') or self.model is None:\n",
    "            raise AttributeError(\"Model is not defined in the class.\")\n",
    "\n",
    "        # Create the directory path if it does not exist\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "        # Construct the file path using os.path.join for better cross-platform compatibility\n",
    "        full_path = os.path.join(path, \"model.pth\")\n",
    "\n",
    "        if os.path.exists(full_path):\n",
    "            if not overwrite:\n",
    "                raise FileExistsError(f\"The file {full_path} already exists and will not be overwritten.\")\n",
    "            else:\n",
    "                logging.info(f\"Overwriting file {full_path}\") # Only log with info as during training we will continuously overwrite the model\n",
    "        \n",
    "        # Save the model's state_dict using torch.save\n",
    "        torch.save(self.model.state_dict(), full_path)\n",
    "        logging.info(f\"Model saved successfully to {full_path}\")\n",
    "\n",
    "    def load(self, path: str): # Only the path to the folder is needed, not the file itself\n",
    " \n",
    "        \"\"\"\n",
    "        Load the PyTorch model from a file.\n",
    "        \"\"\"\n",
    "        \n",
    "        if not hasattr(self, 'model') or self.model is None:\n",
    "            raise AttributeError(\"Model is not defined in the class.\")\n",
    "\n",
    "        # Construct the file path\n",
    "        full_path = os.path.join(path, \"model.pth\")\n",
    "\n",
    "        if not os.path.exists(full_path):\n",
    "            raise FileNotFoundError(f\"The file {full_path} does not exist.\")\n",
    "\n",
    "        try:\n",
    "            # Load the model's state_dict using torch.load\n",
    "            self.model.load_state_dict(torch.load(full_path))\n",
    "            logging.info(f\"Model loaded successfully from {full_path}\")\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"An error occurred while loading the model: {e}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/agents/newsvendor/erm.py#L26){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "## SGDBaseAgent\n",
       "\n",
       ">      SGDBaseAgent (environment_info:ddopnew.utils.MDPInfo,\n",
       ">                    dataloader:ddopnew.dataloaders.base.BaseDataLoader,\n",
       ">                    input_shape:int, output_shape:int,\n",
       ">                    optimizer_params:Optional[dict]=None,\n",
       ">                    learning_rate_scheduler=None,\n",
       ">                    dataloader_params:Optional[dict]=None,\n",
       ">                    preprocessors:Optional[List]=None,\n",
       ">                    postprocessors:Optional[List]=None,\n",
       ">                    torch_preprocessors:Optional[List]=None, device:str='cpu',\n",
       ">                    agent_name:str|None=None)\n",
       "\n",
       "*Base class for Agents that are trained using Stochastic Gradient Descent (SGD) on PyTorch models.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| environment_info | MDPInfo |  |  |\n",
       "| dataloader | BaseDataLoader |  |  |\n",
       "| input_shape | int |  |  |\n",
       "| output_shape | int |  |  |\n",
       "| optimizer_params | Optional | None | default: {\"optimizer\": \"Adam\", \"lr\": 0.01, \"weight_decay\": 0.0} |\n",
       "| learning_rate_scheduler | NoneType | None | TODO: add base class for learning rate scheduler for typing |\n",
       "| dataloader_params | Optional | None | default: {\"batch_size\": 32, \"shuffle\": True} |\n",
       "| preprocessors | Optional | None | default: [] |\n",
       "| postprocessors | Optional | None | default: [] |\n",
       "| torch_preprocessors | Optional | None | default: [] |\n",
       "| device | str | cpu | \"cuda\" or \"cpu\" |\n",
       "| agent_name | str \\| None | None |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/agents/newsvendor/erm.py#L26){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "## SGDBaseAgent\n",
       "\n",
       ">      SGDBaseAgent (environment_info:ddopnew.utils.MDPInfo,\n",
       ">                    dataloader:ddopnew.dataloaders.base.BaseDataLoader,\n",
       ">                    input_shape:int, output_shape:int,\n",
       ">                    optimizer_params:Optional[dict]=None,\n",
       ">                    learning_rate_scheduler=None,\n",
       ">                    dataloader_params:Optional[dict]=None,\n",
       ">                    preprocessors:Optional[List]=None,\n",
       ">                    postprocessors:Optional[List]=None,\n",
       ">                    torch_preprocessors:Optional[List]=None, device:str='cpu',\n",
       ">                    agent_name:str|None=None)\n",
       "\n",
       "*Base class for Agents that are trained using Stochastic Gradient Descent (SGD) on PyTorch models.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| environment_info | MDPInfo |  |  |\n",
       "| dataloader | BaseDataLoader |  |  |\n",
       "| input_shape | int |  |  |\n",
       "| output_shape | int |  |  |\n",
       "| optimizer_params | Optional | None | default: {\"optimizer\": \"Adam\", \"lr\": 0.01, \"weight_decay\": 0.0} |\n",
       "| learning_rate_scheduler | NoneType | None | TODO: add base class for learning rate scheduler for typing |\n",
       "| dataloader_params | Optional | None | default: {\"batch_size\": 32, \"shuffle\": True} |\n",
       "| preprocessors | Optional | None | default: [] |\n",
       "| postprocessors | Optional | None | default: [] |\n",
       "| torch_preprocessors | Optional | None | default: [] |\n",
       "| device | str | cpu | \"cuda\" or \"cpu\" |\n",
       "| agent_name | str \\| None | None |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(SGDBaseAgent, title_level=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important notes:\n",
    "\n",
    "SGD-based agents are all agents that are trained via SGD such as Linear Models or Neural Networks. Some specific requirements are necessary to make them interface properly with the environment.\n",
    "\n",
    "**Torch perprocessors**:\n",
    "\n",
    "* In addition to the general Numpy-based pre-processor, we also provide pre-processors that work on tensor level within the ```fit_epoch``` method and the ```predict``` method. They can be used in addition to the numpy-based pre-processors or instead of them. It's important to ensure that the shape of observations (after pre-processing) is the same for those from the environemnt and those from the dataloader during training.\n",
    "\n",
    "**Dataloader**:\n",
    "\n",
    "* As for normal supervised learning via Torch, we make use of the Torch dataloader to load the data. Instead of defining a custom dataset class, we provide a Wrapper that can be used around our dataloader to make its output and interface the same as a Torch dataset. The dataloader is then initialized when the agent is created such that the agent has access to the same dataloader as the environment.\n",
    " \n",
    "**Training process**:\n",
    "\n",
    "* The outper loop of the training process (epochs) is handled outside the agent by the ```run_experiment```functions (or can also be customized). The agent needs to have a ```fit_epoch``` method that tells the agent what to do within an epoch. \n",
    "This includes:\n",
    "    * Getting the data from the dataloader\n",
    "    * Pre-processing the data\n",
    "    * Forward pass\n",
    "    * Loss calculation\n",
    "    * Backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/agents/newsvendor/erm.py#L64){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SGDBaseAgent.set_dataloader\n",
       "\n",
       ">      SGDBaseAgent.set_dataloader\n",
       ">                                   (dataloader:ddopnew.dataloaders.base.BaseDat\n",
       ">                                   aLoader, dataloader_params:dict)\n",
       "\n",
       "*Set the dataloader for the agent by wrapping it into a Torch Dataset*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| dataloader | BaseDataLoader |  |\n",
       "| dataloader_params | dict | dict with keys: batch_size, shuffle |\n",
       "| **Returns** | **None** |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/agents/newsvendor/erm.py#L64){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SGDBaseAgent.set_dataloader\n",
       "\n",
       ">      SGDBaseAgent.set_dataloader\n",
       ">                                   (dataloader:ddopnew.dataloaders.base.BaseDat\n",
       ">                                   aLoader, dataloader_params:dict)\n",
       "\n",
       "*Set the dataloader for the agent by wrapping it into a Torch Dataset*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| dataloader | BaseDataLoader |  |\n",
       "| dataloader_params | dict | dict with keys: batch_size, shuffle |\n",
       "| **Returns** | **None** |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(SGDBaseAgent.set_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/agents/newsvendor/erm.py#L77){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SGDBaseAgent.set_loss_function\n",
       "\n",
       ">      SGDBaseAgent.set_loss_function ()\n",
       "\n",
       "*Set loss function for the model*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/agents/newsvendor/erm.py#L77){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SGDBaseAgent.set_loss_function\n",
       "\n",
       ">      SGDBaseAgent.set_loss_function ()\n",
       "\n",
       "*Set loss function for the model*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(SGDBaseAgent.set_loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/agents/newsvendor/erm.py#L82){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SGDBaseAgent.set_model\n",
       "\n",
       ">      SGDBaseAgent.set_model (input_shape:Tuple, output_shape:Tuple)\n",
       "\n",
       "*Set the model for the agent*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/agents/newsvendor/erm.py#L82){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SGDBaseAgent.set_model\n",
       "\n",
       ">      SGDBaseAgent.set_model (input_shape:Tuple, output_shape:Tuple)\n",
       "\n",
       "*Set the model for the agent*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(SGDBaseAgent.set_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/agents/newsvendor/erm.py#L86){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SGDBaseAgent.set_optimizer\n",
       "\n",
       ">      SGDBaseAgent.set_optimizer (optimizer_params:dict)\n",
       "\n",
       "*Set the optimizer for the model*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| optimizer_params | dict | dict with keys: optimizer, lr, weight_decay |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/agents/newsvendor/erm.py#L86){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SGDBaseAgent.set_optimizer\n",
       "\n",
       ">      SGDBaseAgent.set_optimizer (optimizer_params:dict)\n",
       "\n",
       "*Set the optimizer for the model*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| optimizer_params | dict | dict with keys: optimizer, lr, weight_decay |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(SGDBaseAgent.set_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/agents/newsvendor/erm.py#L102){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SGDBaseAgent.set_learning_rate_scheduler\n",
       "\n",
       ">      SGDBaseAgent.set_learning_rate_scheduler\n",
       ">                                                (learning_rate_scheduler:None=N\n",
       ">                                                one)\n",
       "\n",
       "*Set learning rate scheudler (can be None)*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| learning_rate_scheduler | None | None |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/agents/newsvendor/erm.py#L102){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SGDBaseAgent.set_learning_rate_scheduler\n",
       "\n",
       ">      SGDBaseAgent.set_learning_rate_scheduler\n",
       ">                                                (learning_rate_scheduler:None=N\n",
       ">                                                one)\n",
       "\n",
       "*Set learning rate scheudler (can be None)*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| learning_rate_scheduler | None | None |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(SGDBaseAgent.set_learning_rate_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/agents/newsvendor/erm.py#L109){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SGDBaseAgent.fit_epoch\n",
       "\n",
       ">      SGDBaseAgent.fit_epoch ()\n",
       "\n",
       "*Fit the model for one epoch using the dataloader*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/agents/newsvendor/erm.py#L109){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SGDBaseAgent.fit_epoch\n",
       "\n",
       ">      SGDBaseAgent.fit_epoch ()\n",
       "\n",
       "*Fit the model for one epoch using the dataloader*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(SGDBaseAgent.fit_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/agents/newsvendor/erm.py#L148){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SGDBaseAgent.draw_action_\n",
       "\n",
       ">      SGDBaseAgent.draw_action_ (observation:numpy.ndarray)\n",
       "\n",
       "*Draw an action based on the fitted model (see predict method)*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| observation | ndarray |  |\n",
       "| **Returns** | **ndarray** |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/agents/newsvendor/erm.py#L148){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SGDBaseAgent.draw_action_\n",
       "\n",
       ">      SGDBaseAgent.draw_action_ (observation:numpy.ndarray)\n",
       "\n",
       "*Draw an action based on the fitted model (see predict method)*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| observation | ndarray |  |\n",
       "| **Returns** | **ndarray** |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(SGDBaseAgent.draw_action_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/agents/newsvendor/erm.py#L158){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SGDBaseAgent.predict\n",
       "\n",
       ">      SGDBaseAgent.predict (X:numpy.ndarray)\n",
       "\n",
       "*Do one forward pass of the model and return the prediction*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| X | ndarray |  |\n",
       "| **Returns** | **ndarray** |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/agents/newsvendor/erm.py#L158){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SGDBaseAgent.predict\n",
       "\n",
       ">      SGDBaseAgent.predict (X:numpy.ndarray)\n",
       "\n",
       "*Do one forward pass of the model and return the prediction*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| X | ndarray |  |\n",
       "| **Returns** | **ndarray** |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(SGDBaseAgent.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/agents/newsvendor/erm.py#L180){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SGDBaseAgent.train\n",
       "\n",
       ">      SGDBaseAgent.train ()\n",
       "\n",
       "*set the internal state of the agent and its model to train*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/agents/newsvendor/erm.py#L180){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SGDBaseAgent.train\n",
       "\n",
       ">      SGDBaseAgent.train ()\n",
       "\n",
       "*set the internal state of the agent and its model to train*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(SGDBaseAgent.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/agents/newsvendor/erm.py#L185){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SGDBaseAgent.eval\n",
       "\n",
       ">      SGDBaseAgent.eval ()\n",
       "\n",
       "*set the internal state of the agent and its model to eval*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/agents/newsvendor/erm.py#L185){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SGDBaseAgent.eval\n",
       "\n",
       ">      SGDBaseAgent.eval ()\n",
       "\n",
       "*set the internal state of the agent and its model to eval*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(SGDBaseAgent.eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/agents/newsvendor/erm.py#L190){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SGDBaseAgent.to\n",
       "\n",
       ">      SGDBaseAgent.to (device:str)\n",
       "\n",
       "*Move the model to the specified device*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| device | str |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/agents/newsvendor/erm.py#L190){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SGDBaseAgent.to\n",
       "\n",
       ">      SGDBaseAgent.to (device:str)\n",
       "\n",
       "*Move the model to the specified device*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| device | str |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(SGDBaseAgent.to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/agents/newsvendor/erm.py#L194){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SGDBaseAgent.save\n",
       "\n",
       ">      SGDBaseAgent.save (path:str, overwrite:bool=True)\n",
       "\n",
       "*Save the PyTorch model to a file in the specified directory.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| path | str |  | The directory where the file will be saved. |\n",
       "| overwrite | bool | True | Allow overwriting; if False, a FileExistsError will be raised if the file exists. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/agents/newsvendor/erm.py#L194){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SGDBaseAgent.save\n",
       "\n",
       ">      SGDBaseAgent.save (path:str, overwrite:bool=True)\n",
       "\n",
       "*Save the PyTorch model to a file in the specified directory.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| path | str |  | The directory where the file will be saved. |\n",
       "| overwrite | bool | True | Allow overwriting; if False, a FileExistsError will be raised if the file exists. |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(SGDBaseAgent.save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/agents/newsvendor/erm.py#L222){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SGDBaseAgent.load\n",
       "\n",
       ">      SGDBaseAgent.load (path:str)\n",
       "\n",
       "*Load the PyTorch model from a file.*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| path | str | Only the path to the folder is needed, not the file itself |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/agents/newsvendor/erm.py#L222){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### SGDBaseAgent.load\n",
       "\n",
       ">      SGDBaseAgent.load (path:str)\n",
       "\n",
       "*Load the PyTorch model from a file.*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| path | str | Only the path to the folder is needed, not the file itself |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(SGDBaseAgent.load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class NVBaseAgent(SGDBaseAgent):\n",
    "\n",
    "    \"\"\"\n",
    "    Base agent for the Newsvendor problem implementing\n",
    "    the loss function for the Empirical Risk Minimization (ERM) approach\n",
    "    based on quantile loss.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                environment_info: MDPInfo,\n",
    "                dataloader: BaseDataLoader,\n",
    "                cu: np.ndarray | Parameter,\n",
    "                co: np.ndarray | Parameter,\n",
    "                input_shape: Tuple,\n",
    "                output_shape: Tuple,\n",
    "                optimizer_params: dict | None = None,  # default: {\"optimizer\": \"Adam\", \"lr\": 0.01, \"weight_decay\": 0.0}\n",
    "                learning_rate_scheduler = None,  # TODO: add base class for learning rate scheduler for typing\n",
    "                dataloader_params: dict | None = None,  # default: {\"batch_size\": 32, \"shuffle\": True}\n",
    "                preprocessors: list | None = None,      # default: []\n",
    "                postprocessors: list | None = None,     # default: []\n",
    "                torch_preprocessors: list | None = None,  # default: []\n",
    "                device: str = \"cpu\", # \"cuda\" or \"cpu\"\n",
    "                agent_name: str | None = None,\n",
    "                ):\n",
    "\n",
    "        \n",
    "        cu = self.convert_to_numpy_array(cu)\n",
    "        co = self.convert_to_numpy_array(co)\n",
    "        \n",
    "        self.sl = cu / (cu + co) # ensure this works if cu and co are Parameters\n",
    "\n",
    "        super().__init__(environment_info, dataloader, input_shape, output_shape, optimizer_params, learning_rate_scheduler, dataloader_params, preprocessors, postprocessors,torch_preprocessors, device, agent_name)\n",
    "\n",
    "\n",
    "    def set_loss_function(self):\n",
    "\n",
    "        \"\"\"Set the loss function for the model to the quantile loss. For training\n",
    "        the model uses quantile loss and not the pinball loss with specific cu and \n",
    "        co values to ensure similar scale of the feedback signal during training.\"\"\"\n",
    "\n",
    "        self.loss_function_params = {\"quantile\": self.sl}\n",
    "        self.loss_function = TorchQuantileLoss(reduction=\"mean\")\n",
    "        \n",
    "        logging.debug(f\"Loss function set to {self.loss_function}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/agents/newsvendor/erm.py#L246){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "## NVBaseAgent\n",
       "\n",
       ">      NVBaseAgent (environment_info:ddopnew.utils.MDPInfo,\n",
       ">                   dataloader:ddopnew.dataloaders.base.BaseDataLoader,\n",
       ">                   cu:numpy.ndarray|ddopnew.utils.Parameter,\n",
       ">                   co:numpy.ndarray|ddopnew.utils.Parameter, input_shape:Tuple,\n",
       ">                   output_shape:Tuple, optimizer_params:dict|None=None,\n",
       ">                   learning_rate_scheduler=None,\n",
       ">                   dataloader_params:dict|None=None,\n",
       ">                   preprocessors:list|None=None, postprocessors:list|None=None,\n",
       ">                   torch_preprocessors:list|None=None, device:str='cpu',\n",
       ">                   agent_name:str|None=None)\n",
       "\n",
       "*Base agent for the Newsvendor problem implementing\n",
       "the loss function for the Empirical Risk Minimization (ERM) approach\n",
       "based on quantile loss.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| environment_info | MDPInfo |  |  |\n",
       "| dataloader | BaseDataLoader |  |  |\n",
       "| cu | numpy.ndarray \\| ddopnew.utils.Parameter |  |  |\n",
       "| co | numpy.ndarray \\| ddopnew.utils.Parameter |  |  |\n",
       "| input_shape | Tuple |  |  |\n",
       "| output_shape | Tuple |  |  |\n",
       "| optimizer_params | dict \\| None | None | default: {\"optimizer\": \"Adam\", \"lr\": 0.01, \"weight_decay\": 0.0} |\n",
       "| learning_rate_scheduler | NoneType | None | TODO: add base class for learning rate scheduler for typing |\n",
       "| dataloader_params | dict \\| None | None | default: {\"batch_size\": 32, \"shuffle\": True} |\n",
       "| preprocessors | list \\| None | None | default: [] |\n",
       "| postprocessors | list \\| None | None | default: [] |\n",
       "| torch_preprocessors | list \\| None | None | default: [] |\n",
       "| device | str | cpu | \"cuda\" or \"cpu\" |\n",
       "| agent_name | str \\| None | None |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/agents/newsvendor/erm.py#L246){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "## NVBaseAgent\n",
       "\n",
       ">      NVBaseAgent (environment_info:ddopnew.utils.MDPInfo,\n",
       ">                   dataloader:ddopnew.dataloaders.base.BaseDataLoader,\n",
       ">                   cu:numpy.ndarray|ddopnew.utils.Parameter,\n",
       ">                   co:numpy.ndarray|ddopnew.utils.Parameter, input_shape:Tuple,\n",
       ">                   output_shape:Tuple, optimizer_params:dict|None=None,\n",
       ">                   learning_rate_scheduler=None,\n",
       ">                   dataloader_params:dict|None=None,\n",
       ">                   preprocessors:list|None=None, postprocessors:list|None=None,\n",
       ">                   torch_preprocessors:list|None=None, device:str='cpu',\n",
       ">                   agent_name:str|None=None)\n",
       "\n",
       "*Base agent for the Newsvendor problem implementing\n",
       "the loss function for the Empirical Risk Minimization (ERM) approach\n",
       "based on quantile loss.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| environment_info | MDPInfo |  |  |\n",
       "| dataloader | BaseDataLoader |  |  |\n",
       "| cu | numpy.ndarray \\| ddopnew.utils.Parameter |  |  |\n",
       "| co | numpy.ndarray \\| ddopnew.utils.Parameter |  |  |\n",
       "| input_shape | Tuple |  |  |\n",
       "| output_shape | Tuple |  |  |\n",
       "| optimizer_params | dict \\| None | None | default: {\"optimizer\": \"Adam\", \"lr\": 0.01, \"weight_decay\": 0.0} |\n",
       "| learning_rate_scheduler | NoneType | None | TODO: add base class for learning rate scheduler for typing |\n",
       "| dataloader_params | dict \\| None | None | default: {\"batch_size\": 32, \"shuffle\": True} |\n",
       "| preprocessors | list \\| None | None | default: [] |\n",
       "| postprocessors | list \\| None | None | default: [] |\n",
       "| torch_preprocessors | list \\| None | None | default: [] |\n",
       "| device | str | cpu | \"cuda\" or \"cpu\" |\n",
       "| agent_name | str \\| None | None |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(NVBaseAgent, title_level=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/agents/newsvendor/erm.py#L280){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### NVBaseAgent.set_loss_function\n",
       "\n",
       ">      NVBaseAgent.set_loss_function ()\n",
       "\n",
       "*Set the loss function for the model to the quantile loss. For training\n",
       "the model uses quantile loss and not the pinball loss with specific cu and \n",
       "co values to ensure similar scale of the feedback signal during training.*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/agents/newsvendor/erm.py#L280){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### NVBaseAgent.set_loss_function\n",
       "\n",
       ">      NVBaseAgent.set_loss_function ()\n",
       "\n",
       "*Set the loss function for the model to the quantile loss. For training\n",
       "the model uses quantile loss and not the pinball loss with specific cu and \n",
       "co values to ensure similar scale of the feedback signal during training.*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(NVBaseAgent.set_loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class NewsvendorlERMAgent(NVBaseAgent):\n",
    "\n",
    "    \"\"\"\n",
    "    Newsvendor agent implementing Empirical Risk Minimization (ERM) approach \n",
    "    based on a linear (regression) model. Note that this implementation finds\n",
    "    the optimal regression parameters via SGD.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                environment_info: MDPInfo,\n",
    "                dataloader: BaseDataLoader,\n",
    "                cu: np.ndarray | Parameter,\n",
    "                co: np.ndarray | Parameter,\n",
    "                input_shape: Tuple,\n",
    "                output_shape: Tuple,\n",
    "                optimizer_params: dict | None = None,  # default: {\"optimizer\": \"Adam\", \"lr\": 0.01, \"weight_decay\": 0.0}\n",
    "                learning_rate_scheduler = None,  # TODO: add base class for learning rate scheduler for typing\n",
    "                model_params: dict | None = None,  # default: {\"relu_output\": False}\n",
    "                dataloader_params: dict | None = None,  # default: {\"batch_size\": 32, \"shuffle\": True}\n",
    "                preprocessors: list | None = None,  # default: []\n",
    "                postprocessors: list | None = None,  # default: []\n",
    "                torch_preprocessors: list | None = None,  # default: [FlattenTimeDim(allow_2d=False)]\n",
    "                device: str = \"cpu\",  # \"cuda\" or \"cpu\"\n",
    "                agent_name: str | None = \"lERM\"\n",
    "                ):\n",
    "\n",
    "        # Handle mutable defaults unique to this class\n",
    "        default_model_params = {\n",
    "            \"relu_output\": False\n",
    "            }\n",
    "\n",
    "        self.model_params = self.update_model_params(default_model_params, model_params or {})\n",
    "\n",
    "        # By default automatically flatten the time dimension of data, if it is not already 2D\n",
    "        torch_preprocessors = [FlattenTimeDim(allow_2d=True)] if torch_preprocessors is None else torch_preprocessors\n",
    "\n",
    "        super().__init__(environment_info, dataloader, cu, co, input_shape, output_shape, optimizer_params, learning_rate_scheduler, dataloader_params, preprocessors, postprocessors, torch_preprocessors, device, agent_name)\n",
    "    \n",
    "    def set_model(self, input_shape, output_shape):\n",
    "\n",
    "        \"\"\"Set the model for the agent to a linear model\"\"\"\n",
    "\n",
    "        from ddopnew.approximators import LinearModel\n",
    "\n",
    "        # flatten time dim of input\n",
    "        input_size = np.prod(input_shape)\n",
    "        output_size = output_shape[0]\n",
    "\n",
    "        self.model = LinearModel(input_size=input_size, output_size=output_size, **self.model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/agents/newsvendor/erm.py#L292){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "## NewsvendorlERMAgent\n",
       "\n",
       ">      NewsvendorlERMAgent (environment_info:ddopnew.utils.MDPInfo,\n",
       ">                           dataloader:ddopnew.dataloaders.base.BaseDataLoader,\n",
       ">                           cu:numpy.ndarray|ddopnew.utils.Parameter,\n",
       ">                           co:numpy.ndarray|ddopnew.utils.Parameter,\n",
       ">                           input_shape:Tuple, output_shape:Tuple,\n",
       ">                           optimizer_params:dict|None=None,\n",
       ">                           learning_rate_scheduler=None,\n",
       ">                           model_params:dict|None=None,\n",
       ">                           dataloader_params:dict|None=None,\n",
       ">                           preprocessors:list|None=None,\n",
       ">                           postprocessors:list|None=None,\n",
       ">                           torch_preprocessors:list|None=None,\n",
       ">                           device:str='cpu', agent_name:str|None='lERM')\n",
       "\n",
       "*Newsvendor agent implementing Empirical Risk Minimization (ERM) approach \n",
       "based on a linear (regression) model. Note that this implementation finds\n",
       "the optimal regression parameters via SGD.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| environment_info | MDPInfo |  |  |\n",
       "| dataloader | BaseDataLoader |  |  |\n",
       "| cu | numpy.ndarray \\| ddopnew.utils.Parameter |  |  |\n",
       "| co | numpy.ndarray \\| ddopnew.utils.Parameter |  |  |\n",
       "| input_shape | Tuple |  |  |\n",
       "| output_shape | Tuple |  |  |\n",
       "| optimizer_params | dict \\| None | None | default: {\"optimizer\": \"Adam\", \"lr\": 0.01, \"weight_decay\": 0.0} |\n",
       "| learning_rate_scheduler | NoneType | None | TODO: add base class for learning rate scheduler for typing |\n",
       "| model_params | dict \\| None | None | default: {\"relu_output\": False} |\n",
       "| dataloader_params | dict \\| None | None | default: {\"batch_size\": 32, \"shuffle\": True} |\n",
       "| preprocessors | list \\| None | None | default: [] |\n",
       "| postprocessors | list \\| None | None | default: [] |\n",
       "| torch_preprocessors | list \\| None | None | default: [FlattenTimeDim(allow_2d=False)] |\n",
       "| device | str | cpu | \"cuda\" or \"cpu\" |\n",
       "| agent_name | str \\| None | lERM |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/agents/newsvendor/erm.py#L292){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "## NewsvendorlERMAgent\n",
       "\n",
       ">      NewsvendorlERMAgent (environment_info:ddopnew.utils.MDPInfo,\n",
       ">                           dataloader:ddopnew.dataloaders.base.BaseDataLoader,\n",
       ">                           cu:numpy.ndarray|ddopnew.utils.Parameter,\n",
       ">                           co:numpy.ndarray|ddopnew.utils.Parameter,\n",
       ">                           input_shape:Tuple, output_shape:Tuple,\n",
       ">                           optimizer_params:dict|None=None,\n",
       ">                           learning_rate_scheduler=None,\n",
       ">                           model_params:dict|None=None,\n",
       ">                           dataloader_params:dict|None=None,\n",
       ">                           preprocessors:list|None=None,\n",
       ">                           postprocessors:list|None=None,\n",
       ">                           torch_preprocessors:list|None=None,\n",
       ">                           device:str='cpu', agent_name:str|None='lERM')\n",
       "\n",
       "*Newsvendor agent implementing Empirical Risk Minimization (ERM) approach \n",
       "based on a linear (regression) model. Note that this implementation finds\n",
       "the optimal regression parameters via SGD.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| environment_info | MDPInfo |  |  |\n",
       "| dataloader | BaseDataLoader |  |  |\n",
       "| cu | numpy.ndarray \\| ddopnew.utils.Parameter |  |  |\n",
       "| co | numpy.ndarray \\| ddopnew.utils.Parameter |  |  |\n",
       "| input_shape | Tuple |  |  |\n",
       "| output_shape | Tuple |  |  |\n",
       "| optimizer_params | dict \\| None | None | default: {\"optimizer\": \"Adam\", \"lr\": 0.01, \"weight_decay\": 0.0} |\n",
       "| learning_rate_scheduler | NoneType | None | TODO: add base class for learning rate scheduler for typing |\n",
       "| model_params | dict \\| None | None | default: {\"relu_output\": False} |\n",
       "| dataloader_params | dict \\| None | None | default: {\"batch_size\": 32, \"shuffle\": True} |\n",
       "| preprocessors | list \\| None | None | default: [] |\n",
       "| postprocessors | list \\| None | None | default: [] |\n",
       "| torch_preprocessors | list \\| None | None | default: [FlattenTimeDim(allow_2d=False)] |\n",
       "| device | str | cpu | \"cuda\" or \"cpu\" |\n",
       "| agent_name | str \\| None | lERM |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(NewsvendorlERMAgent, title_level=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further information:   \n",
    "   \n",
    "    References\n",
    "    ----------\n",
    "    \n",
    "    .. [1] Gah-Yi Ban, Cynthia Rudin, \"The Big Data Newsvendor: Practical Insights\n",
    "        from Machine Learning\", 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/agents/newsvendor/erm.py#L331){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### NewsvendorlERMAgent.set_model\n",
       "\n",
       ">      NewsvendorlERMAgent.set_model (input_shape, output_shape)\n",
       "\n",
       "*Set the model for the agent to a linear model*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/agents/newsvendor/erm.py#L331){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### NewsvendorlERMAgent.set_model\n",
       "\n",
       ">      NewsvendorlERMAgent.set_model (input_shape, output_shape)\n",
       "\n",
       "*Set the model for the agent to a linear model*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(NewsvendorlERMAgent.set_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-19.723870891879358 -18.81128201610496\n",
      "-16.557284640159896 -15.787909485147676\n"
     ]
    }
   ],
   "source": [
    "from ddopnew.envs.inventory import NewsvendorEnv\n",
    "from ddopnew.dataloaders.tabular import XYDataLoader\n",
    "from ddopnew.experiment_functions import run_experiment, test_agent\n",
    "\n",
    "val_index_start = 800 #90_000\n",
    "test_index_start = 900 #100_000\n",
    "\n",
    "X = np.random.rand(1000, 2)\n",
    "Y = np.random.rand(1000, 1)\n",
    "\n",
    "dataloader = XYDataLoader(X, Y, val_index_start, test_index_start)\n",
    "\n",
    "environment = NewsvendorEnv(\n",
    "    dataloader = dataloader,\n",
    "    underage_cost = 0.42857,\n",
    "    overage_cost = 1.0,\n",
    "    gamma = 0.999,\n",
    "    horizon_train = 365,\n",
    ")\n",
    "\n",
    "agent = NewsvendorlERMAgent(environment.mdp_info,\n",
    "                            dataloader,\n",
    "                            cu=np.array([0.42857]),\n",
    "                            co=np.array([1.0]),\n",
    "                            input_shape=(2,),\n",
    "                            output_shape=(1,),\n",
    "                            optimizer_params= {\"optimizer\": \"Adam\", \"lr\": 0.01, \"weight_decay\": 0.0}, # other optimizers: \"SGD\", \"RMSprop\"\n",
    "                            learning_rate_scheduler = None, # TODO add base class for learning rate scheduler for typing\n",
    "                            model_params = {\"relu_output\": False}, #\n",
    "                            dataloader_params={\"batch_size\": 32, \"shuffle\": True},\n",
    "                            torch_preprocessors = [],\n",
    "                            device = \"cpu\", # \"cuda\" or \"cpu\"\n",
    ")\n",
    "\n",
    "environment.test()\n",
    "agent.eval()\n",
    "\n",
    "R, J = test_agent(agent, environment)\n",
    "\n",
    "print(R, J)\n",
    "\n",
    "run_experiment(agent, environment, 2, run_id = \"test\") # fit agent via run_experiment function\n",
    "\n",
    "environment.test()\n",
    "agent.eval()\n",
    "\n",
    "R, J = test_agent(agent, environment)\n",
    "\n",
    "print(R, J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class NewsvendorDLAgent(NVBaseAgent):\n",
    "\n",
    "    \"\"\"\n",
    "    Newsvendor agent implementing Empirical Risk Minimization (ERM) approach \n",
    "    based on a deep learning model. \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                environment_info: MDPInfo,\n",
    "                dataloader: BaseDataLoader,\n",
    "                cu: np.ndarray | Parameter,\n",
    "                co: np.ndarray | Parameter,\n",
    "                input_shape: Tuple,\n",
    "                output_shape: Tuple,\n",
    "                learning_rate_scheduler = None,  # TODO: add base class for learning rate scheduler for typing\n",
    "                \n",
    "                # parameters in yaml file\n",
    "                optimizer_params: dict | None = None,  # default: {\"optimizer\": \"Adam\", \"lr\": 0.01, \"weight_decay\": 0.0}\n",
    "                model_params: dict | None = None,  # default: {\"hidden_layers\": [64, 64], \"drop_prob\": 0.0, \"batch_norm\": False, \"relu_output\": False}\n",
    "                dataloader_params: dict | None = None,  # default: {\"batch_size\": 32, \"shuffle\": True}\n",
    "                device: str = \"cpu\", # \"cuda\" or \"cpu\"\n",
    "\n",
    "                preprocessors: list | None = None,  # default: []\n",
    "                postprocessors: list | None = None,  # default: []\n",
    "                torch_preprocessors: list | None = None,  # default: [FlattenTimeDim(allow_2d=False)]\n",
    "                agent_name: str | None = \"DLNV\",\n",
    "                ):\n",
    "\n",
    "        # Handle mutable defaults unique to this class\n",
    "        default_model_params = {\n",
    "            \"hidden_layers\": [64, 64],\n",
    "            \"drop_prob\": 0.0,\n",
    "            \"batch_norm\": False,\n",
    "            \"relu_output\": False\n",
    "            }\n",
    "\n",
    "        self.model_params = self.update_model_params(default_model_params, model_params or {})\n",
    "        \n",
    "        torch_preprocessors = [FlattenTimeDim(allow_2d=True)] if torch_preprocessors is None else torch_preprocessors\n",
    "\n",
    "        super().__init__(environment_info, dataloader, cu, co, input_shape, output_shape, optimizer_params, learning_rate_scheduler, dataloader_params, preprocessors, postprocessors, torch_preprocessors, device, agent_name)\n",
    "    \n",
    "    def set_model(self, input_shape, output_shape):\n",
    "        \n",
    "        \"\"\"Set the model for the agent to an MLP\"\"\"\n",
    "\n",
    "\n",
    "        # flatten time dim of input\n",
    "        input_size = np.prod(input_shape)\n",
    "        output_size = output_shape[0]\n",
    "\n",
    "        from ddopnew.approximators import MLP\n",
    "        self.model = MLP(input_size=input_size, output_size=output_size, **self.model_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/agents/newsvendor/erm.py#L339){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "## NewsvendorDLAgent\n",
       "\n",
       ">      NewsvendorDLAgent (environment_info:ddopnew.utils.MDPInfo,\n",
       ">                         dataloader:ddopnew.dataloaders.base.BaseDataLoader,\n",
       ">                         cu:numpy.ndarray|ddopnew.utils.Parameter,\n",
       ">                         co:numpy.ndarray|ddopnew.utils.Parameter,\n",
       ">                         input_shape:Tuple, output_shape:Tuple,\n",
       ">                         learning_rate_scheduler=None,\n",
       ">                         optimizer_params:dict|None=None,\n",
       ">                         model_params:dict|None=None,\n",
       ">                         dataloader_params:dict|None=None, device:str='cpu',\n",
       ">                         preprocessors:list|None=None,\n",
       ">                         postprocessors:list|None=None,\n",
       ">                         torch_preprocessors:list|None=None,\n",
       ">                         agent_name:str|None='DLNV')\n",
       "\n",
       "*Newsvendor agent implementing Empirical Risk Minimization (ERM) approach \n",
       "based on a deep learning model.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| environment_info | MDPInfo |  |  |\n",
       "| dataloader | BaseDataLoader |  |  |\n",
       "| cu | numpy.ndarray \\| ddopnew.utils.Parameter |  |  |\n",
       "| co | numpy.ndarray \\| ddopnew.utils.Parameter |  |  |\n",
       "| input_shape | Tuple |  |  |\n",
       "| output_shape | Tuple |  |  |\n",
       "| learning_rate_scheduler | NoneType | None | TODO: add base class for learning rate scheduler for typing |\n",
       "| optimizer_params | dict \\| None | None | default: {\"optimizer\": \"Adam\", \"lr\": 0.01, \"weight_decay\": 0.0} |\n",
       "| model_params | dict \\| None | None | default: {\"hidden_layers\": [64, 64], \"drop_prob\": 0.0, \"batch_norm\": False, \"relu_output\": False} |\n",
       "| dataloader_params | dict \\| None | None | default: {\"batch_size\": 32, \"shuffle\": True} |\n",
       "| device | str | cpu | \"cuda\" or \"cpu\" |\n",
       "| preprocessors | list \\| None | None | default: [] |\n",
       "| postprocessors | list \\| None | None | default: [] |\n",
       "| torch_preprocessors | list \\| None | None | default: [FlattenTimeDim(allow_2d=False)] |\n",
       "| agent_name | str \\| None | DLNV |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/agents/newsvendor/erm.py#L339){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "## NewsvendorDLAgent\n",
       "\n",
       ">      NewsvendorDLAgent (environment_info:ddopnew.utils.MDPInfo,\n",
       ">                         dataloader:ddopnew.dataloaders.base.BaseDataLoader,\n",
       ">                         cu:numpy.ndarray|ddopnew.utils.Parameter,\n",
       ">                         co:numpy.ndarray|ddopnew.utils.Parameter,\n",
       ">                         input_shape:Tuple, output_shape:Tuple,\n",
       ">                         learning_rate_scheduler=None,\n",
       ">                         optimizer_params:dict|None=None,\n",
       ">                         model_params:dict|None=None,\n",
       ">                         dataloader_params:dict|None=None, device:str='cpu',\n",
       ">                         preprocessors:list|None=None,\n",
       ">                         postprocessors:list|None=None,\n",
       ">                         torch_preprocessors:list|None=None,\n",
       ">                         agent_name:str|None='DLNV')\n",
       "\n",
       "*Newsvendor agent implementing Empirical Risk Minimization (ERM) approach \n",
       "based on a deep learning model.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| environment_info | MDPInfo |  |  |\n",
       "| dataloader | BaseDataLoader |  |  |\n",
       "| cu | numpy.ndarray \\| ddopnew.utils.Parameter |  |  |\n",
       "| co | numpy.ndarray \\| ddopnew.utils.Parameter |  |  |\n",
       "| input_shape | Tuple |  |  |\n",
       "| output_shape | Tuple |  |  |\n",
       "| learning_rate_scheduler | NoneType | None | TODO: add base class for learning rate scheduler for typing |\n",
       "| optimizer_params | dict \\| None | None | default: {\"optimizer\": \"Adam\", \"lr\": 0.01, \"weight_decay\": 0.0} |\n",
       "| model_params | dict \\| None | None | default: {\"hidden_layers\": [64, 64], \"drop_prob\": 0.0, \"batch_norm\": False, \"relu_output\": False} |\n",
       "| dataloader_params | dict \\| None | None | default: {\"batch_size\": 32, \"shuffle\": True} |\n",
       "| device | str | cpu | \"cuda\" or \"cpu\" |\n",
       "| preprocessors | list \\| None | None | default: [] |\n",
       "| postprocessors | list \\| None | None | default: [] |\n",
       "| torch_preprocessors | list \\| None | None | default: [FlattenTimeDim(allow_2d=False)] |\n",
       "| agent_name | str \\| None | DLNV |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(NewsvendorDLAgent, title_level=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further information:   \n",
    "   \n",
    "    References\n",
    "    ----------\n",
    "    \n",
    "    .. [1] Afshin Oroojlooyjadid, Lawrence V. Snyder, Martin Takáˇc,\n",
    "            \"Applying Deep Learning to the Newsvendor Problem\", 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/agents/newsvendor/erm.py#L381){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### NewsvendorDLAgent.set_model\n",
       "\n",
       ">      NewsvendorDLAgent.set_model (input_shape, output_shape)\n",
       "\n",
       "*Set the model for the agent to an MLP*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopnew/blob/main/ddopnew/agents/newsvendor/erm.py#L381){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### NewsvendorDLAgent.set_model\n",
       "\n",
       ">      NewsvendorDLAgent.set_model (input_shape, output_shape)\n",
       "\n",
       "*Set the model for the agent to an MLP*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(NewsvendorDLAgent.set_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-21.00788921607091 -20.014243363220327\n",
      "-15.843676238460636 -15.124868911930205\n"
     ]
    }
   ],
   "source": [
    "dataloader = XYDataLoader(X, Y, val_index_start, test_index_start)\n",
    "\n",
    "environment = NewsvendorEnv(\n",
    "    dataloader = dataloader,\n",
    "    underage_cost = 0.42857,\n",
    "    overage_cost = 1.0,\n",
    "    gamma = 0.999,\n",
    "    horizon_train = 365,\n",
    ")\n",
    "\n",
    "model_params = {\n",
    "    \"hidden_layers\": [64, 64],\n",
    "}\n",
    "\n",
    "agent = NewsvendorDLAgent(environment.mdp_info,\n",
    "                            dataloader,\n",
    "                            cu=np.array([0.42857]),\n",
    "                            co=np.array([1.0]),\n",
    "                            input_shape=(2,),\n",
    "                            output_shape=(1,),\n",
    "                            optimizer_params= {\"optimizer\": \"Adam\", \"lr\": 0.01, \"weight_decay\": 0.0}, # other optimizers: \"SGD\", \"RMSprop\"\n",
    "                            learning_rate_scheduler = None, # TODO add base class for learning rate scheduler for typing\n",
    "                            model_params = model_params, #\n",
    "                            dataloader_params={\"batch_size\": 32, \"shuffle\": True},\n",
    "                            torch_preprocessors = [],\n",
    "                            device = \"cpu\" # \"cuda\" or \"cpu\"\n",
    ")\n",
    "\n",
    "environment.test()\n",
    "agent.eval()\n",
    "\n",
    "R, J = test_agent(agent, environment)\n",
    "\n",
    "print(R, J)\n",
    "\n",
    "run_experiment(agent, environment, 2, run_id = \"test\") # fit agent via run_experiment function\n",
    "\n",
    "environment.test()\n",
    "agent.eval()\n",
    "\n",
    "R, J = test_agent(agent, environment)\n",
    "\n",
    "print(R, J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
