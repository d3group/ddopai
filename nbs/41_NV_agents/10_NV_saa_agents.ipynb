{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAA based agents\n",
    "\n",
    "TODO: ADD PROCESSORS\n",
    "> To be written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp agents.newsvendor.saa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging_level = logging.DEBUG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Union, Optional, List\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "from ddopnew.envs.base import BaseEnvironment\n",
    "from ddopnew.agents.base import BaseAgent\n",
    "from ddopnew.utils import MDPInfo\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.utils.validation import check_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BaseSAAagent(BaseAgent):\n",
    "\n",
    "    def __init__(self,\n",
    "                 environment_info: MDPInfo,\n",
    "                 preprocessors: Optional[List[object]] = None,\n",
    "                 postprocessors: Optional[List[object]] = None):\n",
    "\n",
    "        super().__init__(environment_info, preprocessors, postprocessors)\n",
    "\n",
    "    def find_weighted_quantiles(self, weights, weightPosIndices, sl, y):\n",
    "        \n",
    "        \"\"\"\n",
    "        Find the weighted quantile of a range of data y. \n",
    "        It assumes that all arrays are of shape (n_samples, n_outputs).\n",
    "\n",
    "        This function is designed for single-output only\n",
    "        \"\"\"\n",
    "\n",
    "        # test shapes have lenght 2 with error\n",
    "        assert len(y.shape) == 2, \"y should be of shape (n_samples, n_outputs)\"\n",
    "\n",
    "        n_outputs = y.shape[1]\n",
    "\n",
    "        yWeightPos = y[weightPosIndices]\n",
    "\n",
    "        if self.print:\n",
    "            print(yWeightPos)\n",
    "        \n",
    "        q = []\n",
    "\n",
    "        if len(weights.shape) == 1:\n",
    "            weights = weights.reshape(-1, 1)\n",
    "        \n",
    "        for i in range(n_outputs):\n",
    "            \n",
    "            indicesYSort = np.argsort(yWeightPos[:, i])\n",
    "            \n",
    "            ySorted = yWeightPos[indicesYSort, i]\n",
    "            \n",
    "            distributionFunction = np.cumsum(weights[indicesYSort, i])\n",
    "\n",
    "            decisionIndex = np.where(distributionFunction >= sl)[0][0]\n",
    "            \n",
    "            q.append(ySorted[decisionIndex])\n",
    "\n",
    "        q = np.array(q)\n",
    "        \n",
    "        return q\n",
    "    \n",
    "    def _validate_X_predict(self, X):\n",
    "        \"\"\"Validate X whenever one tries to predict\"\"\"\n",
    "\n",
    "        X = check_array(X)\n",
    "\n",
    "        n_features = X.shape[1]\n",
    "        if self.n_features_ != n_features:\n",
    "            raise ValueError(\"Number of features of the model must match the input. \"\n",
    "                             \"Model n_features is %s and input n_features is %s \"\n",
    "                             % (self.n_features_, n_features))\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class NewsvendorSAAagent(BaseSAAagent):\n",
    "\n",
    "    def __init__(self,\n",
    "                environment_info: MDPInfo,\n",
    "                cu: Union[float, np.ndarray],\n",
    "                co: Union[float, np.ndarray],\n",
    "                preprocessors: Optional[List[object]] = None,\n",
    "                postprocessors: Optional[List[object]] = None):\n",
    "\n",
    "        # if float, convert to array\n",
    "        self.cu = np.array([cu]) if isinstance(cu, float) else cu\n",
    "        self.co = np.array([co]) if isinstance(co, float) else co\n",
    "\n",
    "        self.sl = cu / (cu + co)\n",
    "        self.fitted = False\n",
    "\n",
    "        super().__init__(environment_info, preprocessors, postprocessors)\n",
    "\n",
    "    def fit(self,\n",
    "            X: np.ndarray,\n",
    "            Y: np.ndarray):\n",
    "\n",
    "        # # potential line:\n",
    "        # X, y = self._validate_data(X, y, multi_output=True)\n",
    "\n",
    "        weights = np.ones(Y.shape)/Y.shape[0]\n",
    "        weightPosIndices = np.arange(Y.shape[0])\n",
    "        \n",
    "        self.quantiles = self.find_weighted_quantiles(weights, weightPosIndices, self.sl, Y)\n",
    "\n",
    "        self.fitted = True\n",
    "\n",
    "    def draw_action_(self, \n",
    "                    observation: np.ndarray) -> np.ndarray:\n",
    "\n",
    "        if self.fitted == False:\n",
    "            return np.array([0.0])\n",
    "\n",
    "        return self.quantiles\n",
    "\n",
    "\n",
    "    def save(self, path: str, overwrite=True):\n",
    "        \n",
    "        \"\"\"\n",
    "        Save the quantiles to a file in the specified directory.\n",
    "\n",
    "        Parameters:\n",
    "        - path (str): The directory where the file will be saved.\n",
    "        - overwrite (bool): If True, the file will be overwritten if it already exists. \n",
    "                            If False, a FileExistsError will be raised if the file exists.\n",
    "\n",
    "        Raises:\n",
    "        - ValueError: If the agent has not been fitted.\n",
    "        - FileExistsError: If the file already exists and overwrite is set to False.\n",
    "        \"\"\"\n",
    "\n",
    "        if not self.fitted:\n",
    "            raise ValueError(\"Agent has not been fitted yet\")\n",
    "\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        \n",
    "        full_path = os.path.join(path, \"saa_quantiles.npy\")\n",
    "        \n",
    "        if os.path.exists(full_path):\n",
    "            if not overwrite:\n",
    "                raise FileExistsError(f\"The file {full_path} already exists and will not be overwritten.\")\n",
    "            else:\n",
    "                logging.warning(f\"Overwriting file {full_path}\")\n",
    "                \n",
    "        np.save(full_path, self.quantiles)\n",
    "\n",
    "    def load(self, path: str):\n",
    "\n",
    "        \"\"\"\n",
    "        Load the quantiles from a file.\n",
    "        \n",
    "        Parameters:\n",
    "        - path (str): The directory where the file is located.\n",
    "        \n",
    "        Raises:\n",
    "        - FileNotFoundError: If the file does not exist.\n",
    "        - ValueError: If the loaded data is not valid.\n",
    "        \"\"\"\n",
    "\n",
    "        full_path = os.path.join(path, \"saa_quantiles.npy\")\n",
    "        \n",
    "        if not os.path.exists(full_path):\n",
    "            raise FileNotFoundError(f\"The file {full_path} does not exist.\")\n",
    "        \n",
    "        try:\n",
    "            self.quantiles = np.load(full_path)\n",
    "            self.fitted = True  # Assuming that loading the quantiles means the agent is now 'fitted'\n",
    "            logging.info(f\"Quantiles loaded successfully from {full_path}\")\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"An error occurred while loading the file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BasewSAAagent(BaseSAAagent):\n",
    "\n",
    "    def __init__(self,\n",
    "                environment_info: MDPInfo,\n",
    "                cu: Union[float, np.ndarray],\n",
    "                co: Union[float, np.ndarray],\n",
    "                preprocessors: Optional[List[object]] = None,\n",
    "                postprocessors: Optional[List[object]] = None):\n",
    "\n",
    "        # if float, convert to array\n",
    "        self.cu = np.array([cu]) if isinstance(cu, float) else cu\n",
    "        self.co = np.array([co]) if isinstance(co, float) else co\n",
    "\n",
    "        self.sl = cu / (cu + co)\n",
    "        self.fitted = False\n",
    "\n",
    "        super().__init__(environment_info, preprocessors, postprocessors)\n",
    "\n",
    "    def fit(self,\n",
    "            X: np.ndarray,\n",
    "            Y: np.ndarray):\n",
    "        \n",
    "        # # potential line:\n",
    "        # X, y = self._validate_data(X, y, multi_output=True)\n",
    "\n",
    "        X = self.flatten_X(X) # remove time dimension, if there\n",
    "\n",
    "        if len(Y.shape) == 2 and Y.shape[1] == 1:\n",
    "            Y = Y.flatten() \n",
    "\n",
    "        self._get_fitted_model(X, Y)\n",
    "\n",
    "        if Y.ndim == 1:\n",
    "            Y = np.reshape(Y, (-1, 1))\n",
    "\n",
    "        # Training data\n",
    "        self.Y_ = Y\n",
    "        self.X_ = X\n",
    "        self.n_samples_ = Y.shape[0]\n",
    "\n",
    "        # Determine output settings\n",
    "        self.n_outputs_ = Y.shape[1]\n",
    "        self.n_features_ = X.shape[1]\n",
    "\n",
    "        self.fitted=True\n",
    "\n",
    "    def draw_action_(self, \n",
    "                    observation: np.ndarray) -> np.ndarray:\n",
    "\n",
    "        if self.fitted == False:\n",
    "            return np.array([0.0])\n",
    "\n",
    "        observation = self.flatten_X(observation) # remove time dimension, if any\n",
    "        \n",
    "        return self.predict(observation)\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _get_fitted_model(self, X, y):\n",
    "        \"\"\"Initialise the underlying model\"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def _calc_weights(self, sample):\n",
    "        \"\"\"Calculate the sample weights\"\"\"\n",
    "\n",
    "    def predict(self, \n",
    "                X: np.ndarray\n",
    "    ) -> np.ndarray:\n",
    "        \"\"\"Predict value for X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            The input samples to predict.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        y : array-like of shape (n_samples, n_outputs)\n",
    "            The predicted values\n",
    "        \"\"\"\n",
    "\n",
    "        X = self._validate_X_predict(X)  \n",
    "\n",
    "        if self.print:\n",
    "            print(\"X: \", X)\n",
    "\n",
    "        weightsDataList = [self._calc_weights(row) for row in X]\n",
    "\n",
    "        if self.print:\n",
    "            print(\"weightsDataList: \", weightsDataList)\n",
    "\n",
    "        pred = [self.find_weighted_quantiles(weights, weightPosIndices, self.sl, self.Y_) \n",
    "                for weights, weightPosIndices in weightsDataList]\n",
    "\n",
    "\n",
    "        pred = np.array(pred)   \n",
    "\n",
    "        if self.print:\n",
    "            print(\"Predicted quantiles: \", pred)\n",
    "\n",
    "        return pred\n",
    "\n",
    "    def save(self, path: str, overwrite=True):\n",
    "        \"\"\"\n",
    "        Save the scikit-learn model to a file in the specified directory.\n",
    "\n",
    "        Parameters:\n",
    "        - path (str): The directory where the model file will be saved.\n",
    "        - overwrite (bool): If True, the file will be overwritten if it already exists. \n",
    "                            If False, a FileExistsError will be raised if the file exists.\n",
    "\n",
    "        Raises:\n",
    "        - ValueError: If the model has not been fitted.\n",
    "        - FileExistsError: If the file already exists and overwrite is set to False.\n",
    "        \"\"\"\n",
    "\n",
    "        if not self.fitted:\n",
    "            raise ValueError(\"Agent has not been fitted yet\")\n",
    "\n",
    "        if not hasattr(self, 'model_') or self.model_ is None:\n",
    "            raise ValueError(\"Agent has no model to save.\")\n",
    "\n",
    "        # Create directory if it does not exist\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        \n",
    "        # Construct the file path using os.path.join for better cross-platform compatibility\n",
    "        full_path = os.path.join(path, \"model.joblib\")\n",
    "        \n",
    "        if os.path.exists(full_path):\n",
    "            if not overwrite:\n",
    "                raise FileExistsError(f\"The file {full_path} already exists and will not be overwritten.\")\n",
    "            else:\n",
    "                logging.warning(f\"Overwriting file {full_path}\")\n",
    "        \n",
    "        # Save the model using joblib\n",
    "        joblib.dump(self.model_, full_path)\n",
    "\n",
    "    def load(self, path: str):\n",
    "        \"\"\"\n",
    "        Load the scikit-learn model from a file.\n",
    "\n",
    "        Parameters:\n",
    "        - path (str): The directory where the model file is located.\n",
    "\n",
    "        Raises:\n",
    "        - FileNotFoundError: If the file does not exist.\n",
    "        - ValueError: If an error occurs during loading.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Construct the file path\n",
    "        full_path = os.path.join(path, \"model.joblib\")\n",
    "        \n",
    "        if not os.path.exists(full_path):\n",
    "            raise FileNotFoundError(f\"The file {full_path} does not exist.\")\n",
    "        \n",
    "        try:\n",
    "            # Load the model using joblib\n",
    "            self.model_ = joblib.load(full_path)\n",
    "            self.fitted = True  # Assuming that loading the model means the agent is now 'fitted'\n",
    "            logging.info(f\"Model loaded successfully from {full_path}\")\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"An error occurred while loading the model: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class NewsvendorRFwSAAagent(BasewSAAagent):\n",
    "\n",
    "    def __init__(self,\n",
    "                environment_info: MDPInfo,\n",
    "                cu: Union[float, np.ndarray],\n",
    "                co: Union[float, np.ndarray], \n",
    "                preprocessors: Optional[List[object]] = None,\n",
    "                postprocessors: Optional[List[object]] = None,\n",
    "                n_estimators: int = 100,\n",
    "                criterion: str = \"squared_error\",\n",
    "                max_depth: Optional[int] = None,\n",
    "                min_samples_split: int = 2,\n",
    "                min_samples_leaf: int = 1,\n",
    "                min_weight_fraction_leaf: float = 0.0,\n",
    "                max_features: Union[int, float, str, None] = 1.0,\n",
    "                max_leaf_nodes: Optional[int] = None,\n",
    "                min_impurity_decrease: float = 0.0,\n",
    "                bootstrap: bool = True,\n",
    "                oob_score: bool = False,\n",
    "                n_jobs: Optional[int] = None,\n",
    "                random_state: Optional[Union[int, np.random.RandomState]] = None,\n",
    "                verbose: int = 0,\n",
    "                warm_start: bool = False,\n",
    "                ccp_alpha: float = 0.0,\n",
    "                max_samples: Optional[Union[int, float]] = None,\n",
    "                monotonic_cst: Optional[np.ndarray] = None\n",
    "                ):\n",
    "        self.criterion = criterion\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.min_weight_fraction_leaf = min_weight_fraction_leaf\n",
    "        self.max_features = max_features\n",
    "        self.max_leaf_nodes = max_leaf_nodes\n",
    "        self.min_impurity_decrease = min_impurity_decrease\n",
    "        self.bootstrap = bootstrap\n",
    "        self.oob_score = oob_score\n",
    "        self.n_jobs = n_jobs\n",
    "        self.random_state = random_state\n",
    "        self.verbose = verbose\n",
    "        self.warm_start = warm_start\n",
    "        self.ccp_alpha = ccp_alpha\n",
    "        self.max_samples = max_samples\n",
    "        self.monotonic_cst = monotonic_cst\n",
    "        self.weight_function = \"w1\"\n",
    "\n",
    "        super().__init__(environment_info, cu, co, preprocessors, postprocessors)\n",
    "\n",
    "    def _get_fitted_model(self,\n",
    "                            X: np.ndarray,\n",
    "                            Y: np.ndarray):\n",
    "\n",
    "        model = RandomForestRegressor(\n",
    "            criterion=self.criterion,\n",
    "            n_estimators=self.n_estimators,\n",
    "            max_depth=self.max_depth,\n",
    "            min_samples_split=self.min_samples_split,\n",
    "            min_samples_leaf=self.min_samples_leaf,\n",
    "            min_weight_fraction_leaf=self.min_weight_fraction_leaf,\n",
    "            max_features=self.max_features,\n",
    "            max_leaf_nodes=self.max_leaf_nodes,\n",
    "            min_impurity_decrease=self.min_impurity_decrease,\n",
    "            bootstrap=self.bootstrap,\n",
    "            oob_score=self.oob_score,\n",
    "            n_jobs=self.n_jobs,\n",
    "            random_state=self.random_state,\n",
    "            verbose=self.verbose,\n",
    "            warm_start=self.warm_start,\n",
    "            ccp_alpha=self.ccp_alpha,\n",
    "            max_samples=self.max_samples,\n",
    "            monotonic_cst = self.monotonic_cst\n",
    "        )\n",
    "\n",
    "        self.model_ = model.fit(X, Y)\n",
    "        self.train_leaf_indices_ = model.apply(X)\n",
    "\n",
    "    def _calc_weights(self, sample):\n",
    "        sample_leaf_indices = self.model_.apply([sample])\n",
    "        if self.weight_function == \"w1\":\n",
    "            n = np.sum(sample_leaf_indices == self.train_leaf_indices_, axis=0)\n",
    "            treeWeights = (sample_leaf_indices == self.train_leaf_indices_) / n\n",
    "            weights = np.sum(treeWeights, axis=1) / self.n_estimators\n",
    "        else:\n",
    "            n = np.sum(sample_leaf_indices == self.train_leaf_indices_)\n",
    "            treeWeights = (sample_leaf_indices == self.train_leaf_indices_) / n\n",
    "            weights = np.sum(treeWeights, axis=1)\n",
    "        \n",
    "        weightPosIndex = np.where(weights > 0)[0]\n",
    "        weightsPos = weights[weightPosIndex]\n",
    "\n",
    "        return (weightsPos, weightPosIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddopnew.envs.inventory import NewsvendorEnv\n",
    "from ddopnew.dataloaders.tabular import XYDataLoader\n",
    "from ddopnew.experiment_functions import run_experiment, test_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-20.441162347552524 -19.43430419703072\n",
      "results\n",
      "-18.473572947918147 -17.59723225709455 -18.473572947918147 -17.59723225709455\n",
      "-15.992307800853201 -15.191937164820196\n"
     ]
    }
   ],
   "source": [
    "val_index_start = 800 #90_000\n",
    "test_index_start = 900 #100_000\n",
    "\n",
    "X = np.random.rand(1000, 2)\n",
    "Y = np.random.rand(1000, 1)\n",
    "\n",
    "dataloader = XYDataLoader(X, Y, val_index_start, test_index_start)\n",
    "\n",
    "environment = NewsvendorEnv(\n",
    "    dataloader = dataloader,\n",
    "    underage_cost = 0.42857,\n",
    "    overage_cost = 1.0,\n",
    "    gamma = 0.999,\n",
    "    horizon_train = 365,\n",
    ")\n",
    "\n",
    "agent = NewsvendorSAAagent(environment.mdp_info, cu=0.42857, co=1.0)\n",
    "agent = NewsvendorRFwSAAagent(environment.mdp_info, cu=0.42857, co=1.0)\n",
    "\n",
    "environment.test()\n",
    "agent.eval()\n",
    "\n",
    "R, J = test_agent(agent, environment)\n",
    "\n",
    "print(R, J)\n",
    "\n",
    "run_experiment(agent, environment, 100, run_id = \"test\", save_best=True) # fit agent via run_experiment function\n",
    "    \n",
    "environment.test()\n",
    "agent.eval()\n",
    "\n",
    "R, J = test_agent(agent, environment)\n",
    "\n",
    "print(R, J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
