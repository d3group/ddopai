{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAA based agents\n",
    "\n",
    "> Agents based on Sample Average Approximation (SAA) or weighted Sample Average Approximation (wSAA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp agents.newsvendor.saa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import logging\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Union, Optional, List\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "from ddopai.envs.base import BaseEnvironment\n",
    "from ddopai.agents.base import BaseAgent\n",
    "from ddopai.utils import MDPInfo\n",
    "from ddopai.agents.obsprocessors import FlattenTimeDimNumpy\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.utils.validation import check_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BaseSAAagent(BaseAgent):\n",
    "\n",
    "    \"\"\"\n",
    "    Base class for Sample Average Approximation Agents, implementing the main method\n",
    "    to find the quntile of some (weighted) empirical distribution.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 environment_info: MDPInfo,\n",
    "                 obsprocessors: Optional[List[object]] = None,\n",
    "                 agent_name: str | None = None,\n",
    "                 ):\n",
    "\n",
    "        super().__init__(environment_info = environment_info, obsprocessors = obsprocessors, agent_name = agent_name)\n",
    "\n",
    "        # check if FlattenTimeDimNumpy in obsprocessors\n",
    "        if not any(isinstance(p, FlattenTimeDimNumpy) for p in self.obsprocessors):\n",
    "            self.add_obsprocessor(FlattenTimeDimNumpy(allow_2d=True))\n",
    "\n",
    "    def find_weighted_quantiles(self, weights, weightPosIndices, sl, y):\n",
    "        \n",
    "        \"\"\"\n",
    "        Find the weighted quantile of a range of data y. \n",
    "        It assumes that all arrays are of shape (n_samples, n_outputs). Note that it\n",
    "        has not been tested for n_outputs > 1.\n",
    "        \"\"\"\n",
    "\n",
    "        # test shapes have lenght 2 with error\n",
    "        assert len(y.shape) == 2, \"y should be of shape (n_samples, n_outputs)\"\n",
    "\n",
    "        n_outputs = y.shape[1]\n",
    "\n",
    "        yWeightPos = y[weightPosIndices]\n",
    "\n",
    "        if self.print:\n",
    "            print(yWeightPos)\n",
    "        \n",
    "        q = []\n",
    "\n",
    "        if len(weights.shape) == 1:\n",
    "            weights = weights.reshape(-1, 1)\n",
    "        \n",
    "        for i in range(n_outputs):\n",
    "            \n",
    "            indicesYSort = np.argsort(yWeightPos[:, i])\n",
    "            \n",
    "            ySorted = yWeightPos[indicesYSort, i]\n",
    "            \n",
    "            distributionFunction = np.cumsum(weights[indicesYSort, i])\n",
    "\n",
    "            decisionIndex = np.where(distributionFunction >= sl)[0][0]\n",
    "            \n",
    "            q.append(ySorted[decisionIndex])\n",
    "\n",
    "        q = np.array(q)\n",
    "        \n",
    "        return q\n",
    "    \n",
    "    def _validate_X_predict(self, X):\n",
    "        \n",
    "        \"\"\"Validate X data before prediction\"\"\"\n",
    "\n",
    "        X = check_array(X)\n",
    "\n",
    "        n_features = X.shape[1]\n",
    "        if self.n_features_ != n_features:\n",
    "            raise ValueError(\"Number of features of the model must match the input. \"\n",
    "                             \"Model n_features is %s and input n_features is %s \"\n",
    "                             % (self.n_features_, n_features))\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/agents/newsvendor/saa.py#L25){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "## BaseSAAagent\n",
       "\n",
       ">      BaseSAAagent (environment_info:ddopai.utils.MDPInfo,\n",
       ">                    obsprocessors:Optional[List[object]]=None,\n",
       ">                    agent_name:str|None=None)\n",
       "\n",
       "*Base class for Sample Average Approximation Agents, implementing the main method\n",
       "to find the quntile of some (weighted) empirical distribution.*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/agents/newsvendor/saa.py#L25){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "## BaseSAAagent\n",
       "\n",
       ">      BaseSAAagent (environment_info:ddopai.utils.MDPInfo,\n",
       ">                    obsprocessors:Optional[List[object]]=None,\n",
       ">                    agent_name:str|None=None)\n",
       "\n",
       "*Base class for Sample Average Approximation Agents, implementing the main method\n",
       "to find the quntile of some (weighted) empirical distribution.*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(BaseSAAagent, title_level=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/agents/newsvendor/saa.py#L84){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BaseSAAagent._validate_X_predict\n",
       "\n",
       ">      BaseSAAagent._validate_X_predict (X)\n",
       "\n",
       "*Validate X data before prediction*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/agents/newsvendor/saa.py#L84){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BaseSAAagent._validate_X_predict\n",
       "\n",
       ">      BaseSAAagent._validate_X_predict (X)\n",
       "\n",
       "*Validate X data before prediction*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(BaseSAAagent._validate_X_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/agents/newsvendor/saa.py#L45){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BaseSAAagent.find_weighted_quantiles\n",
       "\n",
       ">      BaseSAAagent.find_weighted_quantiles (weights, weightPosIndices, sl, y)\n",
       "\n",
       "*Find the weighted quantile of a range of data y. \n",
       "It assumes that all arrays are of shape (n_samples, n_outputs). Note that it\n",
       "has not been tested for n_outputs > 1.*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/agents/newsvendor/saa.py#L45){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BaseSAAagent.find_weighted_quantiles\n",
       "\n",
       ">      BaseSAAagent.find_weighted_quantiles (weights, weightPosIndices, sl, y)\n",
       "\n",
       "*Find the weighted quantile of a range of data y. \n",
       "It assumes that all arrays are of shape (n_samples, n_outputs). Note that it\n",
       "has not been tested for n_outputs > 1.*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(BaseSAAagent.find_weighted_quantiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class NewsvendorSAAagent(BaseSAAagent):\n",
    "\n",
    "    \"\"\"\n",
    "    Newsvendor agent that uses Sample Average Approximation to find the quantile of the empirical distribution\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                environment_info: MDPInfo,\n",
    "                cu: float | np.ndarray, # underage cost\n",
    "                co: float | np.ndarray, # overage cost\n",
    "                obsprocessors: list[object] | None = None,\n",
    "                agent_name: str = \"SAA\",\n",
    "                ):\n",
    "\n",
    "            # if float, convert to array\n",
    "            cu = self.convert_to_numpy_array(cu)\n",
    "            co = self.convert_to_numpy_array(co)\n",
    "\n",
    "            self.sl = cu / (cu + co)\n",
    "            self.fitted = False\n",
    "\n",
    "            super().__init__(environment_info = environment_info, obsprocessors = obsprocessors, agent_name = agent_name)\n",
    "\n",
    "    def fit(self,\n",
    "            X: np.ndarray, # features will be ignored\n",
    "            Y: np.ndarray) -> None:\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        Fit the agent to the data. The agent will find the quantile of the empirical distribution of the data.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        # # potential line:\n",
    "        # X, y = self._validate_data(X, y, multi_output=True)\n",
    "\n",
    "        weights = np.ones(Y.shape)/Y.shape[0]\n",
    "        weightPosIndices = np.arange(Y.shape[0])\n",
    "        \n",
    "        self.quantiles = self.find_weighted_quantiles(weights, weightPosIndices, self.sl, Y)\n",
    "\n",
    "        self.fitted = True\n",
    "\n",
    "    def draw_action_(self, \n",
    "                    observation: np.ndarray) -> np.ndarray: #\n",
    "        \"\"\"\n",
    "\n",
    "        Draw an action from the quantile of the empirical distribution.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "        if self.fitted == False:\n",
    "            return np.array([0.0])\n",
    "\n",
    "        return self.quantiles\n",
    "\n",
    "\n",
    "    def save(self,\n",
    "                path: str, # The directory where the file will be saved.\n",
    "                overwrite: bool=True): # Allow overwriting; if False, a FileExistsError will be raised if the file exists.\n",
    "        \n",
    "        \"\"\"\n",
    "        Save the quantiles to a file in the specified directory.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if not self.fitted:\n",
    "            raise ValueError(\"Agent has not been fitted yet\")\n",
    "\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        \n",
    "        full_path = os.path.join(path, \"saa_quantiles.npy\")\n",
    "        \n",
    "        if os.path.exists(full_path):\n",
    "            if not overwrite:\n",
    "                raise FileExistsError(f\"The file {full_path} already exists and will not be overwritten.\")\n",
    "            else:\n",
    "                logging.warning(f\"Overwriting file {full_path}\")\n",
    "                \n",
    "        np.save(full_path, self.quantiles)\n",
    "\n",
    "    def load(self, path: str): # Only the path to the folder is needed, not the file itself\n",
    "\n",
    "        \"\"\"\n",
    "        Load the quantiles from a file.\n",
    "        \n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        full_path = os.path.join(path, \"saa_quantiles.npy\")\n",
    "        \n",
    "        if not os.path.exists(full_path):\n",
    "            raise FileNotFoundError(f\"The file {full_path} does not exist.\")\n",
    "        \n",
    "        try:\n",
    "            self.quantiles = np.load(full_path)\n",
    "            self.fitted = True  # Assuming that loading the quantiles means the agent is now 'fitted'\n",
    "            logging.info(f\"Quantiles loaded successfully from {full_path}\")\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"An error occurred while loading the file: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/agents/newsvendor/saa.py#L98){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "## NewsvendorSAAagent\n",
       "\n",
       ">      NewsvendorSAAagent (environment_info:ddopai.utils.MDPInfo,\n",
       ">                          cu:float|numpy.ndarray, co:float|numpy.ndarray,\n",
       ">                          obsprocessors:list[object]|None=None,\n",
       ">                          agent_name:str='SAA')\n",
       "\n",
       "*Newsvendor agent that uses Sample Average Approximation to find the quantile of the empirical distribution*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| environment_info | MDPInfo |  |  |\n",
       "| cu | float \\| numpy.ndarray |  | underage cost |\n",
       "| co | float \\| numpy.ndarray |  | overage cost |\n",
       "| obsprocessors | list[object] \\| None | None |  |\n",
       "| agent_name | str | SAA |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/agents/newsvendor/saa.py#L98){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "## NewsvendorSAAagent\n",
       "\n",
       ">      NewsvendorSAAagent (environment_info:ddopai.utils.MDPInfo,\n",
       ">                          cu:float|numpy.ndarray, co:float|numpy.ndarray,\n",
       ">                          obsprocessors:list[object]|None=None,\n",
       ">                          agent_name:str='SAA')\n",
       "\n",
       "*Newsvendor agent that uses Sample Average Approximation to find the quantile of the empirical distribution*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| environment_info | MDPInfo |  |  |\n",
       "| cu | float \\| numpy.ndarray |  | underage cost |\n",
       "| co | float \\| numpy.ndarray |  | overage cost |\n",
       "| obsprocessors | list[object] \\| None | None |  |\n",
       "| agent_name | str | SAA |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(NewsvendorSAAagent, title_level=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further information:\n",
    "\n",
    "References:\n",
    "\n",
    "    .. [1] Levi, Retsef, Georgia Perakis, and Joline Uichanco. \"The data-driven newsvendor problem: new bounds and insights.\"\n",
    "           Operations Research 63.6 (2015): 1294-1306."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/agents/newsvendor/saa.py#L123){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### NewsvendorSAAagent.fit\n",
       "\n",
       ">      NewsvendorSAAagent.fit (X:numpy.ndarray, Y:numpy.ndarray)\n",
       "\n",
       "*Fit the agent to the data. The agent will find the quantile of the empirical distribution of the data.*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| X | ndarray | features will be ignored |\n",
       "| Y | ndarray |  |\n",
       "| **Returns** | **None** |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/agents/newsvendor/saa.py#L123){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### NewsvendorSAAagent.fit\n",
       "\n",
       ">      NewsvendorSAAagent.fit (X:numpy.ndarray, Y:numpy.ndarray)\n",
       "\n",
       "*Fit the agent to the data. The agent will find the quantile of the empirical distribution of the data.*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| X | ndarray | features will be ignored |\n",
       "| Y | ndarray |  |\n",
       "| **Returns** | **None** |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(NewsvendorSAAagent.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/agents/newsvendor/saa.py#L143){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### NewsvendorSAAagent.draw_action_\n",
       "\n",
       ">      NewsvendorSAAagent.draw_action_ (observation:numpy.ndarray)\n",
       "\n",
       "*Draw an action from the quantile of the empirical distribution.*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| observation | ndarray |  |\n",
       "| **Returns** | **ndarray** |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/agents/newsvendor/saa.py#L143){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### NewsvendorSAAagent.draw_action_\n",
       "\n",
       ">      NewsvendorSAAagent.draw_action_ (observation:numpy.ndarray)\n",
       "\n",
       "*Draw an action from the quantile of the empirical distribution.*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| observation | ndarray |  |\n",
       "| **Returns** | **ndarray** |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(NewsvendorSAAagent.draw_action_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/agents/newsvendor/saa.py#L158){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### NewsvendorSAAagent.save\n",
       "\n",
       ">      NewsvendorSAAagent.save (path:str, overwrite:bool=True)\n",
       "\n",
       "*Save the quantiles to a file in the specified directory.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| path | str |  | The directory where the file will be saved. |\n",
       "| overwrite | bool | True | Allow overwriting; if False, a FileExistsError will be raised if the file exists. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/agents/newsvendor/saa.py#L158){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### NewsvendorSAAagent.save\n",
       "\n",
       ">      NewsvendorSAAagent.save (path:str, overwrite:bool=True)\n",
       "\n",
       "*Save the quantiles to a file in the specified directory.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| path | str |  | The directory where the file will be saved. |\n",
       "| overwrite | bool | True | Allow overwriting; if False, a FileExistsError will be raised if the file exists. |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(NewsvendorSAAagent.save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/agents/newsvendor/saa.py#L182){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### NewsvendorSAAagent.load\n",
       "\n",
       ">      NewsvendorSAAagent.load (path:str)\n",
       "\n",
       "*Load the quantiles from a file.*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| path | str | Only the path to the folder is needed, not the file itself |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/agents/newsvendor/saa.py#L182){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### NewsvendorSAAagent.load\n",
       "\n",
       ">      NewsvendorSAAagent.load (path:str)\n",
       "\n",
       "*Load the quantiles from a file.*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| path | str | Only the path to the folder is needed, not the file itself |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(NewsvendorSAAagent.load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class BasewSAAagent(BaseSAAagent):\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    Base class for weighted Sample Average Approximation (wSAA) Agents\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                environment_info: MDPInfo,\n",
    "                cu: float | np.ndarray,\n",
    "                co: float | np.ndarray,\n",
    "                obsprocessors: list[object] | None = None,\n",
    "                agent_name: str = \"wSAA\",\n",
    "                ):  #\n",
    "\n",
    "\n",
    "        # if float, convert to array\n",
    "        self.cu = np.array([cu]) if isinstance(cu, float) else cu\n",
    "        self.co = np.array([co]) if isinstance(co, float) else co\n",
    "\n",
    "        cu = self.convert_to_numpy_array(cu)\n",
    "        co = self.convert_to_numpy_array(co)\n",
    "\n",
    "        self.sl = cu / (cu + co)\n",
    "        \n",
    "        self.fitted = False\n",
    "\n",
    "        super().__init__(environment_info = environment_info, obsprocessors = obsprocessors, agent_name = agent_name)\n",
    "\n",
    "    def fit(self,\n",
    "            X: np.ndarray,\n",
    "            Y: np.ndarray): #\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        Fit the agent to the data. The function will call _get_fitted_model which will\n",
    "        train a machine learning model to determine the sample weightes (e.g., kNN, DT, RF).\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        # # potential line:\n",
    "        # X, y = self._validate_data(X, y, multi_output=True)\n",
    "\n",
    "        # get FlattenTimeDimNumpy obsprocessor\n",
    "        flatten_obsprocessor = [p for p in self.obsprocessors if isinstance(p, FlattenTimeDimNumpy)][0]\n",
    "\n",
    "        X = flatten_obsprocessor(X)\n",
    "\n",
    "        if len(Y.shape) == 2 and Y.shape[1] == 1:\n",
    "            Y = Y.flatten() \n",
    "\n",
    "        self._get_fitted_model(X, Y)\n",
    "\n",
    "        if Y.ndim == 1:\n",
    "            Y = np.reshape(Y, (-1, 1))\n",
    "\n",
    "        # Training data\n",
    "        self.Y_ = Y\n",
    "        self.X_ = X\n",
    "        self.n_samples_ = Y.shape[0]\n",
    "\n",
    "        # Determine output settings\n",
    "        self.n_outputs_ = Y.shape[1]\n",
    "        self.n_features_ = X.shape[1]\n",
    "\n",
    "        self.fitted=True\n",
    "\n",
    "    def draw_action_(self, \n",
    "                    observation: np.ndarray) -> np.ndarray: # \n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        Draw an action based on the fitted model (see predict method)\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if self.fitted == False:\n",
    "            return np.array([0.0])\n",
    "        \n",
    "        return self.predict(observation)\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _get_fitted_model(self, X, y):\n",
    "        \"\"\"Initialise the underlying model - depending on the underlying machine learning model\"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def _calc_weights(self, sample):\n",
    "        \"\"\"Calculate the sample weights - depending on the underlying machine learning model\"\"\"\n",
    "\n",
    "    def predict(self, \n",
    "                X: np.ndarray\n",
    "    ) -> np.ndarray: #\n",
    "        \"\"\"Predict value for X by finding the quantiles of the empirical distribution based\n",
    "        on the sample weights predicted by the underlying machine learning model.\n",
    "        \"\"\"\n",
    "\n",
    "        X = self._validate_X_predict(X)  \n",
    "\n",
    "        if self.print:\n",
    "            print(\"X: \", X)\n",
    "\n",
    "        weightsDataList = [self._calc_weights(row) for row in X]\n",
    "\n",
    "        if self.print:\n",
    "            print(\"weightsDataList: \", weightsDataList)\n",
    "\n",
    "        pred = [self.find_weighted_quantiles(weights, weightPosIndices, self.sl, self.Y_) \n",
    "                for weights, weightPosIndices in weightsDataList]\n",
    "\n",
    "\n",
    "        pred = np.array(pred)   \n",
    "\n",
    "        if self.print:\n",
    "            print(\"Predicted quantiles: \", pred)\n",
    "\n",
    "        return pred\n",
    "\n",
    "    def save(self,\n",
    "                path: str, # The directory where the file will be saved.\n",
    "                overwrite: bool=True): # Allow overwriting; if False, a FileExistsError will be raised if the file exists.\n",
    "        \"\"\"\n",
    "        Save the scikit-learn model to a file in the specified directory.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        if not self.fitted:\n",
    "            raise ValueError(\"Agent has not been fitted yet\")\n",
    "\n",
    "        if not hasattr(self, 'model_') or self.model_ is None:\n",
    "            raise ValueError(\"Agent has no model to save.\")\n",
    "\n",
    "        # Create directory if it does not exist\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "        \n",
    "        # Construct the file path using os.path.join for better cross-platform compatibility\n",
    "        full_path = os.path.join(path, \"model.joblib\")\n",
    "        \n",
    "        if os.path.exists(full_path):\n",
    "            if not overwrite:\n",
    "                raise FileExistsError(f\"The file {full_path} already exists and will not be overwritten.\")\n",
    "            else:\n",
    "                logging.warning(f\"Overwriting file {full_path}\")\n",
    "        \n",
    "        # Save the model using joblib\n",
    "        joblib.dump(self.model_, full_path)\n",
    "\n",
    "    def load(self, path: str): # Only the path to the folder is needed, not the file itself\n",
    "        \"\"\"\n",
    "        Load the scikit-learn model from a file.\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        # Construct the file path\n",
    "        full_path = os.path.join(path, \"model.joblib\")\n",
    "        \n",
    "        if not os.path.exists(full_path):\n",
    "            raise FileNotFoundError(f\"The file {full_path} does not exist.\")\n",
    "        \n",
    "        try:\n",
    "            # Load the model using joblib\n",
    "            self.model_ = joblib.load(full_path)\n",
    "            self.fitted = True  # Assuming that loading the model means the agent is now 'fitted'\n",
    "            logging.info(f\"Model loaded successfully from {full_path}\")\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"An error occurred while loading the model: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/agents/newsvendor/saa.py#L203){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "## BasewSAAagent\n",
       "\n",
       ">      BasewSAAagent (environment_info:ddopai.utils.MDPInfo,\n",
       ">                     cu:float|numpy.ndarray, co:float|numpy.ndarray,\n",
       ">                     obsprocessors:list[object]|None=None,\n",
       ">                     agent_name:str='wSAA')\n",
       "\n",
       "*Base class for weighted Sample Average Approximation (wSAA) Agents*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/agents/newsvendor/saa.py#L203){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "## BasewSAAagent\n",
       "\n",
       ">      BasewSAAagent (environment_info:ddopai.utils.MDPInfo,\n",
       ">                     cu:float|numpy.ndarray, co:float|numpy.ndarray,\n",
       ">                     obsprocessors:list[object]|None=None,\n",
       ">                     agent_name:str='wSAA')\n",
       "\n",
       "*Base class for weighted Sample Average Approximation (wSAA) Agents*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(BasewSAAagent, title_level=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/agents/newsvendor/saa.py#L234){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BasewSAAagent.fit\n",
       "\n",
       ">      BasewSAAagent.fit (X:numpy.ndarray, Y:numpy.ndarray)\n",
       "\n",
       "*Fit the agent to the data. The function will call _get_fitted_model which will\n",
       "train a machine learning model to determine the sample weightes (e.g., kNN, DT, RF).*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| X | ndarray |  |\n",
       "| Y | ndarray |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/agents/newsvendor/saa.py#L234){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BasewSAAagent.fit\n",
       "\n",
       ">      BasewSAAagent.fit (X:numpy.ndarray, Y:numpy.ndarray)\n",
       "\n",
       "*Fit the agent to the data. The function will call _get_fitted_model which will\n",
       "train a machine learning model to determine the sample weightes (e.g., kNN, DT, RF).*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| X | ndarray |  |\n",
       "| Y | ndarray |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(BasewSAAagent.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/agents/base.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BaseAgent.draw_action\n",
       "\n",
       ">      BaseAgent.draw_action (observation:numpy.ndarray)\n",
       "\n",
       "*Main interfrace to the environemnt. Applies preprocessors to the observation.\n",
       "Internal logic of the agent to be implemented in draw_action_ method.*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| observation | ndarray |  |\n",
       "| **Returns** | **ndarray** |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/agents/base.py#LNone){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BaseAgent.draw_action\n",
       "\n",
       ">      BaseAgent.draw_action (observation:numpy.ndarray)\n",
       "\n",
       "*Main interfrace to the environemnt. Applies preprocessors to the observation.\n",
       "Internal logic of the agent to be implemented in draw_action_ method.*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| observation | ndarray |  |\n",
       "| **Returns** | **ndarray** |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(BasewSAAagent.draw_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/agents/newsvendor/saa.py#L287){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BasewSAAagent._get_fitted_model\n",
       "\n",
       ">      BasewSAAagent._get_fitted_model (X, y)\n",
       "\n",
       "*Initialise the underlying model - depending on the underlying machine learning model*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/agents/newsvendor/saa.py#L287){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BasewSAAagent._get_fitted_model\n",
       "\n",
       ">      BasewSAAagent._get_fitted_model (X, y)\n",
       "\n",
       "*Initialise the underlying model - depending on the underlying machine learning model*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(BasewSAAagent._get_fitted_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/agents/newsvendor/saa.py#L291){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BasewSAAagent._calc_weights\n",
       "\n",
       ">      BasewSAAagent._calc_weights (sample)\n",
       "\n",
       "*Calculate the sample weights - depending on the underlying machine learning model*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/agents/newsvendor/saa.py#L291){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BasewSAAagent._calc_weights\n",
       "\n",
       ">      BasewSAAagent._calc_weights (sample)\n",
       "\n",
       "*Calculate the sample weights - depending on the underlying machine learning model*"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(BasewSAAagent._calc_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/agents/newsvendor/saa.py#L294){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BasewSAAagent.predict\n",
       "\n",
       ">      BasewSAAagent.predict (X:numpy.ndarray)\n",
       "\n",
       "*Predict value for X by finding the quantiles of the empirical distribution based\n",
       "on the sample weights predicted by the underlying machine learning model.*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| X | ndarray |  |\n",
       "| **Returns** | **ndarray** |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/agents/newsvendor/saa.py#L294){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BasewSAAagent.predict\n",
       "\n",
       ">      BasewSAAagent.predict (X:numpy.ndarray)\n",
       "\n",
       "*Predict value for X by finding the quantiles of the empirical distribution based\n",
       "on the sample weights predicted by the underlying machine learning model.*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| X | ndarray |  |\n",
       "| **Returns** | **ndarray** |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(BasewSAAagent.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/agents/newsvendor/saa.py#L322){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BasewSAAagent.save\n",
       "\n",
       ">      BasewSAAagent.save (path:str, overwrite:bool=True)\n",
       "\n",
       "*Save the scikit-learn model to a file in the specified directory.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| path | str |  | The directory where the file will be saved. |\n",
       "| overwrite | bool | True | Allow overwriting; if False, a FileExistsError will be raised if the file exists. |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/agents/newsvendor/saa.py#L322){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BasewSAAagent.save\n",
       "\n",
       ">      BasewSAAagent.save (path:str, overwrite:bool=True)\n",
       "\n",
       "*Save the scikit-learn model to a file in the specified directory.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| path | str |  | The directory where the file will be saved. |\n",
       "| overwrite | bool | True | Allow overwriting; if False, a FileExistsError will be raised if the file exists. |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(BasewSAAagent.save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/agents/newsvendor/saa.py#L351){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BasewSAAagent.load\n",
       "\n",
       ">      BasewSAAagent.load (path:str)\n",
       "\n",
       "*Load the scikit-learn model from a file.*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| path | str | Only the path to the folder is needed, not the file itself |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/agents/newsvendor/saa.py#L351){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### BasewSAAagent.load\n",
       "\n",
       ">      BasewSAAagent.load (path:str)\n",
       "\n",
       "*Load the scikit-learn model from a file.*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| path | str | Only the path to the folder is needed, not the file itself |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(BasewSAAagent.load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class NewsvendorRFwSAAagent(BasewSAAagent):\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    Newsvendor agent that uses weighted Sample Average Approximation based on Random Forest\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                environment_info: MDPInfo,\n",
    "                cu: float | np.ndarray, # underage cost\n",
    "                co: float | np.ndarray, # overage cost\n",
    "                obsprocessors: list[object] | None = None, # List of obsprocessors to apply to the observation\n",
    "                n_estimators: int = 100,# The number of trees in the forest.\n",
    "                criterion: str = \"squared_error\", # Function to measure the quality of a split.\n",
    "                max_depth: int | None = None, # Maximum depth of the tree; None means unlimited.\n",
    "                min_samples_split: int = 2, # Minimum samples required to split a node.\n",
    "                min_samples_leaf: int = 1, # Minimum samples required to be at a leaf node.\n",
    "                min_weight_fraction_leaf: float = 0.0, # Minimum weighted fraction of the total weights at a leaf node.\n",
    "                max_features: int | float | str | None = 1.0, # Number of features to consider when looking for the best split.\n",
    "                max_leaf_nodes: int | None = None, # Maximum number of leaf nodes; None means unlimited.\n",
    "                min_impurity_decrease: float = 0.0, # Minimum impurity decrease required to split a node.\n",
    "                bootstrap: bool = True, # Whether to use bootstrap samples when building trees.\n",
    "                oob_score: bool = False, # Whether to use out-of-bag samples to estimate R^2 on unseen data.\n",
    "                n_jobs: int | None = None, # Number of jobs to run in parallel; None means 1.\n",
    "                random_state: int | np.random.RandomState | None = None, # Controls randomness for bootstrapping and feature sampling.\n",
    "                verbose: int = 0, # Controls the verbosity when fitting and predicting.\n",
    "                warm_start: bool = False, # If True, reuse solution from previous fit and add more estimators.\n",
    "                ccp_alpha: float = 0.0, # Complexity parameter for Minimal Cost-Complexity Pruning.\n",
    "                max_samples: int | float | None = None, # Number of samples to draw when bootstrap is True.\n",
    "                monotonic_cst: np.ndarray | None = None, # Monotonic constraints for features.\n",
    "                agent_name: str = \"wSAA\", # Default wSAA, change if it is needed to differentiate among different ML models\n",
    "                ):\n",
    "        self.criterion = criterion\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.min_weight_fraction_leaf = min_weight_fraction_leaf\n",
    "        self.max_features = max_features\n",
    "        self.max_leaf_nodes = max_leaf_nodes\n",
    "        self.min_impurity_decrease = min_impurity_decrease\n",
    "        self.bootstrap = bootstrap\n",
    "        self.oob_score = oob_score\n",
    "        self.n_jobs = n_jobs\n",
    "        self.random_state = random_state\n",
    "        self.verbose = verbose\n",
    "        self.warm_start = warm_start\n",
    "        self.ccp_alpha = ccp_alpha\n",
    "        self.max_samples = max_samples\n",
    "        self.monotonic_cst = monotonic_cst\n",
    "        self.weight_function = \"w1\"\n",
    "\n",
    "        super().__init__(environment_info = environment_info, cu = cu, co = co, obsprocessors = obsprocessors, agent_name = agent_name)\n",
    "\n",
    "    def _get_fitted_model(self,\n",
    "                            X: np.ndarray,\n",
    "                            Y: np.ndarray): #\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        Fit the underlying machine learning model using all X and Y data in the train set.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        model = RandomForestRegressor(\n",
    "            criterion=self.criterion,\n",
    "            n_estimators=self.n_estimators,\n",
    "            max_depth=self.max_depth,\n",
    "            min_samples_split=self.min_samples_split,\n",
    "            min_samples_leaf=self.min_samples_leaf,\n",
    "            min_weight_fraction_leaf=self.min_weight_fraction_leaf,\n",
    "            max_features=self.max_features,\n",
    "            max_leaf_nodes=self.max_leaf_nodes,\n",
    "            min_impurity_decrease=self.min_impurity_decrease,\n",
    "            bootstrap=self.bootstrap,\n",
    "            oob_score=self.oob_score,\n",
    "            n_jobs=self.n_jobs,\n",
    "            random_state=self.random_state,\n",
    "            verbose=self.verbose,\n",
    "            warm_start=self.warm_start,\n",
    "            ccp_alpha=self.ccp_alpha,\n",
    "            max_samples=self.max_samples,\n",
    "            monotonic_cst = self.monotonic_cst\n",
    "        )\n",
    "\n",
    "        self.model_ = model.fit(X, Y)\n",
    "        self.train_leaf_indices_ = model.apply(X)\n",
    "\n",
    "    def _calc_weights(self, sample: np.ndarray) -> tuple[np.ndarray, np.ndarray]: #\n",
    "\n",
    "        \"\"\"\n",
    "        Calculate the sample weights based on the Random Forest model.\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        sample_leaf_indices = self.model_.apply([sample])\n",
    "        if self.weight_function == \"w1\":\n",
    "            n = np.sum(sample_leaf_indices == self.train_leaf_indices_, axis=0)\n",
    "            treeWeights = (sample_leaf_indices == self.train_leaf_indices_) / n\n",
    "            weights = np.sum(treeWeights, axis=1) / self.n_estimators\n",
    "        else:\n",
    "            n = np.sum(sample_leaf_indices == self.train_leaf_indices_)\n",
    "            treeWeights = (sample_leaf_indices == self.train_leaf_indices_) / n\n",
    "            weights = np.sum(treeWeights, axis=1)\n",
    "        \n",
    "        weightPosIndex = np.where(weights > 0)[0]\n",
    "        weightsPos = weights[weightPosIndex]\n",
    "\n",
    "        return (weightsPos, weightPosIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/agents/newsvendor/saa.py#L372){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "## NewsvendorRFwSAAagent\n",
       "\n",
       ">      NewsvendorRFwSAAagent (environment_info:ddopai.utils.MDPInfo,\n",
       ">                             cu:float|numpy.ndarray, co:float|numpy.ndarray,\n",
       ">                             obsprocessors:list[object]|None=None,\n",
       ">                             n_estimators:int=100,\n",
       ">                             criterion:str='squared_error',\n",
       ">                             max_depth:int|None=None, min_samples_split:int=2,\n",
       ">                             min_samples_leaf:int=1,\n",
       ">                             min_weight_fraction_leaf:float=0.0,\n",
       ">                             max_features:int|float|str|None=1.0,\n",
       ">                             max_leaf_nodes:int|None=None,\n",
       ">                             min_impurity_decrease:float=0.0,\n",
       ">                             bootstrap:bool=True, oob_score:bool=False,\n",
       ">                             n_jobs:int|None=None, random_state:int|numpy.rando\n",
       ">                             m.mtrand.RandomState|None=None, verbose:int=0,\n",
       ">                             warm_start:bool=False, ccp_alpha:float=0.0,\n",
       ">                             max_samples:int|float|None=None,\n",
       ">                             monotonic_cst:numpy.ndarray|None=None,\n",
       ">                             agent_name:str='wSAA')\n",
       "\n",
       "*Newsvendor agent that uses weighted Sample Average Approximation based on Random Forest*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| environment_info | MDPInfo |  |  |\n",
       "| cu | float \\| numpy.ndarray |  | underage cost |\n",
       "| co | float \\| numpy.ndarray |  | overage cost |\n",
       "| obsprocessors | list[object] \\| None | None | List of obsprocessors to apply to the observation |\n",
       "| n_estimators | int | 100 | The number of trees in the forest. |\n",
       "| criterion | str | squared_error | Function to measure the quality of a split. |\n",
       "| max_depth | int \\| None | None | Maximum depth of the tree; None means unlimited. |\n",
       "| min_samples_split | int | 2 | Minimum samples required to split a node. |\n",
       "| min_samples_leaf | int | 1 | Minimum samples required to be at a leaf node. |\n",
       "| min_weight_fraction_leaf | float | 0.0 | Minimum weighted fraction of the total weights at a leaf node. |\n",
       "| max_features | int \\| float \\| str \\| None | 1.0 | Number of features to consider when looking for the best split. |\n",
       "| max_leaf_nodes | int \\| None | None | Maximum number of leaf nodes; None means unlimited. |\n",
       "| min_impurity_decrease | float | 0.0 | Minimum impurity decrease required to split a node. |\n",
       "| bootstrap | bool | True | Whether to use bootstrap samples when building trees. |\n",
       "| oob_score | bool | False | Whether to use out-of-bag samples to estimate R\\^2 on unseen data. |\n",
       "| n_jobs | int \\| None | None | Number of jobs to run in parallel; None means 1. |\n",
       "| random_state | int \\| numpy.random.mtrand.RandomState \\| None | None | Controls randomness for bootstrapping and feature sampling. |\n",
       "| verbose | int | 0 | Controls the verbosity when fitting and predicting. |\n",
       "| warm_start | bool | False | If True, reuse solution from previous fit and add more estimators. |\n",
       "| ccp_alpha | float | 0.0 | Complexity parameter for Minimal Cost-Complexity Pruning. |\n",
       "| max_samples | int \\| float \\| None | None | Number of samples to draw when bootstrap is True. |\n",
       "| monotonic_cst | numpy.ndarray \\| None | None | Monotonic constraints for features. |\n",
       "| agent_name | str | wSAA | Default wSAA, change if it is needed to differentiate among different ML models |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/agents/newsvendor/saa.py#L372){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "## NewsvendorRFwSAAagent\n",
       "\n",
       ">      NewsvendorRFwSAAagent (environment_info:ddopai.utils.MDPInfo,\n",
       ">                             cu:float|numpy.ndarray, co:float|numpy.ndarray,\n",
       ">                             obsprocessors:list[object]|None=None,\n",
       ">                             n_estimators:int=100,\n",
       ">                             criterion:str='squared_error',\n",
       ">                             max_depth:int|None=None, min_samples_split:int=2,\n",
       ">                             min_samples_leaf:int=1,\n",
       ">                             min_weight_fraction_leaf:float=0.0,\n",
       ">                             max_features:int|float|str|None=1.0,\n",
       ">                             max_leaf_nodes:int|None=None,\n",
       ">                             min_impurity_decrease:float=0.0,\n",
       ">                             bootstrap:bool=True, oob_score:bool=False,\n",
       ">                             n_jobs:int|None=None, random_state:int|numpy.rando\n",
       ">                             m.mtrand.RandomState|None=None, verbose:int=0,\n",
       ">                             warm_start:bool=False, ccp_alpha:float=0.0,\n",
       ">                             max_samples:int|float|None=None,\n",
       ">                             monotonic_cst:numpy.ndarray|None=None,\n",
       ">                             agent_name:str='wSAA')\n",
       "\n",
       "*Newsvendor agent that uses weighted Sample Average Approximation based on Random Forest*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| environment_info | MDPInfo |  |  |\n",
       "| cu | float \\| numpy.ndarray |  | underage cost |\n",
       "| co | float \\| numpy.ndarray |  | overage cost |\n",
       "| obsprocessors | list[object] \\| None | None | List of obsprocessors to apply to the observation |\n",
       "| n_estimators | int | 100 | The number of trees in the forest. |\n",
       "| criterion | str | squared_error | Function to measure the quality of a split. |\n",
       "| max_depth | int \\| None | None | Maximum depth of the tree; None means unlimited. |\n",
       "| min_samples_split | int | 2 | Minimum samples required to split a node. |\n",
       "| min_samples_leaf | int | 1 | Minimum samples required to be at a leaf node. |\n",
       "| min_weight_fraction_leaf | float | 0.0 | Minimum weighted fraction of the total weights at a leaf node. |\n",
       "| max_features | int \\| float \\| str \\| None | 1.0 | Number of features to consider when looking for the best split. |\n",
       "| max_leaf_nodes | int \\| None | None | Maximum number of leaf nodes; None means unlimited. |\n",
       "| min_impurity_decrease | float | 0.0 | Minimum impurity decrease required to split a node. |\n",
       "| bootstrap | bool | True | Whether to use bootstrap samples when building trees. |\n",
       "| oob_score | bool | False | Whether to use out-of-bag samples to estimate R\\^2 on unseen data. |\n",
       "| n_jobs | int \\| None | None | Number of jobs to run in parallel; None means 1. |\n",
       "| random_state | int \\| numpy.random.mtrand.RandomState \\| None | None | Controls randomness for bootstrapping and feature sampling. |\n",
       "| verbose | int | 0 | Controls the verbosity when fitting and predicting. |\n",
       "| warm_start | bool | False | If True, reuse solution from previous fit and add more estimators. |\n",
       "| ccp_alpha | float | 0.0 | Complexity parameter for Minimal Cost-Complexity Pruning. |\n",
       "| max_samples | int \\| float \\| None | None | Number of samples to draw when bootstrap is True. |\n",
       "| monotonic_cst | numpy.ndarray \\| None | None | Monotonic constraints for features. |\n",
       "| agent_name | str | wSAA | Default wSAA, change if it is needed to differentiate among different ML models |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(NewsvendorRFwSAAagent, title_level=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Further information:\n",
    "\n",
    "Notes\n",
    "    -----\n",
    "    \n",
    "The default values for the parameters controlling the size of the trees\n",
    "(e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
    "unpruned trees which can potentially be very large on some data sets. To\n",
    "reduce memory consumption, the complexity and size of the trees should be\n",
    "controlled by setting those parameter values.\n",
    "The features are always randomly permuted at each split. Therefore,\n",
    "the best found split may vary, even with the same training data,\n",
    "``max_features=n_features`` and ``bootstrap=False``, if the improvement\n",
    "of the criterion is identical for several splits enumerated during the\n",
    "search of the best split. To obtain a deterministic behaviour during\n",
    "fitting, ``random_state`` has to be fixed.\n",
    "\n",
    "\n",
    "References\n",
    "    ----------\n",
    "\n",
    "    .. [1] L. Breiman, \"Random Forests\", Machine Learning, 45(1), 5-32, 2001.\n",
    "\n",
    "    .. [2] P. Geurts, D. Ernst., and L. Wehenkel, \"Extremely randomized\n",
    "           trees\", Machine Learning, 63(1), 3-42, 2006.\n",
    "\n",
    "    .. [3] Bertsimas, Dimitris, and Nathan Kallus, \"From predictive to prescriptive analytics.\"\n",
    "           arXiv preprint arXiv:1402.5481 (2014).\n",
    "\n",
    "    .. [4] scikit-learn, RandomForestRegressor,\n",
    "           <https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/ensemble/_forest.py>\n",
    "           \n",
    "    .. [5] Scornet, Erwan. \"Random forests and kernel methods.\"\n",
    "           IEEE Transactions on Information Theory 62.3 (2016): 1485-1500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/agents/newsvendor/saa.py#L428){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### NewsvendorRFwSAAagent._get_fitted_model\n",
       "\n",
       ">      NewsvendorRFwSAAagent._get_fitted_model (X:numpy.ndarray,\n",
       ">                                               Y:numpy.ndarray)\n",
       "\n",
       "*Fit the underlying machine learning model using all X and Y data in the train set.*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| X | ndarray |  |\n",
       "| Y | ndarray |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/agents/newsvendor/saa.py#L428){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### NewsvendorRFwSAAagent._get_fitted_model\n",
       "\n",
       ">      NewsvendorRFwSAAagent._get_fitted_model (X:numpy.ndarray,\n",
       ">                                               Y:numpy.ndarray)\n",
       "\n",
       "*Fit the underlying machine learning model using all X and Y data in the train set.*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| X | ndarray |  |\n",
       "| Y | ndarray |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(NewsvendorRFwSAAagent._get_fitted_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/agents/newsvendor/saa.py#L462){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### NewsvendorRFwSAAagent._calc_weights\n",
       "\n",
       ">      NewsvendorRFwSAAagent._calc_weights (sample:numpy.ndarray)\n",
       "\n",
       "*Calculate the sample weights based on the Random Forest model.*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| sample | ndarray |  |\n",
       "| **Returns** | **tuple** |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/opimwue/ddopai/blob/main/ddopai/agents/newsvendor/saa.py#L462){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### NewsvendorRFwSAAagent._calc_weights\n",
       "\n",
       ">      NewsvendorRFwSAAagent._calc_weights (sample:numpy.ndarray)\n",
       "\n",
       "*Calculate the sample weights based on the Random Forest model.*\n",
       "\n",
       "|    | **Type** | **Details** |\n",
       "| -- | -------- | ----------- |\n",
       "| sample | ndarray |  |\n",
       "| **Returns** | **tuple** |  |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(NewsvendorRFwSAAagent._calc_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddopai.envs.inventory.single_period import NewsvendorEnv\n",
    "from ddopai.dataloaders.tabular import XYDataLoader\n",
    "from ddopai.experiments.experiment_functions import run_experiment, test_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-18.01888542213257 -17.142493964355882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Overwriting file results/test/saved_models/best/model.joblib\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results\n",
      "-15.763567080255545 -15.022369246527656 -15.763567080255545 -15.022369246527656\n",
      "-17.334785352427232 -16.554914069406784\n"
     ]
    }
   ],
   "source": [
    "val_index_start = 800 #90_000\n",
    "test_index_start = 900 #100_000\n",
    "\n",
    "X = np.random.rand(1000, 2)\n",
    "Y = np.random.rand(1000, 1)\n",
    "\n",
    "dataloader = XYDataLoader(X, Y, val_index_start, test_index_start)\n",
    "\n",
    "environment = NewsvendorEnv(\n",
    "    dataloader = dataloader,\n",
    "    underage_cost = 0.42857,\n",
    "    overage_cost = 1.0,\n",
    "    gamma = 0.999,\n",
    "    horizon_train = 365,\n",
    ")\n",
    "\n",
    "agent = NewsvendorSAAagent(environment.mdp_info, cu=0.42857, co=1.0)\n",
    "agent = NewsvendorRFwSAAagent(environment.mdp_info, cu=0.42857, co=1.0)\n",
    "\n",
    "environment.test()\n",
    "agent.eval()\n",
    "\n",
    "R, J = test_agent(agent, environment)\n",
    "\n",
    "print(R, J)\n",
    "\n",
    "run_experiment(agent, environment, 100, run_id = \"test\", save_best=True) # fit agent via run_experiment function\n",
    "    \n",
    "environment.test()\n",
    "agent.eval()\n",
    "\n",
    "R, J = test_agent(agent, environment)\n",
    "\n",
    "print(R, J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
