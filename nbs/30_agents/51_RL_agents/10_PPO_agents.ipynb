{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPO agents\n",
    "\n",
    "> PPO based agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp agents.rl.ppo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "import logging\n",
    "\n",
    "# set logging level to INFO\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "from typing import Union, Optional, List, Tuple\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from ddopai.envs.base import BaseEnvironment\n",
    "from ddopai.agents.rl.mushroom_rl import MushroomBaseAgent\n",
    "from ddopai.utils import MDPInfo, Parameter\n",
    "from ddopai.agents.obsprocessors import FlattenTimeDimNumpy\n",
    "from ddopai.RL_approximators import MLPState, MLPActor\n",
    "from ddopai.envs.actionprocessors import ClipAction\n",
    "\n",
    "from ddopai.dataloaders.base import BaseDataLoader\n",
    "\n",
    "from mushroom_rl.algorithms.actor_critic.deep_actor_critic import PPO\n",
    "from mushroom_rl.policy import GaussianTorchPolicy\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchinfo import summary\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "class PPOAgent(MushroomBaseAgent):\n",
    "\n",
    "    \"\"\"\n",
    "    XXX\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Make structure same to SAC with TD3 base class\n",
    "\n",
    "    def __init__(self, \n",
    "                environment_info: MDPInfo,\n",
    "\n",
    "                learning_rate_actor: float = 3e-4,\n",
    "                learning_rate_critic: float | None = None, # If none, then it is set to learning_rate_actor\n",
    "                batch_size: int = 64,\n",
    "                hidden_layers: List = None, # if None, then default is [64, 64]\n",
    "                activation: str = \"relu\", # \"relu\", \"sigmoid\", \"tanh\", \"leakyrelu\", \"elu\"\n",
    "                # tau: float = 0.005,\n",
    "                std_0: float = 0.1,\n",
    "                n_epochs_policy: int = 4,\n",
    "                eps_ppo: float = 0.2,\n",
    "                lam: float = 0.95,\n",
    "                ent_coeff: float = 0.,\n",
    "                n_steps_per_fit=1000,\n",
    "\n",
    "                drop_prob: float = 0.0,\n",
    "                batch_norm: bool = False,\n",
    "                init_method: str = \"xavier_uniform\", # \"xavier_uniform\", \"xavier_normal\", \"he_normal\", \"he_uniform\", \"normal\", \"uniform\"\n",
    "\n",
    "                optimizer: str = \"Adam\", # \"Adam\" or \"SGD\" or \"RMSprop\"  \n",
    "                loss: str = \"MSE\", # currently only MSE is supported     \n",
    "                obsprocessors: list | None = None,      # default: []\n",
    "                device: str = \"cpu\", # \"cuda\" or \"cpu\"\n",
    "                agent_name: str | None = \"SAC\",\n",
    "                ):\n",
    "\n",
    "        self.n_steps_per_fit=n_steps_per_fit\n",
    "\n",
    "        # The standard TD3 agent needs a 2D input, so we need to flatten the time dimension\n",
    "        flatten_time_dim_processor = FlattenTimeDimNumpy(allow_2d=True, batch_dim_included=False)\n",
    "        obsprocessors = (obsprocessors or []) + [flatten_time_dim_processor]\n",
    "\n",
    "        use_cuda = self.set_device(device)\n",
    "\n",
    "        hidden_layers = hidden_layers or [64, 64]\n",
    "\n",
    "        OptimizerClass=self.get_optimizer_class(optimizer)\n",
    "        learning_rate_critic = learning_rate_critic or learning_rate_actor\n",
    "        lossfunction = self.get_loss_function(loss)\n",
    "\n",
    "        input_shape = self.get_input_shape(environment_info.observation_space)\n",
    "        actor_output_shape = environment_info.action_space.shape\n",
    "\n",
    "        input_shape = self.convert_recursively_to_int(input_shape)\n",
    "        actor_output_shape = self.convert_recursively_to_int(actor_output_shape)\n",
    "\n",
    "        policy_params = dict(network=MLPActor,\n",
    "\n",
    "                                input_shape=input_shape,\n",
    "                                output_shape=actor_output_shape,\n",
    "\n",
    "                                hidden_layers=hidden_layers,\n",
    "                                activation=activation,\n",
    "                                drop_prob=drop_prob,\n",
    "                                batch_norm=batch_norm,\n",
    "                                init_method=init_method,\n",
    "\n",
    "                                use_cuda=use_cuda,\n",
    "                                dropout=self.dropout,\n",
    "\n",
    "                                st_0=std_0,\n",
    "\n",
    "                                )\n",
    "                            \n",
    "        policy = GaussianTorchPolicy(**policy_params)\n",
    "\n",
    "        actor_optimizer = {'class': OptimizerClass,\n",
    "            'params': {'lr': learning_rate_actor}} \n",
    "\n",
    "        critic_params = dict(network=MLPState,\n",
    "                optimizer={'class': OptimizerClass,\n",
    "                        'params': {'lr': learning_rate_critic}}, \n",
    "                loss=lossfunction,\n",
    "                input_shape=input_shape,\n",
    "                output_shape=(1,),\n",
    "\n",
    "                hidden_layers=hidden_layers,\n",
    "                activation=activation,\n",
    "                drop_prob=drop_prob,\n",
    "                batch_norm=batch_norm,\n",
    "                init_method=init_method,\n",
    "\n",
    "                use_cuda=use_cuda,\n",
    "                dropout=self.dropout,)\n",
    "\n",
    "        self.agent = PPO(\n",
    "            mdp_info=environment_info,\n",
    "            policy=policy,\n",
    "            actor_optimizer=actor_optimizer,\n",
    "            critic_params=critic_params,\n",
    "            n_epochs_policy=n_epochs_policy,\n",
    "            batch_size=batch_size,\n",
    "            eps_ppo=eps_ppo,\n",
    "            lam=lam,\n",
    "            ent_coeff=ent_coeff,\n",
    "            critic_fit_params=None\n",
    "        )\n",
    "\n",
    "        super().__init__(\n",
    "            environment_info=environment_info,\n",
    "            obsprocessors=obsprocessors,\n",
    "            device=device,\n",
    "            agent_name=agent_name\n",
    "        )\n",
    "\n",
    "        logging.info(\"Actor network:\")\n",
    "        if logging.getLogger().isEnabledFor(logging.INFO):\n",
    "            input_size = self.add_batch_dimension_for_shape(input_shape)\n",
    "            print(summary(self.actor, input_size=input_size))\n",
    "            time.sleep(.2)\n",
    "\n",
    "        logging.info(\"Critic network:\")\n",
    "        if logging.getLogger().isEnabledFor(logging.INFO):\n",
    "            input_size = self.add_batch_dimension_for_shape(input_shape)\n",
    "            print(summary(self.critic, input_size=input_size))\n",
    "\n",
    "    def get_network_list(self, set_actor_critic_attributes: bool = True):\n",
    "        \"\"\" Get the list of networks in the agent for the save and load functions\n",
    "        Get the actor for the predict function in eval mode \"\"\"\n",
    "\n",
    "        critic = self.agent._V._impl.model.network\n",
    "        actor = self.agent.policy._mu._impl.model.network\n",
    "\n",
    "        networks = []\n",
    "        networks.append(critic)\n",
    "        networks.append(actor)\n",
    "\n",
    "        if set_actor_critic_attributes:\n",
    "            return networks, actor, critic\n",
    "        else:\n",
    "            return networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddopai.envs.inventory.single_period import NewsvendorEnv\n",
    "from ddopai.dataloaders.tabular import XYDataLoader\n",
    "from ddopai.experiments.experiment_functions import run_experiment, test_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "(10000, 2) (10000, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/magnus/miniforge3/envs/inventory_gym_2/lib/python3.11/site-packages/gymnasium/spaces/box.py:130: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n",
      "INFO:root:Actor network:\n",
      "/Users/magnus/miniforge3/envs/inventory_gym_2/lib/python3.11/site-packages/torchinfo/torchinfo.py:462: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  action_fn=lambda data: sys.getsizeof(data.storage()),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "MLPActor                                 [1, 1]                    --\n",
      "├─Sequential: 1-1                        [1, 1]                    --\n",
      "│    └─Linear: 2-1                       [1, 64]                   192\n",
      "│    └─ReLU: 2-2                         [1, 64]                   --\n",
      "│    └─Dropout: 2-3                      [1, 64]                   --\n",
      "│    └─Linear: 2-4                       [1, 64]                   4,160\n",
      "│    └─ReLU: 2-5                         [1, 64]                   --\n",
      "│    └─Dropout: 2-6                      [1, 64]                   --\n",
      "│    └─Linear: 2-7                       [1, 1]                    65\n",
      "│    └─Identity: 2-8                     [1, 1]                    --\n",
      "==========================================================================================\n",
      "Total params: 4,417\n",
      "Trainable params: 4,417\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.00\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.02\n",
      "Estimated Total Size (MB): 0.02\n",
      "==========================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Critic network:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "MLPState                                 [1, 1]                    --\n",
      "├─Sequential: 1-1                        [1, 1]                    --\n",
      "│    └─Linear: 2-1                       [1, 64]                   192\n",
      "│    └─ReLU: 2-2                         [1, 64]                   --\n",
      "│    └─Dropout: 2-3                      [1, 64]                   --\n",
      "│    └─Linear: 2-4                       [1, 64]                   4,160\n",
      "│    └─ReLU: 2-5                         [1, 64]                   --\n",
      "│    └─Dropout: 2-6                      [1, 64]                   --\n",
      "│    └─Linear: 2-7                       [1, 1]                    65\n",
      "│    └─Identity: 2-8                     [1, 1]                    --\n",
      "==========================================================================================\n",
      "Total params: 4,417\n",
      "Trainable params: 4,417\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.00\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.02\n",
      "Estimated Total Size (MB): 0.02\n",
      "==========================================================================================\n",
      "-44.039980104932894 -28.64890791879266\n",
      "-44.039980104932894 -28.64890791879266\n"
     ]
    }
   ],
   "source": [
    "\n",
    "val_index_start = 8000 #90_000\n",
    "test_index_start = 9000 #100_000\n",
    "\n",
    "X = np.random.standard_normal((10000, 2))\n",
    "Y = np.random.standard_normal((10000, 1))\n",
    "Y += 2*X[:,0].reshape(-1, 1) + 3*X[:,1].reshape(-1, 1)\n",
    "Y = X[:,0].reshape(-1, 1)\n",
    "# truncate Y at 0:\n",
    "Y = np.maximum(Y, 0)\n",
    "# normalize Y max to 1\n",
    "Y = Y/np.max(Y)\n",
    "\n",
    "print(np.max(Y))\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "\n",
    "clip_action = ClipAction(0., 1.)\n",
    "\n",
    "dataloader = XYDataLoader(X, Y, val_index_start, test_index_start, lag_window_params =  {'lag_window': 0, 'include_y': False, 'pre_calc': True})\n",
    "\n",
    "environment = NewsvendorEnv(\n",
    "    dataloader = dataloader,\n",
    "    underage_cost = 0.42857,\n",
    "    overage_cost = 1.0,\n",
    "    gamma = 0.999,\n",
    "    horizon_train = 365,\n",
    "    q_bound_high = 1.0,\n",
    "    q_bound_low = -0.1,\n",
    "    postprocessors = [clip_action],\n",
    ")\n",
    "\n",
    "agent = PPOAgent(environment.mdp_info,\n",
    "                obsprocessors = None,      # default: []\n",
    "                device=\"cpu\", # \"cuda\" or \"cpu\"\n",
    ")\n",
    "\n",
    "environment.test()\n",
    "agent.eval()\n",
    "\n",
    "R, J = test_agent(agent, environment)\n",
    "\n",
    "print(R, J)\n",
    "\n",
    "environment.train()\n",
    "agent.train()\n",
    "environment.print=False\n",
    "\n",
    "# run_experiment(agent, environment, n_epochs=50, n_steps=1000, run_id = \"test\", save_best=True, print_freq=1) # fit agent via run_experiment function\n",
    "\n",
    "environment.test()\n",
    "agent.eval()\n",
    "\n",
    "R, J = test_agent(agent, environment)\n",
    "\n",
    "print(R, J)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
