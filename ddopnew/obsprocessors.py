# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00_utils/11_obsprocessors.ipynb.

# %% auto 0
__all__ = ['FlattenTimeDimNumpy', 'ConvertDictSpace']

# %% ../nbs/00_utils/11_obsprocessors.ipynb 3
from typing import Union, Optional, List, Tuple, Dict

import numpy as np
from .utils import Parameter, check_parameter_types

import torch
import torch.nn as nn
import torch.nn.functional as F

# %% ../nbs/00_utils/11_obsprocessors.ipynb 4
class FlattenTimeDimNumpy():

    """
    Preprocessor to flatten the time and feature dimension of the input.
    Used, e.g., to convert time-series data for models that cannot process
    a time dimension such as MLPs or Regression models.
    """

    def __init__(self,
        allow_2d: Optional[bool] = False, #
        batch_dim_included: Optional[bool] = True
        ):
        self.allow_2d = allow_2d
        self.batch_dim_included = batch_dim_included

    def check_input(self,
            input: np.ndarray #
            ):
        """
        Check that the input is a PyTorch tensor with the correct shape.
        """
        # Check if the input is a PyTorch tensor
        if not isinstance(input, np.ndarray):
            raise TypeError(f"Expected input to be a numpy array, but got {type(input)} instead.")

        # Determine expected dimensions based on batch_dim_included
        expected_ndim = 3 if self.batch_dim_included else 2
        allow_ndim = 2 if self.batch_dim_included else 1

        # Check if the input array has the correct dimensions
        if input.ndim == expected_ndim:
            # If the input is 3D, it is valid regardless of allow_2d
            return
        elif input.ndim == allow_ndim:
            # If the input has fewer dimensions, check if the reduced dimension is allowed
            if not self.allow_2d:
                raise ValueError(
                    f"Expected input to have {expected_ndim} dimensions with shape "
                    f"{'(batch_size, timesteps, features)' if self.batch_dim_included else '(timesteps, features)'}, "
                    f"but got shape {input.shape} instead. "
                    f"{allow_ndim}D inputs are not allowed when allow_2d is False."
                )
        else:
            # If the input has an unexpected number of dimensions
            expected_shape_msg = (
                f"Expected input to have {expected_ndim} dimensions with shape "
                f"{'(batch_size, timesteps, features)' if self.batch_dim_included else '(timesteps, features)'}"
                if not self.allow_2d
                else f"Expected input to have {expected_ndim} dimensions with shape "
                     f"{'(batch_size, timesteps, features)' if self.batch_dim_included else '(timesteps, features)'} "
                     f"or {allow_ndim} dimensions with shape "
                     f"{'(batch_size, features)' if self.batch_dim_included else '(features)'}"
            )
            raise ValueError(f"{expected_shape_msg}, but got shape {input.shape} instead.")
            
    def __call__(self,
                input: np.ndarray
                ) -> np.ndarray:
                
        """
        Process the input array by keeping the batch dimension and flattening
        the time and feature dimensions.
        """

        # Validate the input tensor
        self.check_input(input)

        if self.batch_dim_included:
            # If batch dimension is included
            if input.ndim == 2:
                output = input
            else:
                # Keep the batch dimension, flatten time and feature dimensions
                batch_size, timesteps, features = input.shape
                output = input.reshape(batch_size, -1)
        else:
            # If batch dimension is not included
            if input.ndim == 1:
                output = input
            else:
                # Flatten time and feature dimensions
                timesteps, features = input.shape
                output = input.reshape(-1)

        return output

# %% ../nbs/00_utils/11_obsprocessors.ipynb 8
class ConvertDictSpace():

    """  

    A utility class to process a dictionary of numpy arrays, with options to preserve or flatten the time dimension.
    
    """

    def __init__(self,
        keep_time_dim: Optional[bool] = False, #If time timension should be flattened as well.
        hybrid_space_params: Optional[Dict] = None, # dict with keys "time" that is a list of observation keys that should keep the time dimension.
        ):
        self.keep_time_dim = keep_time_dim
        self.hybrid_space_params = hybrid_space_params

        if not keep_time_dim and hybrid_space_params is not None:
            raise ValueError("If keep_time_dim is False, hybrid_space_params must be None.")
        if hybrid_space_params is not None and not isinstance(hybrid_space_params, dict):
            raise ValueError("hybrid_space_params must be a dictionary if provided.")


    def __call__(self, 
                input: Dict, # Observation as dict of with numpy arrays
                flatten: True,
                ) -> List[np.ndarray] | np.ndarray: 

        """
        Process the input dictionary by converting it to a numpy array.
        """

        if self.hybrid_space_params is not None:
            obs_2d = [] # time X features
            obs_1d = [] # features
        else:
            obs = [] # features or time X features

        for counter, (key, value) in enumerate(input.items()):
            if not isinstance(value, np.ndarray):
                raise TypeError(f"Expected input to be a dictionary of numpy arrays, but got {type(value)} instead.")

            if self.hybrid_space_params is not None:
                if key in self.hybrid_space_params["time"]:
                    obs_2d.append(value)
                    if counter != 0:
                        assert obs_2d[counter].shape[0] == obs_2d[counter-1].shape[0], "All time dimensions must be the same."
                else:
                    obs_1d.append(value.flatten())
            else:
                if self.keep_time_dim:
                    obs.append(value)
                    if counter != 0:
                        assert obs[counter].shape[0] == obs[counter-1].shape[0], "All time dimensions must be the same."
                else:
                    obs.append(value.flatten())

        if self.hybrid_space_params is not None:
            obs_2d = np.concatenate(obs_2d, axis=0)
            obs_1d = np.concatenate(obs_1d, axis=0)
            if flatten:
                # create a single one dimnensional vector
                return np.concatenate([obs_2d.flatten(), obs_1d], axis=0)
            else:
                return [obs_2d, obs_1d]
        else:
            return np.concatenate(obs, axis=0)

    def determine_output_shape(self,
        sample_input: Dict, #
        ) -> Tuple | List:
        """
        Determine the output shape based on the input dictionary.
        """

        output = self.__call__(sample_input)
        if isinstance(output, list):
            return [output[0].shape, output[1].shape]
        else:
            return output.shape
        
